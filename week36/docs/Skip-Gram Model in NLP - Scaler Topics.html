<!DOCTYPE html>
<!-- saved from url=(0050)https://www.scaler.com/topics/nlp/skip-gram-model/ -->
<html lang="en"><link type="text/css" rel="stylesheet" id="dark-mode-custom-link"><link type="text/css" rel="stylesheet" id="dark-mode-general-link"><style lang="en" type="text/css" id="dark-mode-custom-style"></style><style lang="en" type="text/css" id="dark-mode-native-style"></style><style lang="en" type="text/css" id="dark-mode-native-sheet"></style><script async="" src="./Skip-Gram Model in NLP - Scaler Topics_files/gtm.js.download"></script><script>
    window[Symbol.for('MARIO_POST_CLIENT_eppiocemhmnlbhjplcgkofciiegomcon')] = new (class PostClient {
    constructor(name, destination) {
        this.name = name;
        this.destination = destination;
        this.serverListeners = {};
        this.bgRequestsListeners = {};
        this.bgEventsListeners = {};
        window.addEventListener('message', (message) => {
            const data = message.data;
            const isNotForMe = !(data.destination && data.destination === this.name);
            const hasNotEventProp = !data.event;
            if (isNotForMe || hasNotEventProp) {
                return;
            }
            if (data.event === 'MARIO_POST_SERVER__BG_RESPONSE') {
                const response = data.args;
                if (this.hasBgRequestListener(response.requestId)) {
                    try {
                        this.bgRequestsListeners[response.requestId](response.response);
                    }
                    catch (e) {
                        console.log(e);
                    }
                    delete this.bgRequestsListeners[response.requestId];
                }
            }
            else if (data.event === 'MARIO_POST_SERVER__BG_EVENT') {
                const response = data.args;
                if (this.hasBgEventListener(response.event)) {
                    try {
                        this.bgEventsListeners[data.id](response.payload);
                    }
                    catch (e) {
                        console.log(e);
                    }
                }
            }
            else if (this.hasServerListener(data.event)) {
                try {
                    this.serverListeners[data.event](data.args);
                }
                catch (e) {
                    console.log(e);
                }
            }
            else {
                console.log(`event not handled: ${data.event}`);
            }
        });
    }
    emitToServer(event, args) {
        const id = this.generateUIID();
        const message = {
            args,
            destination: this.destination,
            event,
            id,
        };
        window.postMessage(message, location.origin);
        return id;
    }
    emitToBg(bgEventName, args) {
        const requestId = this.generateUIID();
        const request = { bgEventName, requestId, args };
        this.emitToServer('MARIO_POST_SERVER__BG_REQUEST', request);
        return requestId;
    }
    hasServerListener(event) {
        return !!this.serverListeners[event];
    }
    hasBgRequestListener(requestId) {
        return !!this.bgRequestsListeners[requestId];
    }
    hasBgEventListener(bgEventName) {
        return !!this.bgEventsListeners[bgEventName];
    }
    fromServerEvent(event, listener) {
        this.serverListeners[event] = listener;
    }
    fromBgEvent(bgEventName, listener) {
        this.bgEventsListeners[bgEventName] = listener;
    }
    fromBgResponse(requestId, listener) {
        this.bgRequestsListeners[requestId] = listener;
    }
    generateUIID() {
        return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
            const r = Math.random() * 16 | 0, v = c === 'x' ? r : (r & 0x3 | 0x8);
            return v.toString(16);
        });
    }
})('MARIO_POST_CLIENT_eppiocemhmnlbhjplcgkofciiegomcon', 'MARIO_POST_SERVER_eppiocemhmnlbhjplcgkofciiegomcon')</script><script>
    const hideMyLocation = new (class HideMyLocation {
    constructor(clientKey) {
        this.clientKey = clientKey;
        this.watchIDs = {};
        this.client = window[Symbol.for(clientKey)];
        const getCurrentPosition = navigator.geolocation.getCurrentPosition;
        const watchPosition = navigator.geolocation.watchPosition;
        const clearWatch = navigator.geolocation.clearWatch;
        const self = this;
        navigator.geolocation.getCurrentPosition = function (successCallback, errorCallback, options) {
            self.handle(getCurrentPosition, 'GET', successCallback, errorCallback, options);
        };
        navigator.geolocation.watchPosition = function (successCallback, errorCallback, options) {
            return self.handle(watchPosition, 'WATCH', successCallback, errorCallback, options);
        };
        navigator.geolocation.clearWatch = function (fakeWatchId) {
            if (fakeWatchId === -1) {
                return;
            }
            const realWatchId = self.watchIDs[fakeWatchId];
            delete self.watchIDs[fakeWatchId];
            return clearWatch.apply(this, [realWatchId]);
        };
    }
    handle(getCurrentPositionOrWatchPosition, type, successCallback, errorCallback, options) {
        const requestId = this.client.emitToBg('HIDE_MY_LOCATION__GET_LOCATION');
        let fakeWatchId = this.getRandomInt(0, 100000);
        this.client.fromBgResponse(requestId, (response) => {
            if (response.enabled) {
                if (response.status === 'SUCCESS') {
                    const position = this.map(response);
                    successCallback(position);
                }
                else {
                    const error = this.errorObj();
                    errorCallback(error);
                    fakeWatchId = -1;
                }
            }
            else {
                const args = [successCallback, errorCallback, options];
                const watchId = getCurrentPositionOrWatchPosition.apply(navigator.geolocation, args);
                if (type === 'WATCH') {
                    this.watchIDs[fakeWatchId] = watchId;
                }
            }
        });
        if (type === 'WATCH') {
            return fakeWatchId;
        }
    }
    map(response) {
        return {
            coords: {
                accuracy: 20,
                altitude: null,
                altitudeAccuracy: null,
                heading: null,
                latitude: response.latitude,
                longitude: response.longitude,
                speed: null,
            },
            timestamp: Date.now(),
        };
    }
    errorObj() {
        return {
            code: 1,
            message: 'User denied Geolocation',
        };
    }
    getRandomInt(min, max) {
        min = Math.ceil(min);
        max = Math.floor(max);
        return Math.floor(Math.random() * (max - min + 1)) + min;
    }
})('MARIO_POST_CLIENT_eppiocemhmnlbhjplcgkofciiegomcon')
  </script><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style class="vjs-styles-defaults">
      .video-js {
        width: 300px;
        height: 150px;
      }

      .vjs-fluid:not(.vjs-audio-only-mode) {
        padding-top: 56.25%
      }
    </style><meta name="viewport" content="width=device-width"><title>Skip-Gram Model in NLP - Scaler Topics</title><link rel="canonical" href="https://www.scaler.com/topics/nlp/skip-gram-model/"><meta name="robots" content="max-snippet:-1, max-video-preview:-1, max-image-preview:large"><meta name="description" content="With this article by Scaler Topics Learn about Skip-Gram Model in NLP with examples, explanations, and applications, read to know more"><meta name="author" content="Navaneeth Malingan"><meta name="category" content="NLP"><meta property="og:type" content="article"><meta property="og:title" content="Skip-Gram Model in NLP - Scaler Topics"><meta property="og:description" content="With this article by Scaler Topics Learn about Skip-Gram Model in NLP with examples, explanations, and applications, read to know more"><meta property="og:url" content="https://www.scaler.com/topics/nlp/skip-gram-model/"><meta property="og:site_name" content="Scaler Topics"><meta property="og:image" content="https://www.scaler.com/topics/images/skip-gram-model-fi.webp"><meta property="og:image:secure_url" content="https://www.scaler.com/topics/images/skip-gram-model-fi.webp"><meta property="og:image:width" content="1680"><meta property="og:image:height" content="296"><meta property="og:image:alt" content="Skip-Gram Model in NLP - Scaler Topics"><meta property="article:published_time" content="2023-02-22T00:00:00.000Z"><meta name="twitter:site" content="@ScalerTopics"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Skip-Gram Model in NLP - Scaler Topics"><meta name="twitter:description" content="With this article by Scaler Topics Learn about Skip-Gram Model in NLP with examples, explanations, and applications, read to know more"><meta name="twitter:image" content="https://www.scaler.com/topics/images/skip-gram-model-fi.webp"><meta name="twitter:label1" content="Written by"><meta name="twitter:data1" content="Navaneeth Malingan"><meta name="twitter:label2" content="Time to read"><meta name="twitter:data2" content="8 mins"><meta name="next-head-count" content="28"><link rel="icon" href="https://www.scaler.com/topics/favicon.ico"><link rel="preconnect" href="https://d1g0iq4cbcvjcd.cloudfront.net/topics"><link rel="dns-prefetch" href="https://d1g0iq4cbcvjcd.cloudfront.net/topics"><link rel="preload" href="https://d1g0iq4cbcvjcd.cloudfront.net/topics/_next/static/media/0ac14a3c407fb3c4-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"><link rel="preload" href="https://d1g0iq4cbcvjcd.cloudfront.net/topics/_next/static/media/fc6fba7ce0876fef-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"><script id="article-schema" type="application/ld+json" data-nscript="beforeInteractive" crossorigin="anonymous">{
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https://www.scaler.com/topics/nlp/skip-gram-model/"
        },
        "headline": "Skip-Gram Model in NLP - Scaler Topics",
        "description": "With this article by Scaler Topics Learn about Skip-Gram Model in NLP with examples, explanations, and applications, read to know more",
        "image": ["https://www.scaler.com/topics/images/skip-gram-model-fi.webp","https://www.scaler.com/topics/images/skip-gram-architecture.webp","https://www.scaler.com/topics/images/dense-vector-representations-example.webp"],
        "author": {
          "@type": "Person",
          "name": "Navaneeth Malingan"
        },
        "publisher": {
          "@type": "Organization",
          "name": "Scaler Topics",
          "logo": {
            "@type": "ImageObject",
            "url": "https://www.scaler.com/topics/media/Scaler_Topics-1.png"
          }
        },
        "datePublished": "2023-02-22T00:00:00.000Z",
        "dateModified": "2023-02-22T00:00:00.000Z"
      }</script><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/6735f263889ca6cf.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/6735f263889ca6cf.css" crossorigin="anonymous" data-n-g=""><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/4c0f02e37a44e2c9.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/4c0f02e37a44e2c9.css" crossorigin="anonymous" data-n-p=""><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/7c735c05af084bb2.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/7c735c05af084bb2.css" crossorigin="anonymous" data-n-p=""><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/1c39bb772a97bb9e.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/1c39bb772a97bb9e.css" crossorigin="anonymous" data-n-p=""><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/94fe3a489e39fa09.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/94fe3a489e39fa09.css" crossorigin="anonymous" data-n-p=""><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/fbd65006672839ac.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/fbd65006672839ac.css" crossorigin="anonymous" data-n-p=""><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/927ff01b8d2587e6.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/927ff01b8d2587e6.css" crossorigin="anonymous"><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/47797229093bb63c.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/47797229093bb63c.css" crossorigin="anonymous"><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/aeb8c11256ca3b1d.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/aeb8c11256ca3b1d.css" crossorigin="anonymous"><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/4c0ae727d6226090.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/4c0ae727d6226090.css" crossorigin="anonymous"><link rel="preload" href="./Skip-Gram Model in NLP - Scaler Topics_files/2ec98c4ee67e074d.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/2ec98c4ee67e074d.css" crossorigin="anonymous"><noscript data-n-css=""></noscript><script defer="" crossorigin="anonymous" nomodule="" src="./Skip-Gram Model in NLP - Scaler Topics_files/polyfills-c67a75d1b6f99dc8.js.download"></script><script defer="" src="./Skip-Gram Model in NLP - Scaler Topics_files/2851.174fc0d9090acac1.js.download" crossorigin="anonymous"></script><script defer="" src="./Skip-Gram Model in NLP - Scaler Topics_files/229.f4fe18dbe8271a66.js.download" crossorigin="anonymous"></script><script defer="" src="./Skip-Gram Model in NLP - Scaler Topics_files/6089-945753cc19ef1318.js.download" crossorigin="anonymous"></script><script defer="" src="./Skip-Gram Model in NLP - Scaler Topics_files/6745-0c96d2e5943424f0.js.download" crossorigin="anonymous"></script><script defer="" src="./Skip-Gram Model in NLP - Scaler Topics_files/637.6782c6cdad9f7f0e.js.download" crossorigin="anonymous"></script><script defer="" src="./Skip-Gram Model in NLP - Scaler Topics_files/1631.96bd270612f29316.js.download" crossorigin="anonymous"></script><script defer="" src="./Skip-Gram Model in NLP - Scaler Topics_files/6770.2c9419eac73999ed.js.download" crossorigin="anonymous"></script><script defer="" src="./Skip-Gram Model in NLP - Scaler Topics_files/9605.8a546c1c3e78df2d.js.download" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/webpack-17163b8d388d842e.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/framework-84476791e5b56604.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/main-ace78b5142fc8917.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/_app-ffff201540212eb1.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/413057b3-57a19db2a0fcc17a.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/3710-83dbb7be4ba9d86a.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/9097-3cd3583c3d4b1241.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/6692-55f284d18e6b58e0.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/8421-8d137677ba16bee6.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/1175-9769c94dea56e294.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/6577-89e483e6cbef1fbb.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/43-3413eb9994e63afa.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/8482-060c2255991aa3c6.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/9490-2ee2aa2c721fd80b.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/7602-1305125b8b303f8b.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/6767-3672cc0ffde37c89.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/730-be8681bbc0639490.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/8974-b2a430f2078aa6cf.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/2793-50c11bb94c01d480.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/3981-bdd337a953e8f047.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/7707-1726b087953f7a60.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/568-874d1ded33a27ece.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/3076-f3a9729fdca7836c.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/8956-183b6cf790c3318a.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/114-d8e1f75a4284ff6b.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/6475-b723c55ff13d3a4f.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/[...slug]-b503fe6671b225b4.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/_buildManifest.js.download" defer="" crossorigin="anonymous"></script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/_ssgManifest.js.download" defer="" crossorigin="anonymous"></script><script ecommerce-type="extend-native-history-api">(() => {
            const nativePushState = history.pushState;
            const nativeReplaceState = history.replaceState;
            const nativeBack = history.back;
            const nativeForward = history.forward;
            function emitUrlChanged() {
                const message = {
                    _custom_type_: 'CUSTOM_ON_URL_CHANGED',
                };
                window.postMessage(message);
            }
            history.pushState = function () {
                nativePushState.apply(history, arguments);
                emitUrlChanged();
            };
            history.replaceState = function () {
                nativeReplaceState.apply(history, arguments);
                emitUrlChanged();
            };
            history.back = function () {
                nativeBack.apply(history, arguments);
                emitUrlChanged();
            };
            history.forward = function () {
                nativeForward.apply(history, arguments);
                emitUrlChanged();
            };
        })()</script><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.skeleton {
  background-image: linear-gradient(to right, #f6f7f8 0%, #e8eaed 20%, #f6f7f8 40%, #f6f7f8 100%);
  background-color: #f6f7f8;
  background-repeat: no-repeat;
  background-size: 90rem 100rem;
  animation: shimmer 720ms linear infinite;
  animation-fill-mode: forwards;
  border-radius: var(--border-radius);
}
.skeleton--circle {
  border-radius: 50%;
}
.skeleton--no-animation {
  background-image: none;
}</style><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.tappable {
  display: inline-flex;
  justify-content: center;
  align-items: center;
  flex: 0 0 auto;
  cursor: pointer;
}
.tappable:hover {
  background: rgba(1, 1, 1, 0.1);
}
.tappable:active {
  background: rgba(1, 1, 1, 0.2);
}
.tappable.disabled {
  pointer-events: none;
  opacity: 0.7;
  filter: grayscale(0.5);
}
.tappable.disabled.btn-tooltip {
  pointer-events: inherit;
}
.tappable.no-highlight:hover, .tappable.no-highlight:active {
  background: transparent;
}

.btn {
  padding: 1rem;
  line-height: normal;
  border-radius: var(--border-radius);
  background-color: #dcdcdc;
}

.btn-default {
  color: var(--default-font-color);
}
.btn-default:hover, .btn-default:active {
  background-color: #dcdcdc;
}

.btn-light {
  background-color: transparent;
  color: var(--light-font-color);
}

.btn-dark {
  background-color: transparent;
  color: var(--dark-font-color);
}

.btn-primary {
  background: var(--primary-color);
  color: var(--light-font-color);
}
.btn-primary:hover {
  background: var(--primary-color-50);
  color: var(--light-font-color);
}
.btn-primary:active {
  background: var(--primary-color-70);
}

.btn-secondary {
  background: var(--secondary-color);
  color: var(--light-font-color);
}
.btn-secondary:hover {
  background: var(--secondary-color-50);
  color: var(--light-font-color);
}
.btn-secondary:active {
  background: var(--secondary-color-70);
}

.btn-success {
  background: var(--success-color);
  color: var(--light-font-color);
}
.btn-success:hover {
  background: var(--accent-color-v4-50);
}
.btn-success:active {
  background: var(--accent-color-v4-70);
}

.btn-danger {
  background: var(--danger-color);
  color: var(--light-font-color);
}
.btn-danger:hover {
  background: var(--accent-color-v5-50);
}
.btn-danger:active {
  background: var(--accent-color-v5-70);
}

.btn-warning {
  background: var(--warning-color);
  color: var(--light-font-color);
}
.btn-warning:hover {
  background: var(--accent-color-v6-50);
}
.btn-warning:active {
  background: var(--accent-color-v6-70);
}

.btn-inverted {
  background: none !important;
  color: var(--default-font-color);
}
.btn-inverted:hover {
  background: rgba(1, 1, 1, 0.1) !important;
  color: var(--default-font-color);
}
.btn-inverted:active {
  color: var(--default-font-color);
}
.btn-inverted.btn-primary {
  color: var(--primary-color);
}
.btn-inverted.btn-primary:hover {
  color: var(--primary-color);
}
.btn-inverted.btn-primary:active {
  color: var(--primary-color-70);
}
.btn-inverted.btn-secondary {
  color: var(--secondary-color);
}
.btn-inverted.btn-secondary:hover {
  color: var(--secondary-color);
}
.btn-inverted.btn-secondary:active {
  color: var(--secondary-color-70);
}
.btn-inverted.btn-success {
  color: var(--success-color);
}
.btn-inverted.btn-success:hover {
  color: var(--accent-color-v4-50);
}
.btn-inverted.btn-success:active {
  color: var(--accent-color-v4-70);
}
.btn-inverted.btn-danger {
  color: var(--danger-color);
}
.btn-inverted.btn-danger:hover {
  color: var(--accent-color-v5-50);
}
.btn-inverted.btn-danger:active {
  color: var(--accent-color-v5-70);
}

.btn-outlined {
  background-color: transparent;
  border: 0.1rem solid var(--default-font-color);
  color: var(--default-font-color);
}
.btn-outlined:hover {
  background: rgba(0, 0, 0, 0.05) !important;
}
.btn-outlined:active {
  background: rgba(0, 0, 0, 0.05) !important;
}
.btn-outlined.btn-primary {
  color: var(--primary-color);
  border-color: var(--primary-color);
}
.btn-outlined.btn-primary:hover {
  border-color: var(--primary-color-50);
}
.btn-outlined.btn-primary:active {
  border-color: var(--primary-color-70);
}
.btn-outlined.btn-secondary {
  color: var(--secondary-color);
  border-color: var(--secondary-color);
}
.btn-outlined.btn-secondary:hover {
  border-color: var(--secondary-color-50);
}
.btn-outlined.btn-secondary:active {
  border-color: var(--secondary-color-70);
}
.btn-outlined.btn-success {
  color: var(--success-color);
  border-color: var(--success-color);
}
.btn-outlined.btn-success:hover {
  border-color: var(--accent-color-v4-50);
}
.btn-outlined.btn-success:active {
  border-color: var(--accent-color-v4-70);
}
.btn-outlined.btn-danger {
  color: var(--danger-color);
  border-color: var(--danger-color);
}
.btn-outlined.btn-danger:hover {
  border-color: var(--accent-color-v5-50);
}
.btn-outlined.btn-danger:active {
  border-color: var(--accent-color-v5-70);
}

.btn-round {
  width: 3rem;
  height: 3rem;
  border-radius: 50%;
}
.btn-round.btn-large {
  width: 4.5rem;
  height: 4.5rem;
}
.btn-round.btn-small {
  width: math-div(3rem, 1.5);
  height: math-div(3rem, 1.5);
}

.btn-long {
  padding: 1rem 3rem;
}

.btn-small {
  font-size: var(--h6-size);
  padding: 0.8rem;
  text-transform: capitalize;
}
.btn-small.btn-long {
  padding: 0.8rem 2.4rem;
}

.btn-large {
  font-size: var(--h3-size);
  padding: 1.2rem;
  text-transform: capitalize;
}
.btn-large.btn-long {
  padding: 1.2rem 3.6rem;
}

.btn-icon [class^=icon-], .btn-icon [class*=" icon-"] {
  font-size: 1.6rem;
}
.btn-icon.btn-large [class^=icon-], .btn-icon.btn-large [class*=" icon-"] {
  font-size: var(--h3-size);
}
.btn-icon.btn-small [class^=icon-], .btn-icon.btn-small [class*=" icon-"] {
  font-size: var(--h5-size);
}

.btn-sharp {
  border-radius: 0;
}

.btn-disabled {
  cursor: default;
  opacity: 0.5;
}

html.can-touch .tappable:hover {
  background: none;
  color: var(--default-font-color);
}
html.can-touch .btn:hover {
  background: var(--primary-color);
  color: var(--light-font-color);
}
html.can-touch .btn-primary:hover {
  background: var(--primary-color);
}
html.can-touch .btn-secondary:hover {
  background: var(--secondary-color);
}
html.can-touch .btn-success:hover {
  background: var(--success-color);
}
html.can-touch .btn-danger:hover {
  background: var(--danger-color);
}
html.can-touch .btn-inverted:hover {
  background: none !important;
  color: var(--primary-color);
}</style><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.chip {
  display: inline-flex;
  border-radius: 1.5rem;
  color: var(--dark-font-color);
  padding: 0.5rem 1.5rem;
  align-items: center;
}
.chip__icon--left {
  margin-right: 1rem;
  padding: 0;
  padding: initial;
}
.chip__icon--right {
  margin-left: 1rem;
  padding: 0;
  padding: initial;
}
.chip--primary {
  background-color: var(--primary-color);
  color: var(--light-font-color);
}
.chip--warning {
  background-color: var(--warning-color);
  color: var(--light-font-color);
}
.chip--success {
  background-color: var(--success-color);
  color: var(--light-font-color);
}
.chip--attention {
  background-color: var(--danger-color);
  color: var(--light-font-color);
}
.chip--danger {
  background-color: var(--danger-color);
  color: var(--light-font-color);
}
.chip--hint {
  color: var(--light-font-color);
}
.chip--outlined {
  background-color: transparent !important;
  background-color: initial !important;
  border-width: 0.1rem;
  border-style: solid;
}
.chip--outlined.chip--default {
  color: var(--light-font-color);
  border-color: var(--light-font-color);
}
.chip--outlined.chip--primary {
  color: var(--primary-color);
  border-color: var(--primary-color);
}
.chip--outlined.chip--warning {
  color: var(--warning-color);
  border-color: var(--warning-color);
}
.chip--outlined.chip--success {
  color: var(--success-color);
  border-color: var(--success-color);
}
.chip--outlined.chip--attention {
  border-color: var(--danger-color);
  color: var(--danger-color);
}
.chip--outlined.chip--danger {
  border-color: var(--danger-color);
  color: var(--danger-color);
}</style><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.popover {
  position: absolute;
  z-index: 99;
  background-color: #ffffff;
  border-radius: var(--border-radius);
  box-shadow: hsla(var(--H-neutral-scale-14), var(--S-neutral-scale-14), var(--L-neutral-scale-14), 0.1) 0.1rem 0.2rem 0.2rem 0.1rem;
}</style><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.dropdown__title {
  overflow: hidden;
}
.dropdown__popover {
  display: flex;
  flex-direction: column;
  border: 0.1rem solid var(--default-border-color);
  background-color: var(--body-background-color);
  padding: 0.5rem 0;
}

.dropdown-item {
  display: flex;
  align-items: center;
  justify-content: flex-start;
  padding: 1rem;
}</style><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/c38cfb72be958f59.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/86b64921117a2b6e.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/fa5b1fc18654baac.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/814103971aaa9697.css" crossorigin="anonymous"><style data-react-tooltip="true">.__react_component_tooltip {
  border-radius: 3px;
  display: inline-block;
  font-size: 13px;
  left: -999em;
  opacity: 0;
  position: fixed;
  pointer-events: none;
  transition: opacity 0.3s ease-out;
  top: -999em;
  visibility: hidden;
  z-index: 999;
}
.__react_component_tooltip.allow_hover, .__react_component_tooltip.allow_click {
  pointer-events: auto;
}
.__react_component_tooltip::before, .__react_component_tooltip::after {
  content: "";
  width: 0;
  height: 0;
  position: absolute;
}
.__react_component_tooltip.show {
  opacity: 0.9;
  margin-top: 0;
  margin-left: 0;
  visibility: visible;
}
.__react_component_tooltip.place-top::before {
  bottom: 0;
  left: 50%;
  margin-left: -11px;
}
.__react_component_tooltip.place-bottom::before {
  top: 0;
  left: 50%;
  margin-left: -11px;
}
.__react_component_tooltip.place-left::before {
  right: 0;
  top: 50%;
  margin-top: -9px;
}
.__react_component_tooltip.place-right::before {
  left: 0;
  top: 50%;
  margin-top: -9px;
}
.__react_component_tooltip .multi-line {
  display: block;
  padding: 2px 0;
  text-align: center;
}</style><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/1d4c51259890e610.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/37b21d37e859bc7c.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/6d044fd6a28a7823.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/4d4434aa48da3dad.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/203b6633826168d2.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/8b9bd2f5f33b0836.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/4f5a94eb8e5dc392.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/2869c9365d9adbf4.css" crossorigin="anonymous"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/3994-895482d2e2657865.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/5049-ac51a78de419d9da.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/9905-1f7f62f3025bd875.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/8711-a8a944e595246ec4.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/9488-838167c018c56d9f.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/courses-6a7686cb76b86aed.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/5751-cd49377b10bfe86a.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/7002-248601e3219a55a2.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/2376-932492b0bf0c64ca.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/events-d4e3b462905d7987.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/2068-d8c544d17117635f.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/5332-8c504931a49893a4.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/index-77106070fc47187b.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/hubs-67d6286f11606b47.js.download"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/3b05454c6474bcd8.css" crossorigin="anonymous"><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.horizontal-scroll-view {
  position: relative;
  width: 100%;
}
.horizontal-scroll-view__items {
  -ms-overflow-style: none;
  scrollbar-width: none;
  overflow-x: auto;
  display: flex;
}
.horizontal-scroll-view__items::-webkit-scrollbar {
  display: none;
}
.horizontal-scroll-view__itemsFlexStart {
  justify-content: flex-start;
}
.horizontal-scroll-view__control {
  position: absolute;
  top: 50%;
  transform: translateY(-50%);
}
.horizontal-scroll-view__control--left {
  left: 1rem;
}
.horizontal-scroll-view__control--right {
  right: 1rem;
}</style><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/6edf5f20c504d6a4.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/21f158369a4332cf.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/cef82f914f5d3e25.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/0c0bb900abcfab16.css" crossorigin="anonymous"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/a1943317d825308b.css" crossorigin="anonymous"><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.tooltip {
  background-color: var(--body-background-color);
  display: block;
  color: var(--neutral-scale-0);
  padding: 0.5rem 1rem;
  font-size: var(--h5-size);
  padding-right: 3rem;
  position: absolute;
  box-shadow: hsla(var(--H-neutral-scale-14), var(--S-neutral-scale-14), var(--L-neutral-scale-14), 0.1) 0.1rem 0.2rem 0.2rem 0.1rem;
}
.tooltip .arrow {
  position: absolute;
  display: none;
  width: 0;
  border: 0.5rem solid transparent;
}
.tooltip .arrow.top {
  display: block;
  left: 50%;
  top: 0;
  border-top: 0;
  border-bottom: 0.5rem solid var(--body-background-color);
  transform: translate(-50%, -100%);
}
.tooltip .arrow.bottom {
  display: block;
  left: 50%;
  bottom: 0;
  border-bottom: 0;
  border-top: 0.5rem solid var(--body-background-color);
  transform: translate(-50%, 100%);
}
.tooltip .arrow.left {
  display: block;
  left: 0;
  top: 50%;
  border-left: 0;
  border-right: 0.5rem solid var(--body-background-color);
  transform: translate(-100%, -50%);
}
.tooltip .arrow.right {
  display: block;
  right: 0;
  top: 50%;
  border-right: 0;
  border-left: 0.5rem solid var(--body-background-color);
  transform: translate(100%, -50%);
}</style><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/a57386affd58c272.css" crossorigin="anonymous"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/9968-45414fbb2e36aa31.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/3667-95fcc7986e605aea.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/1008-e6827334234282ce.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/2619-f1af377491843fe8.js.download"><link as="script" rel="prefetch" crossorigin="anonymous" href="./Skip-Gram Model in NLP - Scaler Topics_files/[slug]-eb2d9f7a11bd706d.js.download"><link rel="stylesheet" type="text/css" href="./Skip-Gram Model in NLP - Scaler Topics_files/e628b23af4e45c8e.css" crossorigin="anonymous"><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.progressbar {
  display: flex;
  justify-content: space-between;
  border: 0.1rem solid var(--default-border-color);
  border-radius: 0.8rem;
  background-color: var(--body-background-color);
  height: 1.7rem;
  position: relative;
}
.progressbar__checkpoint {
  position: absolute;
}
.progressbar__checkpoint-wrapper {
  display: flex;
  flex-direction: column;
  font-size: var(--h6-size);
}
.progressbar__checkpoint-wrapper span {
  margin-left: -0.5rem;
}
.progressbar__checkpoint-icon {
  width: 3rem;
  margin-top: -0.5rem;
}
.progressbar__checkpoint-text {
  white-space: nowrap;
  transform: translateX(-35%);
}
.progressbar__checkpoint-mark {
  width: 0.1rem;
  height: 2.5rem;
  background-color: var(--neutral-scale-12);
}
.progressbar__color {
  text-align: right;
  border-radius: 0.8rem;
  padding-right: 0.7rem;
  background-color: var(--accent-color-v2-60);
  font-size: var(--h6-size);
  color: var(--light-font-color);
}
.progressbar__limit {
  font-size: var(--h6-size);
  padding-right: 0.5rem;
}

.width-percent {
  padding-right: 0.5rem;
}</style><style type="text/css">/* Z-indexes */
/* Theme related mixins */
/* Other mixins */
/* Primary Colors */
/* Secondary Colors */
/* Accent V1 Colors */
/* Accent V2 Colors */
/* Accent V3 Colors */
/* Accent V4 Colors */
/* Accent V5 Colors */
/* Accent V6 Colors */
/* Neutral Colors */
/* Main Colors */
/* Family */
/* Size */
/* Weight */
/* Paragraph */
/* Paragraph Line Height */
/* Spacing */
/* Others */
/* Aliases */
.l-logo-spinner {
  position: relative;
}
.l-logo-spinner__spinner {
  border: 0.2rem solid var(--neutral-scale-1);
  border-radius: 50%;
  border-top: 0.2rem solid var(--secondary-color-60);
  background-color: transparent;
  width: 10rem;
  height: 10rem;
  animation: spin 2s linear infinite;
}
@media screen and (max-width: 480px) {
  .l-logo-spinner__spinner {
    width: 5rem;
    height: 5rem;
  }
}
.l-logo-spinner__logo {
  position: absolute;
  height: 4rem;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
}
@media screen and (max-width: 480px) {
  .l-logo-spinner__logo {
    height: 2rem;
  }
}
.l-logo-spinner--small .l-logo-spinner__spinner {
  width: 5rem;
  height: 5rem;
}
.l-logo-spinner--small .l-logo-spinner__logo {
  height: 2rem;
}</style><meta http-equiv="origin-trial" content="A+N5HpM5gDAUeupaWw3J2yuMrpgH0IC7KtFHAqtmHkW8Vr+dPpJWuOpMNIRh3ybxyoIUKlvDQs7+VGPfYdQ/qQUAAABxeyJvcmlnaW4iOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb206NDQzIiwiZmVhdHVyZSI6IkZlZENtQXV0b1JlYXV0aG4iLCJleHBpcnkiOjE2OTE1MzkxOTksImlzVGhpcmRQYXJ0eSI6dHJ1ZX0="><link id="googleidentityservice" type="text/css" media="all" rel="stylesheet" href="./Skip-Gram Model in NLP - Scaler Topics_files/style"><style id="googleidentityservice_button_styles">.qJTHM{-webkit-user-select:none;color:#202124;direction:ltr;-webkit-touch-callout:none;font-family:"Roboto-Regular",arial,sans-serif;-webkit-font-smoothing:antialiased;font-weight:400;margin:0;overflow:hidden;-webkit-text-size-adjust:100%}.ynRLnc{left:-9999px;position:absolute;top:-9999px}.L6cTce{display:none}.bltWBb{word-break:break-all}.hSRGPd{color:#1a73e8;cursor:pointer;font-weight:500;text-decoration:none}.Bz112c-W3lGp{height:16px;width:16px}.Bz112c-E3DyYd{height:20px;width:20px}.Bz112c-r9oPif{height:24px;width:24px}.Bz112c-uaxL4e{-webkit-border-radius:10px;border-radius:10px}.LgbsSe-Bz112c{display:block}.S9gUrf-YoZ4jf,.S9gUrf-YoZ4jf *{border:none;margin:0;padding:0}.fFW7wc-ibnC6b>.aZ2wEe>div{border-color:#4285f4}.P1ekSe-ZMv3u>div:nth-child(1){background-color:#1a73e8!important}.P1ekSe-ZMv3u>div:nth-child(2),.P1ekSe-ZMv3u>div:nth-child(3){background-image:linear-gradient(to right,rgba(255,255,255,.7),rgba(255,255,255,.7)),linear-gradient(to right,#1a73e8,#1a73e8)!important}.haAclf{display:inline-block}.nsm7Bb-HzV7m-LgbsSe{-webkit-border-radius:4px;border-radius:4px;-webkit-box-sizing:border-box;box-sizing:border-box;-webkit-transition:background-color .218s,border-color .218s;transition:background-color .218s,border-color .218s;-webkit-user-select:none;-webkit-appearance:none;background-color:#fff;background-image:none;border:1px solid #dadce0;color:#3c4043;cursor:pointer;font-family:"Google Sans",arial,sans-serif;font-size:14px;height:40px;letter-spacing:0.25px;outline:none;overflow:hidden;padding:0 12px;position:relative;text-align:center;vertical-align:middle;white-space:nowrap;width:auto}@media screen and (-ms-high-contrast:active){.nsm7Bb-HzV7m-LgbsSe{border:2px solid windowText;color:windowText}}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe{font-size:14px;height:32px;letter-spacing:0.25px;padding:0 10px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe{font-size:11px;height:20px;letter-spacing:0.3px;padding:0 8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe{padding:0;width:40px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe{width:32px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe{width:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK{-webkit-border-radius:20px;border-radius:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.pSzOP-SxQuSe{-webkit-border-radius:16px;border-radius:16px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.purZT-SxQuSe{-webkit-border-radius:10px;border-radius:10px}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc{border:none;color:#fff}.nsm7Bb-HzV7m-LgbsSe.MFS4be-v3pZbf-Ia7Qfc{background-color:#1a73e8}.nsm7Bb-HzV7m-LgbsSe.MFS4be-JaPV2b-Ia7Qfc{background-color:#202124;color:#e8eaed}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:18px;margin-right:8px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:14px;min-width:14px;width:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:10px;min-width:10px;width:10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin-left:8px;margin-right:-4px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:10px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:4px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:3px;border-top-left-radius:3px;-webkit-border-bottom-left-radius:3px;border-bottom-left-radius:3px;display:-webkit-box;display:-webkit-flex;display:flex;justify-content:center;-webkit-align-items:center;align-items:center;background-color:#fff;height:36px;margin-left:-10px;margin-right:12px;min-width:36px;width:36px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c,.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:28px;margin-left:-8px;margin-right:10px;min-width:28px;width:28px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:16px;margin-left:-6px;margin-right:8px;min-width:16px;width:16px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:3px;border-radius:3px;margin-left:2px;margin-right:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:14px;border-radius:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:8px;border-radius:8px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-bN97Pc-sM5MNb{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;-webkit-flex-direction:row;flex-direction:row;justify-content:space-between;-webkit-flex-wrap:nowrap;flex-wrap:nowrap;height:100%;position:relative;width:100%}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX{justify-content:center}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:1;flex-grow:1;font-family:"Google Sans",arial,sans-serif;font-weight:500;overflow:hidden;text-overflow:ellipsis;vertical-align:top}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-weight:300}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:0;flex-grow:0}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-MJoBVe{-webkit-transition:background-color .218s;transition:background-color .218s;bottom:0;left:0;position:absolute;right:0;top:0}.nsm7Bb-HzV7m-LgbsSe:hover,.nsm7Bb-HzV7m-LgbsSe:focus{-webkit-box-shadow:none;box-shadow:none;border-color:#d2e3fc;outline:none}.nsm7Bb-HzV7m-LgbsSe:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,.04)}.nsm7Bb-HzV7m-LgbsSe:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,.1)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,.24)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,.32)}.nsm7Bb-HzV7m-LgbsSe .n1UuX-DkfjY{-webkit-border-radius:50%;border-radius:50%;display:-webkit-box;display:-webkit-flex;display:flex;height:20px;margin-left:-4px;margin-right:8px;min-width:20px;width:20px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-family:"Roboto";font-size:12px;text-align:left}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .ssJRIf,.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .fmcmS{overflow:hidden;text-overflow:ellipsis}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;color:#5f6368;fill:#5f6368;font-size:11px;font-weight:400}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.MFS4be-Ia7Qfc .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{color:#e8eaed;fill:#e8eaed}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .Bz112c{height:18px;margin:-3px -3px -3px 2px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:0;border-top-left-radius:0;-webkit-border-bottom-left-radius:0;border-bottom-left-radius:0;-webkit-border-top-right-radius:3px;border-top-right-radius:3px;-webkit-border-bottom-right-radius:3px;border-bottom-right-radius:3px;margin-left:12px;margin-right:-10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.L5Fo6c-sM5MNb{border:0;display:block;left:0;position:relative;top:0}.L5Fo6c-bF1uUb{-webkit-border-radius:4px;border-radius:4px;bottom:0;cursor:pointer;left:0;position:absolute;right:0;top:0}.L5Fo6c-bF1uUb:focus{border:none;outline:none}sentinel{}</style></head><body data-new-gr-c-s-check-loaded="14.1129.0" data-gr-ext-installed="" data-new-gr-c-s-loaded="14.1129.0"><div id="__next"><div class="__className_fea366 full-height column"><div class="Header_header_container__uchwV header_items_headerContainer__Ea7gR articleLayout"><div class="Header_header__links__KRM32"><div class="Header_links_container__4fhhe row sr-container"><div class="row flex-ac"><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><a class="Tappable-module_root__N7ll5 Header_link_item__Jeq_c Header_hide_above_tablet__YBTTX" target="_blank"><div class="Header_exp_scaler_link__nl8_2 Header_exp_scaler__idDAV"><span class="m-r-xxs">Experience</span><img src="./Skip-Gram Model in NLP - Scaler Topics_files/scalerLogoWhite.svg" alt="Scaler" height="8" width="60" loading="lazy"></div></a></div><a href="https://www.scaler.com/?utm_source=topics" class="Header_link_item__Jeq_c Header_hide_below_desktop__JfhVe" target="_blank"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/scalerLogoWhite.svg" alt="Scaler" height="8" width="60" loading="lazy"></a><div class="Header_item_separator__qyfwr"></div></div><div class="row flex-ac"><a href="https://www.scaler.com/academy/?utm_source=topics" class="Header_link_item__Jeq_c" target="_blank">Academy</a><div class="Header_item_separator__qyfwr"></div></div><div class="row flex-ac"><a href="https://www.scaler.com/data-science-course/?utm_source=topics" class="Header_link_item__Jeq_c" target="_blank">Data Science</a><div class="Header_item_separator__qyfwr"></div></div><div class="row flex-ac"><a href="https://www.scaler.com/neovarsity/?utm_source=topics" class="Header_link_item__Jeq_c" target="_blank">Neovarsity</a></div></div></div><div class="Header_header__scmTs sr-container"><div class="Header_header__branding__lJ8b8"><a class="header__logo Header_logo__YtLXM" href="https://www.scaler.com/topics/"><img class="Header_header__logo_img__Uiby_ show-in-tablet" src="./Skip-Gram Model in NLP - Scaler Topics_files/topic_logo.svg" alt="Scaler Topics Logo" width="32" height="32"><img loading="lazy" class="Header_header__logo_img__Uiby_ hide-in-tablet" src="./Skip-Gram Model in NLP - Scaler Topics_files/ScalerTopics_Logo.svg" alt="Scaler Topics Logo" height="64" width="120"></a></div><div class="Header_middle_items__oV5uq header_items_middleItem__6JSjC"><div class="full-width Header_header__content__8w1ZO"><div class="header_items_headItems__qhL4j"><div class="header_items_headLinks__y1htd"><div><div class="dropdown"><a class="tappable dropdown__title header_items_header_title__y_fDv"><div class="header_items_header_middle_item__Pyg_d"><span class="m-r-5">Topics</span><svg fill="currentColor" class="icons_icon_chevron__cl99H icons_icon_chevron__down__hhjJu header_items_dropdown_icon__F__ut hide-in-mobile" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M9.875 20.563l-1.875-1.875 8-8 8 8-1.875 1.875-6.125-6.125z"></path></svg></div></a></div></div><div><div class="dropdown"><a class="tappable dropdown__title header_items_header_title__y_fDv"><div class="header_items_header_middle_item__Pyg_d"><span class="m-r-5">Explore</span><svg fill="currentColor" class="icons_icon_chevron__cl99H icons_icon_chevron__down__hhjJu header_items_dropdown_icon__F__ut hide-in-mobile" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M9.875 20.563l-1.875-1.875 8-8 8 8-1.875 1.875-6.125-6.125z"></path></svg></div></a></div></div><a data-id="header-item" class="header_items_header_middle_item__Pyg_d" role="link" tabindex="0" href="https://www.scaler.com/topics/courses/">Courses</a><a data-id="header-item" class="header_items_header_middle_item__Pyg_d" role="link" tabindex="0" href="https://www.scaler.com/topics/events/">Events</a></div><div class="row flex-ac space-between"><div class="search_searchbarContainer__x3u_B search-bar_headSearch__9JRJh header_items_search_bar__vmysN hide-in-tablet"><div class="search_container__d1rV9 p-15"><svg fill="currentColor" class="search_search_icon__Kr9M1" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M30.243 28.489l-6.719-6.89c1.716-2.097 2.756-4.806 2.756-7.757 0-0.002 0-0.004 0-0.005v0c-0.009-6.821-5.537-12.349-12.357-12.356h-0.001c-6.821 0.009-12.347 5.535-12.356 12.355v0.001c0.007 6.821 5.535 12.349 12.355 12.358h0.001c0.002 0 0.003 0 0.005 0 2.952 0 5.66-1.040 7.779-2.774l-0.022 0.017 6.719 6.89c0.118 0.118 0.28 0.19 0.46 0.19s0.342-0.073 0.46-0.19l0.92-0.92c0.118-0.118 0.19-0.28 0.19-0.46s-0.073-0.342-0.19-0.46v0zM13.922 23.592c-5.384-0.007-9.747-4.371-9.753-9.755v-0.001c0.007-5.384 4.37-9.746 9.753-9.753h0.001c5.385 0.006 9.748 4.369 9.755 9.753v0.001c-0.006 5.385-4.37 9.749-9.755 9.755h-0.001z"></path></svg><div class="Tappable-module_root__N7ll5 search_search_btn__AjpZg" data-testid="input-id1"><span class="search_search_text__80cj0">Search for Articles, Topics</span></div></div></div></div></div></div><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><a class="Tappable-module_root__N7ll5 Header_link_item__Jeq_c" target="_blank"><div class="Header_exp_scaler_link__nl8_2 Header_exp_scaler__idDAV hide-in-mobile show-in-tablet"><span class="m-r-xxs">Experience</span><img src="./Skip-Gram Model in NLP - Scaler Topics_files/scalerLogoWhite.svg" alt="Scaler" height="8" width="60" loading="lazy"></div></a></div><input type="button" class="Header_header_signin__H8u_q cursor hide-in-tablet" value="Sign In"><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><a class="Tappable-module_root__N7ll5 Header_exp_scaler__idDAV Header_hide_in_small_screen__rcYLc" target="_blank">Experience Scaler</a></div></div><div class="show-in-tablet show-in-tablet"><button type="button" class="header_items_hamburger_btn__xaYX0 cursor"><svg fill="currentColor" class="header_items_hamburger_icon__3lUyt" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M27.324 14.969h-22.652c-0.569 0-1.029 0.461-1.029 1.029s0.461 1.029 1.029 1.029h22.652c0.569 0 1.029-0.461 1.029-1.029s-0.461-1.029-1.029-1.029v0z"></path><path d="M4.672 8.793h22.652c0.569 0 1.029-0.461 1.029-1.029s-0.461-1.029-1.029-1.029h-22.652c-0.569 0-1.029 0.461-1.029 1.029s0.461 1.029 1.029 1.029v0z"></path><path d="M27.324 23.207h-22.652c-0.569 0-1.029 0.461-1.029 1.029s0.461 1.029 1.029 1.029h22.652c0.569 0 1.029-0.461 1.029-1.029s-0.461-1.029-1.029-1.029v0z"></path></svg></button></div></div></div><div id="g_id_onload" class="google_one_tap_container___MYf6" data-client_id="331221439469-cck96vlpggojbrd35h8ahaqkccngrsc9.apps.googleusercontent.com" data-login_uri="https://www.scaler.com/google_one_tap/" data-prompt_parent_id="g_id_onload" data-auto_prompt="false"><div id="credential_picker_container" style="position: relative; z-index: 9999; top: 0px; left: 0px; height: 250px; width: auto;"><iframe src="./Skip-Gram Model in NLP - Scaler Topics_files/select.html" title="Finestra di dialogo Accedi con Google" style="height: 250px; width: 391px; overflow: hidden;"></iframe></div></div><main class="mainContainer articlePage articleLayout"><div class="view_view_container__AUfnF"><div class="readingProgressBar_reading_bar_parent__Mo14l"><div class="reading-progress-bar readingProgressBar_reading_progress__FkzHm" style="width: 61.5017%;"></div><div class="readingProgressBar_reading_bar_container__hohPF"></div></div><div class="row flex-jc"><div class="view_left_section__zPSLG"><div class="view_main_container__Id57J view_ar_container__LNAHP"><div><div class="row"><div class="row"><div class="hide-in-tablet breadcrumb_container__HwKni view_breadcrumb_display__dKFsT"><div data-id="breadcrumb" class="breadcrumb_item__jdd_h" href="/topics/"><div data-tip="Home" data-place="bottom" currentitem="false"><svg fill="currentColor" class="breadcrumb_link_icon__28vc6 column flex-ac" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 33 32"><path d="M26.089 27.6h-5.647c-0.001 0-0.002 0-0.003 0-1.033 0-1.871-0.834-1.877-1.866v-5.657c0-0.004-0.004-0.008-0.008-0.008v0h-3.768c-0.004 0-0.008 0.004-0.008 0.008v0 5.656c-0.006 1.032-0.844 1.866-1.876 1.867h-5.652c-1.032-0.002-1.869-0.835-1.875-1.866v-10.897s0-0.011 0-0.015c0.010-0.535 0.238-1.016 0.598-1.358l0.001-0.001 0.013-0.012 9.419-8.56c0.332-0.305 0.778-0.493 1.267-0.493s0.934 0.187 1.268 0.494l-0.001-0.001 9.429 8.569c0.361 0.343 0.589 0.823 0.599 1.357l0 0.002s0 0.011 0 0.015v10.899c-0.006 1.032-0.844 1.867-1.877 1.867-0 0-0.001 0-0.001 0h0zM14.787 18.199h3.768c1.035 0.002 1.873 0.84 1.875 1.875v5.66c0 0.004 0.004 0.008 0.008 0.008v0h5.651c0.004 0 0.008-0.004 0.008-0.008v0-10.883c-0.001-0.010-0.005-0.020-0.012-0.027l0 0-9.421-8.557-9.408 8.549c-0.007 0.007-0.011 0.016-0.012 0.027v10.891c0 0.004 0.004 0.008 0.008 0.008v0h5.651c0.004 0 0.008-0.004 0.008-0.008v0-5.656c0.001-1.036 0.841-1.876 1.877-1.876v0z"></path></svg></div><div class="__react_component_tooltip td5b80311-4290-4c92-b6ad-c1bf3eb27455 place-top type-dark" id="td5b80311-4290-4c92-b6ad-c1bf3eb27455" data-id="tooltip"><style aria-hidden="true">
  	.td5b80311-4290-4c92-b6ad-c1bf3eb27455 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-top {
        margin-top: -10px;
    }
    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-bottom {
        margin-top: 10px;
    }
    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-left {
        margin-left: -10px;
    }
    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-right {
        margin-left: 10px;
    }
    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .td5b80311-4290-4c92-b6ad-c1bf3eb27455.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></div><svg fill="currentColor" class="icons_icon_chevron__cl99H icons_icon_chevron__right__YxLYH hide-in-tablet" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M9.875 20.563l-1.875-1.875 8-8 8 8-1.875 1.875-6.125-6.125z"></path></svg><div class="breadcrumb_seperator__GMDUz show-in-tablet"></div><a data-testid="breadcrumbs-id" href="https://www.scaler.com/topics/hubs/"><div data-id="breadcrumb" class="breadcrumb_item__jdd_h"><div data-tip="Reading Tracks" data-place="bottom" currentitem="false"><svg fill="currentColor" stroke="" class="breadcrumb_link_icon__28vc6 column flex-ac" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14 16.56c-0.309 0-0.56-0.251-0.56-0.56v0-12c0-0.309 0.251-0.56 0.56-0.56s0.56 0.251 0.56 0.56v10.88l3.104-2.328c0.092-0.070 0.209-0.112 0.336-0.112s0.244 0.042 0.337 0.113l-0.001-0.001 3.104 2.328v-10.88c0-0.309 0.251-0.56 0.56-0.56s0.56 0.251 0.56 0.56v12c0 0.309-0.251 0.56-0.56 0.56-0.127 0-0.244-0.042-0.337-0.113l0.001 0.001-3.664-2.748-3.664 2.748c-0.092 0.070-0.209 0.112-0.336 0.112v0z"></path><path d="M6 27.56c-0.309 0-0.56-0.251-0.56-0.56v0-20c0-0 0-0.001 0-0.001 0-0.983 0.397-1.873 1.040-2.519l-0 0c0.638-0.642 1.523-1.040 2.5-1.040 0.003 0 0.006 0 0.010 0h17.011c0.309 0 0.56 0.251 0.56 0.56v0 20c0 0.309-0.251 0.56-0.56 0.56v0h-17.013c0 0-0 0-0 0-1.337 0-2.421 1.080-2.427 2.415v0.025c0 0.309-0.251 0.56-0.56 0.56v0zM8.987 4.56c-0.002 0-0.004 0-0.007 0-0.668 0-1.273 0.272-1.71 0.711l-0 0c-0.439 0.442-0.711 1.051-0.711 1.723 0 0.001 0 0.002 0 0.003v-0 17.402c0.629-0.595 1.48-0.96 2.416-0.96 0.004 0 0.008 0 0.012 0h16.453v-18.88z"></path><path d="M24 28.56h-18c-0.309 0-0.56-0.251-0.56-0.56v0-1c0-0.309 0.251-0.56 0.56-0.56s0.56 0.251 0.56 0.56v0 0.44h17.44c0.309 0 0.56 0.251 0.56 0.56s-0.251 0.56-0.56 0.56v0z"></path></svg></div></div></a><svg fill="currentColor" class="icons_icon_chevron__cl99H icons_icon_chevron__right__YxLYH hide-in-tablet" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M9.875 20.563l-1.875-1.875 8-8 8 8-1.875 1.875-6.125-6.125z"></path></svg><div class="breadcrumb_seperator__GMDUz show-in-tablet"></div><a data-testid="breadcrumbs-id" href="https://www.scaler.com/topics/nlp/"><div data-id="breadcrumb" class="breadcrumb_item__jdd_h">NLP Tutorial</div></a><svg fill="currentColor" class="icons_icon_chevron__cl99H icons_icon_chevron__right__YxLYH hide-in-tablet breadcrumb_isLastSeparator__nSYW7" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M9.875 20.563l-1.875-1.875 8-8 8 8-1.875 1.875-6.125-6.125z"></path></svg><div class="breadcrumb_seperator__GMDUz show-in-tablet breadcrumb_isLastSeparator__nSYW7"></div><div data-id="breadcrumb" class="breadcrumb_item__jdd_h breadcrumb_isLast__v_LIa breadcrumb_title_display__TIbaq">Skip-Gram Model in NLP</div></div><div class="show-in-tablet breadcrumb_mobile_container__JPiqx view_breadcrumb_display__dKFsT"><div class="row flex-ac" aria-hidden="true"><svg fill="currentColor" class="icons_icon_chevron__cl99H icons_icon_chevron__left__TwvkN breadcrumb_back_icon__a6Usx" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M9.875 20.563l-1.875-1.875 8-8 8 8-1.875 1.875-6.125-6.125z"></path></svg><div class="breadcrumb_title_display__TIbaq">Skip-Gram Model in NLP</div></div></div></div><div class="shareButton_share__Vm9x8 shareButton_buttonHover__AmSQt"><svg fill="currentColor" class="" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M8 11.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM8 19.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M22 20.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM22 28.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M22 2.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM22 10.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M11.364 14.505c-0 0-0 0-0 0-0.234 0-0.441-0.121-0.56-0.304l-0.002-0.003c-0.066-0.102-0.106-0.227-0.106-0.361 0-0.234 0.121-0.44 0.303-0.559l0.003-0.002 7.272-4.675c0.102-0.066 0.227-0.106 0.361-0.106 0.234 0 0.44 0.121 0.559 0.303l0.002 0.003c0.066 0.102 0.106 0.227 0.106 0.361 0 0.234-0.121 0.44-0.303 0.559l-0.003 0.002-7.272 4.675c-0.102 0.067-0.226 0.106-0.36 0.107h-0z"></path><path d="M18.635 23.503c-0 0-0 0-0 0-0.134 0-0.258-0.039-0.362-0.107l0.003 0.002-7.271-4.675c-0.186-0.12-0.307-0.327-0.307-0.561 0-0.134 0.039-0.258 0.107-0.363l-0.002 0.003c0.12-0.186 0.327-0.307 0.561-0.307 0.134 0 0.258 0.039 0.363 0.107l-0.003-0.002 7.272 4.675c0.186 0.12 0.307 0.327 0.307 0.561 0 0.368-0.298 0.667-0.667 0.667-0.001 0-0.001 0-0.002 0h0z"></path></svg></div></div><h1 class="view_title__pgLhk">Skip-Gram Model in NLP</h1><div class="challengePopup_popupContainer__ONoum"><div class="challengePopup_logoContainer__4XZkZ"><svg class="challengePopup_challenge_icon__2fHsv h3" fill="currentColor" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M27.503 28.803h-18c-0.994-0.001-1.799-0.806-1.8-1.8v-4.258c-0.206 0.036-0.444 0.056-0.686 0.056-0.119 0-0.237-0.005-0.353-0.014l0.015 0.001c-2.231-0.174-3.976-2.027-3.976-4.288 0-2.375 1.925-4.3 4.3-4.3 0.247 0 0.49 0.021 0.726 0.061l-0.025-0.004v-4.254c0.001-0.994 0.806-1.799 1.8-1.8h4.754c-0.037-0.211-0.058-0.454-0.058-0.702 0-2.377 1.926-4.304 4.303-4.305h0c2.374 0.002 4.298 1.927 4.298 4.302 0 0.249-0.021 0.493-0.062 0.73l0.004-0.025h4.754c0.994 0.001 1.799 0.806 1.8 1.8v5.338c-0.001 0.441-0.359 0.798-0.8 0.798-0.125 0-0.244-0.029-0.35-0.080l0.005 0.002c-0.335-0.163-0.729-0.258-1.145-0.258-0.073 0-0.146 0.003-0.218 0.009l0.009-0.001h-0.006c-1.404 0.106-2.503 1.271-2.503 2.693 0 1.491 1.209 2.7 2.7 2.7 0.423 0 0.823-0.097 1.179-0.27l-0.016 0.007c0.101-0.049 0.219-0.078 0.344-0.078 0.441 0 0.799 0.357 0.8 0.798v5.338c0 0.001 0 0.002 0 0.002 0 0.992-0.802 1.797-1.793 1.802h-0zM8.503 20.866c0.442 0 0.8 0.358 0.8 0.8v0 5.338c0 0.11 0.090 0.2 0.2 0.2v0h18c0.11 0 0.2-0.090 0.2-0.2v0-4.254c-0.21 0.037-0.453 0.057-0.7 0.057-2.375 0-4.3-1.925-4.3-4.3 0-2.261 1.745-4.114 3.961-4.287l0.015-0.001c0.101-0.009 0.219-0.013 0.338-0.013 0.242 0 0.48 0.020 0.711 0.059l-0.025-0.003v-4.258c0-0.11-0.090-0.2-0.2-0.2v0h-5.84c-0.441-0.001-0.798-0.359-0.798-0.8 0-0.125 0.029-0.243 0.080-0.349l-0.002 0.005c0.166-0.34 0.262-0.739 0.262-1.161 0-1.491-1.209-2.7-2.7-2.7-1.421 0-2.586 1.098-2.692 2.492l-0.001 0.009v0.006c-0.005 0.064-0.008 0.137-0.008 0.212 0 0.415 0.095 0.808 0.265 1.157l-0.007-0.016c0.049 0.101 0.078 0.219 0.078 0.345 0 0.441-0.357 0.799-0.798 0.8h-5.84c-0.11 0-0.2 0.090-0.2 0.2v0 5.338c-0.001 0.441-0.359 0.798-0.8 0.798-0.125 0-0.243-0.029-0.349-0.080l0.005 0.002c-0.34-0.166-0.74-0.263-1.163-0.263-1.491 0-2.7 1.209-2.7 2.7 0 1.422 1.099 2.587 2.494 2.692l0.009 0.001h0.006c0.063 0.005 0.135 0.008 0.209 0.008 0.416 0 0.81-0.095 1.161-0.265l-0.016 0.007c0.099-0.047 0.216-0.075 0.339-0.075 0.002 0 0.005 0 0.007 0h-0z"></path></svg></div><div class="challengePopup_content__RwKaC"><div class="challengePopup_content__text__753Ig"><strong>Challenge Inside! :  </strong>Find out where you stand! Try quiz, solve problems &amp; win rewards!</div><a href="https://www.scaler.com/topics/nlp/skip-gram-model/#topic-challenge-container-570512"><div class="challengePopup_content__link__Qf6Sn">Go to Challenge</div></a></div></div><div class="markdown-body"><section class="abstract"><h2 id="overview" level="2">Overview</h2><p>The skip-gram model is a method for <strong>learning word embeddings</strong>, which are continuous, dense, and low-dimensional representations of words in a vocabulary. It is trained using <strong>large amounts of unstructured text</strong> data and can <strong>capture the context</strong> and semantic similarity between words.</p></section>
<section class="main"><h2 id="introduction" level="2">Introduction</h2><p>The skip-gram model was introduced by Mikolov et al. in their paper "<a href="https://arxiv.org/abs/1301.3781" target="_blank" rel="noopener nofollow">Efficient Estimation of Word Representations in Vector Space</a>" (<span class="highlight--red">2013</span>). The skip-gram model is a way of teaching a computer to understand the <strong>meaning of words based on the context</strong> they are used in. An example would be training a computer to understand the word "dog" by looking at sentences where "dog" appears and seeing the words that come before and after it. By doing this, the computer will be able to understand how the word "dog" is commonly used and will be able to use that understanding in other ways.</p><p>Here's an example to illustrate the concept:</p><p>Let's say you have the sentence.</p><p><strong>The dog fetched the ball.</strong></p><p>If you are trying to train a skip-gram model for the word "dog", the goal of the model is to predict the context words "the" and "fetched" given the input word "dog". So, the training data for the model would be pairs of the form (input word = "dog", context word = "the"), (input word = "dog", context word = "fetched").</p></section>
<section class="main"><div class="column m-v-xs full-width"><div class="social-validation_premium_badge_container__pLCZ3 column full-width p-s"><div class="social-validation_premium_box__cb_UH"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/premium_tag.svg" alt="premium tags" layout="fixed" height="24" width="119" class="m-0" loading="lazy"><div class="full-width"><div class="social-validation_badge_text__npQpl">Explore and unlock the<img src="./Skip-Gram Model in NLP - Scaler Topics_files/scaler_logo.svg" alt="scaler logo" height="13" width="90" class="social-validation_scaler_logo__REvDY" loading="lazy">recipe to transform your career</div><div class="row full-width m-t-xs social-validation_premium_details__cGO0q"><div class="social-validation_premium_data__Djsr9 relative p-r-xxs m-r-xxs"><div class="column"><div class="social-validation_data_heading__YLZAD"><span class="bold h5">3700+</span></div><div class="social-validation_data_text__tnNOG">Placed at Google Amazon and other top tech companies</div></div></div><div class="social-validation_premium_data__Djsr9 relative p-r-xxs m-r-xxs"><div class="column"><div class="social-validation_data_heading__YLZAD"><span class="bold h5">93.5%</span> Placement Rate</div><div class="social-validation_data_text__tnNOG">21.6LPA Average salary of learners</div></div></div><div class="social-validation_premium_data__Djsr9 relative p-r-xxs m-r-xxs"><div class="column"><div class="social-validation_data_heading__YLZAD"><span class="bold h5">126%</span> average salary hike</div><div class="social-validation_data_text__tnNOG">₹900CR Salary created for Scaler graduates in last 4 years</div></div></div></div><div class="m-t-s m-b-xxs social-validation_data_heading__YLZAD">Discover &amp; <span class="bold">connect with Alumni</span> who have walked the same path as you</div><div class="horizontal-scroll-view horizontal-scroll_container__jCbjd social-validation_horizonalScrollContainer___iDqP horizontal-scroll-view__shadow-right"><div class="horizontal-scroll-view__items row full-width space-between social-validation_premium_cards__geRaF horizontal-scroll-view__itemsFlexStart" data-testid="horizontal-scroll id"><div class="premium-badge-cards_card_body__3ca3p p-xs"><div class="row"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-image_id.png" alt="Alumini image" height="48" width="48" class="premium-badge-cards_alumni_img__xnS_f" loading="lazy"><div class="column m-b-xxs"><div class="premium-badge-cards_alumni_name__c_Iao">Krishna Chaitanya</div><div class="premium-badge-cards_alumni_role__5xze2">Software Engineer III</div></div></div><div class="premium-badge-cards_alumni_company_container__rOtCx row align-c space-between p-xxs p-r-s p-l-s m-t-xxs"><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Pre-Scaler</div><div class="premium-badge-cards_company_name__MPcld">Sigmoid</div></div><svg fill="currentColor" width="32" height="8" viewBox="0 0 32 8" xmlns="http://www.w3.org/2000/svg"><path d="M31.3882 4.35355C31.5835 4.15829 31.5835 3.84171 31.3882 3.64645L28.2062 0.464466C28.011 0.269204 27.6944 0.269204 27.4991 0.464466C27.3039 0.659728 27.3039 0.976311 27.4991 1.17157L30.3276 4L27.4991 6.82843C27.3039 7.02369 27.3039 7.34027 27.4991 7.53553C27.6944 7.7308 28.011 7.7308 28.2062 7.53553L31.3882 4.35355ZM0.034668 4.5H31.0347V3.5H0.034668V4.5Z"></path></svg><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Post-Scaler</div><div class="premium-badge-cards_company_name__MPcld"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-company_logo_id.png" alt="Walmart" height="24" width="68" class="premium-badge-cards_company_logo_url__9Df67" loading="lazy"></div></div></div><div class="premium-badge-cards_hike_container__qIOjb row p-h-xxs align-c relative">200% Hike</div><div class="premium-badge-cards_review__288IA">I am a tech enthusiast now, but that was not always the case. I come from a non-tech background and used to be very unfamilia... <a href="https://www.linkedin.com/feed/update/urn:li:activity:6932710426249965571/" target="_blank" class="premium-badge-cards_read_full_review__C6r6a">Read Full Review</a></div></div><div class="premium-badge-cards_card_body__3ca3p p-xs"><div class="row"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-image_id(1).png" alt="Alumini image" height="48" width="48" class="premium-badge-cards_alumni_img__xnS_f" loading="lazy"><div class="column m-b-xxs"><div class="premium-badge-cards_alumni_name__c_Iao">Sudhanshu Gera</div><div class="premium-badge-cards_alumni_role__5xze2">Software Engineer III</div></div></div><div class="premium-badge-cards_alumni_company_container__rOtCx row align-c space-between p-xxs p-r-s p-l-s m-t-xxs"><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Pre-Scaler</div><div class="premium-badge-cards_company_name__MPcld">Wipro Limited</div></div><svg fill="currentColor" width="32" height="8" viewBox="0 0 32 8" xmlns="http://www.w3.org/2000/svg"><path d="M31.3882 4.35355C31.5835 4.15829 31.5835 3.84171 31.3882 3.64645L28.2062 0.464466C28.011 0.269204 27.6944 0.269204 27.4991 0.464466C27.3039 0.659728 27.3039 0.976311 27.4991 1.17157L30.3276 4L27.4991 6.82843C27.3039 7.02369 27.3039 7.34027 27.4991 7.53553C27.6944 7.7308 28.011 7.7308 28.2062 7.53553L31.3882 4.35355ZM0.034668 4.5H31.0347V3.5H0.034668V4.5Z"></path></svg><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Post-Scaler</div><div class="premium-badge-cards_company_name__MPcld"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-company_logo_id(1).png" alt="Walmart" height="24" width="68" class="premium-badge-cards_company_logo_url__9Df67" loading="lazy"></div></div></div><div class="premium-badge-cards_hike_container__qIOjb row p-h-xxs align-c relative">150% Hike</div><div class="premium-badge-cards_review__288IA">At the beginning, it was not the easiest of tasks to cope up with the classes but I was stern in my intent which helped me la... <a href="https://www.linkedin.com/posts/sudhanshu-gera-b2ab84116_myjourney-walmart-productbased-activity-6904752011343192064-VQ5_" target="_blank" class="premium-badge-cards_read_full_review__C6r6a">Read Full Review</a></div></div><div class="premium-badge-cards_card_body__3ca3p p-xs"><div class="row"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-image_id(2).png" alt="Alumini image" height="48" width="48" class="premium-badge-cards_alumni_img__xnS_f" loading="lazy"><div class="column m-b-xxs"><div class="premium-badge-cards_alumni_name__c_Iao">Ankit Pangasa</div><div class="premium-badge-cards_alumni_role__5xze2">Senior Software Engineer</div></div></div><div class="premium-badge-cards_alumni_company_container__rOtCx row align-c space-between p-xxs p-r-s p-l-s m-t-xxs"><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Pre-Scaler</div><div class="premium-badge-cards_company_name__MPcld">Adobe</div></div><svg fill="currentColor" width="32" height="8" viewBox="0 0 32 8" xmlns="http://www.w3.org/2000/svg"><path d="M31.3882 4.35355C31.5835 4.15829 31.5835 3.84171 31.3882 3.64645L28.2062 0.464466C28.011 0.269204 27.6944 0.269204 27.4991 0.464466C27.3039 0.659728 27.3039 0.976311 27.4991 1.17157L30.3276 4L27.4991 6.82843C27.3039 7.02369 27.3039 7.34027 27.4991 7.53553C27.6944 7.7308 28.011 7.7308 28.2062 7.53553L31.3882 4.35355ZM0.034668 4.5H31.0347V3.5H0.034668V4.5Z"></path></svg><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Post-Scaler</div><div class="premium-badge-cards_company_name__MPcld"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-company_logo_id(2).png" alt="Google" height="24" width="68" class="premium-badge-cards_company_logo_url__9Df67" loading="lazy"></div></div></div><div class="premium-badge-cards_hike_container__qIOjb row p-h-xxs align-c relative">200% Hike</div><div class="premium-badge-cards_review__288IA">Their course structure is impeccable and has truly helped me widen the horizons of my knowledge. They have truly established ... <a href="https://www.linkedin.com/posts/ankit-pangasa_coding-tech-interviews-activity-6983352812755693569-WyX8?utm_source=share&amp;utm_medium=member_desktop" target="_blank" class="premium-badge-cards_read_full_review__C6r6a">Read Full Review</a></div></div><div class="premium-badge-cards_card_body__3ca3p p-xs"><div class="row"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-image_id(3).png" alt="Alumini image" height="48" width="48" class="premium-badge-cards_alumni_img__xnS_f" loading="lazy"><div class="column m-b-xxs"><div class="premium-badge-cards_alumni_name__c_Iao">Vikas Tiwari</div><div class="premium-badge-cards_alumni_role__5xze2">Backend Developer</div></div></div><div class="premium-badge-cards_alumni_company_container__rOtCx row align-c space-between p-xxs p-r-s p-l-s m-t-xxs"><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Pre-Scaler</div><div class="premium-badge-cards_company_name__MPcld">Innefu</div></div><svg fill="currentColor" width="32" height="8" viewBox="0 0 32 8" xmlns="http://www.w3.org/2000/svg"><path d="M31.3882 4.35355C31.5835 4.15829 31.5835 3.84171 31.3882 3.64645L28.2062 0.464466C28.011 0.269204 27.6944 0.269204 27.4991 0.464466C27.3039 0.659728 27.3039 0.976311 27.4991 1.17157L30.3276 4L27.4991 6.82843C27.3039 7.02369 27.3039 7.34027 27.4991 7.53553C27.6944 7.7308 28.011 7.7308 28.2062 7.53553L31.3882 4.35355ZM0.034668 4.5H31.0347V3.5H0.034668V4.5Z"></path></svg><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Post-Scaler</div><div class="premium-badge-cards_company_name__MPcld"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-company_logo_id(3).png" alt="Make My Trip" height="24" width="68" class="premium-badge-cards_company_logo_url__9Df67" loading="lazy"></div></div></div><div class="premium-badge-cards_hike_container__qIOjb row p-h-xxs align-c relative">180% Hike</div><div class="premium-badge-cards_review__288IA">All thanks to Scaler Academy for providing such amazing learning resources which helped me to become a better engineer.... <a href="https://www.linkedin.com/feed/update/urn:li:activity:6800048178604359680/" target="_blank" class="premium-badge-cards_read_full_review__C6r6a">Read Full Review</a></div></div><div class="premium-badge-cards_card_body__3ca3p p-xs"><div class="row"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-image_id(4).png" alt="Alumini image" height="48" width="48" class="premium-badge-cards_alumni_img__xnS_f" loading="lazy"><div class="column m-b-xxs"><div class="premium-badge-cards_alumni_name__c_Iao">Abinay Bingumalla</div><div class="premium-badge-cards_alumni_role__5xze2">Full Stack</div></div></div><div class="premium-badge-cards_alumni_company_container__rOtCx row align-c space-between p-xxs p-r-s p-l-s m-t-xxs"><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Pre-Scaler</div><div class="premium-badge-cards_company_name__MPcld">Reliance Infocomm Limited</div></div><svg fill="currentColor" width="32" height="8" viewBox="0 0 32 8" xmlns="http://www.w3.org/2000/svg"><path d="M31.3882 4.35355C31.5835 4.15829 31.5835 3.84171 31.3882 3.64645L28.2062 0.464466C28.011 0.269204 27.6944 0.269204 27.4991 0.464466C27.3039 0.659728 27.3039 0.976311 27.4991 1.17157L30.3276 4L27.4991 6.82843C27.3039 7.02369 27.3039 7.34027 27.4991 7.53553C27.6944 7.7308 28.011 7.7308 28.2062 7.53553L31.3882 4.35355ZM0.034668 4.5H31.0347V3.5H0.034668V4.5Z"></path></svg><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Post-Scaler</div><div class="premium-badge-cards_company_name__MPcld"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-company_logo_id(4).png" alt="Microsoft" height="24" width="68" class="premium-badge-cards_company_logo_url__9Df67" loading="lazy"></div></div></div><div class="premium-badge-cards_hike_container__qIOjb row p-h-xxs align-c relative">112% Hike</div><div class="premium-badge-cards_review__288IA">With Scaler, I became a lot more disciplined and focused. Without their support, maybe it would have taken me a few more year... <a href="https://www.linkedin.com/posts/abinayb_gratitude-scaler-mentor-activity-6879686185539764224-awLo" target="_blank" class="premium-badge-cards_read_full_review__C6r6a">Read Full Review</a></div></div><div class="premium-badge-cards_card_body__3ca3p p-xs"><div class="row"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-image_id(5).png" alt="Alumini image" height="48" width="48" class="premium-badge-cards_alumni_img__xnS_f" loading="lazy"><div class="column m-b-xxs"><div class="premium-badge-cards_alumni_name__c_Iao">Saliq Saifi</div><div class="premium-badge-cards_alumni_role__5xze2">Senior Software Engineer</div></div></div><div class="premium-badge-cards_alumni_company_container__rOtCx row align-c space-between p-xxs p-r-s p-l-s m-t-xxs"><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Pre-Scaler</div><div class="premium-badge-cards_company_name__MPcld">Mahindra Comviva</div></div><svg fill="currentColor" width="32" height="8" viewBox="0 0 32 8" xmlns="http://www.w3.org/2000/svg"><path d="M31.3882 4.35355C31.5835 4.15829 31.5835 3.84171 31.3882 3.64645L28.2062 0.464466C28.011 0.269204 27.6944 0.269204 27.4991 0.464466C27.3039 0.659728 27.3039 0.976311 27.4991 1.17157L30.3276 4L27.4991 6.82843C27.3039 7.02369 27.3039 7.34027 27.4991 7.53553C27.6944 7.7308 28.011 7.7308 28.2062 7.53553L31.3882 4.35355ZM0.034668 4.5H31.0347V3.5H0.034668V4.5Z"></path></svg><div class="column premium-badge-cards_company_info__ANYKG"><div class="premium-badge-cards_company_header__9WjhJ">Post-Scaler</div><div class="premium-badge-cards_company_name__MPcld"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/success-story-company_logo_id(5).png" alt="Airtel" height="24" width="68" class="premium-badge-cards_company_logo_url__9Df67" loading="lazy"></div></div></div><div class="premium-badge-cards_hike_container__qIOjb row p-h-xxs align-c relative">400% Hike</div><div class="premium-badge-cards_review__288IA">The best career decision I ever made was to join Scaler by InterviewBit. I was preparing myself but couldn't get any good opp... <a href="https://www.linkedin.com/feed/update/urn:li:activity:6858336509620207616/" target="_blank" class="premium-badge-cards_read_full_review__C6r6a">Read Full Review</a></div></div></div><a class="tappable btn btn-primary btn-icon btn-round horizontal-scroll-view__control horizontal-scroll-view__control--right horizontal-scroll_scrollArrow__A0mnS social-validation_arrowClassName__qDCBG" data-direction="right"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></a></div></div><div class="row full-width m-t-xs social-validation_column_mobile__sxLBt"><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW row flex-c"><div class="signin-alert-popup_overLay__Xq3de"></div><a class="Tappable-module_root__N7ll5 social-validation_button__lRMr_ social-validation_highlight__5pznd social-validation_full_width_mobile__nj_z5 m-r-xs">Talk to Counsellor</a></div><a class="social-validation_button__lRMr_ row flex-c" href="https://www.scaler.com/review/?utm_source=topics&amp;utm_medium=social_validation" target="_blank">Read All Reviews</a></div></div></div></div><h2 id="architecture-of-skip-gram-model" level="2">Architecture of Skip-Gram Model</h2><p>The architecture of the skip-gram model consists of an <strong>input layer</strong>, an <strong>output layer</strong>, and a <strong>hidden layer</strong>. The input layer is the word to be predicted, and the output layer is the context words. The hidden layer represents the embedding of the input word learned during training. The skip-gram model uses a feedforward neural network with a single hidden layer, as shown in the diagram below:</p><p><img alt="skip gram architecture" loading="eager" width="864" height="200" decoding="async" data-nimg="1" class="markdown_image_container__jjYk1 markdown_loaded__iZ4O5" src="./Skip-Gram Model in NLP - Scaler Topics_files/skip-gram-architecture.webp" style="color: transparent; height: auto; max-width: 100%;"></p><p><strong>Input Layer --&gt; Hidden Layer --&gt; Output Layer</strong></p><p>The input and output layers are connected to the hidden layer through weights, adjusted during training to minimize the prediction error. The skip-gram model uses a <strong>negative sampling objective function</strong> to optimize the weights and learn the embeddings.</p><p>The skip-gram model is a method for learning word embeddings that captures the <strong>context and semantic similarity</strong> between words in a vocabulary. It is trained using a feedforward neural network with a single hidden layer and is widely used in NLP tasks.</p></section>
<section class="main"><h2 id="implementing-the-skip-gram-model" level="2">Implementing the Skip-gram Model</h2><p>To implement a skip-gram model for word embeddings, you will need a <strong>large corpus of text in a single language</strong> and tools for preprocessing and tokenizing the text. You can download and access the text using the <strong>Natural Language Toolkit (NLTK)</strong> library.</p><p>We can use <span class="highlight--red">TensorFlow</span> with the <strong>Keras API</strong> to build and train the model. A skip-gram generator can create training data for the model in pairs of words (the target word and the context word) and labels indicating whether the context word appears within a fixed window size of the target word in the input text.</p><p>The model architecture should include <strong>embedding layers</strong> for the target and context words and a dense layer with a <strong>sigmoid activation</strong> function to predict the probability of the context word appearing within a fixed window of the target word. The trained word embeddings can be extracted from the model once trained. The model can then be compiled with a loss function, an optimizer, and fit on the skip grams.</p><div class="article-course-widget_promotion_item_box__X2T2e article-course-widget_course_box__HFqjq"><div class="row m-b-xs"><div class="column p-r-xs"> <span class="article-course-widget_meta_info__FtcOg article-course-widget_course_info__WLsVf">Explore<span class="article-course-widget_highlighted_text___aH_L"> free courses</span> by our <span class="article-course-widget_highlighted_text___aH_L">top instructors</span></span><a class="tappable article-course-widget_view_all___L8mM" href="https://www.scaler.com/topics/courses/">View All</a></div><div class="article-course-widget_widget__9Whod"><div class="row article-course-widget_widget_container__QlWMZ"><div tabindex="0" role="button" class="desktop_widget_container__ulu9J column cursor" href="/topics/course/java-beginners/"><div class="full-width full-height relative"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/Java-master-image.webp" alt="Java Course - Mastering the Fundamentals" class="desktop_cover_img__D1FcF" loading="lazy"><div class="desktop_instructor_name__dg1Ax">Tarun Luthra</div></div><div class="p-xs desktop_meta_data__LQc4P"><span class="bold h5">Java Course - Mastering the Fundamentals</span><div class="align-c row h6"><svg fill="currentColor" class="h4" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M15.004 11.5c-2.2 0-4 1.8-4 4s1.8 4 4 4 4-1.8 4-4-1.8-4-4-4zM9.004 15.5c0-3.3 2.7-6 6-6s6 2.7 6 6-2.7 6-6 6-6-2.7-6-6z"></path><path d="M15.004 21.5c-1.5 0-2.9 0.4-4.2 1.2s-2.3 1.9-2.9 3.2c-0.3 0.5-0.9 0.7-1.3 0.4-0.6-0.2-0.8-0.8-0.5-1.3 0.8-1.6 2.1-3 3.7-4s3.4-1.5 5.2-1.5c1.8 0 3.7 0.5 5.2 1.5 1.6 1 2.8 2.3 3.7 4 0.2 0.5 0.1 1.1-0.4 1.3s-1.1 0.1-1.3-0.4c-0.7-1.3-1.7-2.4-2.9-3.2-1.4-0.8-2.8-1.2-4.3-1.2z"></path><path d="M15.004 29.5c-0.8 0-1.7-0.1-2.5-0.3-2.5-0.5-4.8-1.7-6.7-3.6-1.8-1.7-3-4-3.5-6.6-0.6-2.5-0.3-5.1 0.7-7.5s2.6-4.4 4.8-5.8c2.1-1.4 4.6-2.2 7.2-2.2 0.7 0 1.4 0.1 2 0.2 0.5 0.1 0.9 0.6 0.8 1.1s-0.6 0.9-1.1 0.8c-0.6-0.1-1.1-0.1-1.7-0.1-2.2 0-4.3 0.6-6.1 1.9-1.8 1.2-3.2 2.9-4.1 4.9s-1.1 4.2-0.6 6.4c0.4 2.1 1.5 4.1 3 5.6s3.5 2.6 5.6 3c2.1 0.4 4.3 0.2 6.4-0.6 2-0.8 3.7-2.2 4.9-4.1 1.2-1.8 1.9-3.9 1.9-6.1 0-1.3-0.2-2.5-0.6-3.7-0.2-0.5 0.1-1.1 0.6-1.3s1.1 0.1 1.3 0.6c0.5 1.4 0.8 2.9 0.7 4.3 0 2.6-0.8 5.1-2.2 7.2s-3.5 3.8-5.8 4.8c-1.6 0.8-3.3 1.1-5 1.1z"></path><path d="M29.704 2.8c0.4 0.4 0.4 1 0 1.4l-4.7 5c-0.2 0.2-0.5 0.3-0.7 0.3-0.3 0-0.5-0.1-0.7-0.3l-2.3-2.5c-0.4-0.4-0.4-1 0-1.4s1-0.4 1.4 0l1.6 1.7 3.9-4.2c0.4-0.4 1.1-0.4 1.5 0z"></path></svg><span class="p-l-5">79k+ enrolled</span></div></div></div><div tabindex="0" role="button" class="desktop_widget_container__ulu9J column cursor" href="/topics/course/python-for-beginners/"><div class="full-width full-height relative"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_pybeg.webp" alt="Python Course for Beginners With Certification: Mastering the Essentials" class="desktop_cover_img__D1FcF" loading="lazy"><div class="desktop_instructor_name__dg1Ax">Rahul Janghu</div></div><div class="p-xs desktop_meta_data__LQc4P"><span class="bold h5">Python Course for Beginners With Certification: Mastering the Essentials</span><div class="align-c row h6"><svg fill="currentColor" class="h4" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M15.004 11.5c-2.2 0-4 1.8-4 4s1.8 4 4 4 4-1.8 4-4-1.8-4-4-4zM9.004 15.5c0-3.3 2.7-6 6-6s6 2.7 6 6-2.7 6-6 6-6-2.7-6-6z"></path><path d="M15.004 21.5c-1.5 0-2.9 0.4-4.2 1.2s-2.3 1.9-2.9 3.2c-0.3 0.5-0.9 0.7-1.3 0.4-0.6-0.2-0.8-0.8-0.5-1.3 0.8-1.6 2.1-3 3.7-4s3.4-1.5 5.2-1.5c1.8 0 3.7 0.5 5.2 1.5 1.6 1 2.8 2.3 3.7 4 0.2 0.5 0.1 1.1-0.4 1.3s-1.1 0.1-1.3-0.4c-0.7-1.3-1.7-2.4-2.9-3.2-1.4-0.8-2.8-1.2-4.3-1.2z"></path><path d="M15.004 29.5c-0.8 0-1.7-0.1-2.5-0.3-2.5-0.5-4.8-1.7-6.7-3.6-1.8-1.7-3-4-3.5-6.6-0.6-2.5-0.3-5.1 0.7-7.5s2.6-4.4 4.8-5.8c2.1-1.4 4.6-2.2 7.2-2.2 0.7 0 1.4 0.1 2 0.2 0.5 0.1 0.9 0.6 0.8 1.1s-0.6 0.9-1.1 0.8c-0.6-0.1-1.1-0.1-1.7-0.1-2.2 0-4.3 0.6-6.1 1.9-1.8 1.2-3.2 2.9-4.1 4.9s-1.1 4.2-0.6 6.4c0.4 2.1 1.5 4.1 3 5.6s3.5 2.6 5.6 3c2.1 0.4 4.3 0.2 6.4-0.6 2-0.8 3.7-2.2 4.9-4.1 1.2-1.8 1.9-3.9 1.9-6.1 0-1.3-0.2-2.5-0.6-3.7-0.2-0.5 0.1-1.1 0.6-1.3s1.1 0.1 1.3 0.6c0.5 1.4 0.8 2.9 0.7 4.3 0 2.6-0.8 5.1-2.2 7.2s-3.5 3.8-5.8 4.8c-1.6 0.8-3.3 1.1-5 1.1z"></path><path d="M29.704 2.8c0.4 0.4 0.4 1 0 1.4l-4.7 5c-0.2 0.2-0.5 0.3-0.7 0.3-0.3 0-0.5-0.1-0.7-0.3l-2.3-2.5c-0.4-0.4-0.4-1 0-1.4s1-0.4 1.4 0l1.6 1.7 3.9-4.2c0.4-0.4 1.1-0.4 1.5 0z"></path></svg><span class="p-l-5">69k+ enrolled</span></div></div></div><div tabindex="0" role="button" class="desktop_widget_container__ulu9J column cursor" href="/topics/course/cpp-beginners/"><div class="full-width full-height relative"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/cpp_card_master.webp" alt="C++ Course: Learn the Essentials" class="desktop_cover_img__D1FcF" loading="lazy"><div class="desktop_instructor_name__dg1Ax">Prateek Narang</div></div><div class="p-xs desktop_meta_data__LQc4P"><span class="bold h5">C++ Course: Learn the Essentials</span><div class="align-c row h6"><svg fill="currentColor" class="h4" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M15.004 11.5c-2.2 0-4 1.8-4 4s1.8 4 4 4 4-1.8 4-4-1.8-4-4-4zM9.004 15.5c0-3.3 2.7-6 6-6s6 2.7 6 6-2.7 6-6 6-6-2.7-6-6z"></path><path d="M15.004 21.5c-1.5 0-2.9 0.4-4.2 1.2s-2.3 1.9-2.9 3.2c-0.3 0.5-0.9 0.7-1.3 0.4-0.6-0.2-0.8-0.8-0.5-1.3 0.8-1.6 2.1-3 3.7-4s3.4-1.5 5.2-1.5c1.8 0 3.7 0.5 5.2 1.5 1.6 1 2.8 2.3 3.7 4 0.2 0.5 0.1 1.1-0.4 1.3s-1.1 0.1-1.3-0.4c-0.7-1.3-1.7-2.4-2.9-3.2-1.4-0.8-2.8-1.2-4.3-1.2z"></path><path d="M15.004 29.5c-0.8 0-1.7-0.1-2.5-0.3-2.5-0.5-4.8-1.7-6.7-3.6-1.8-1.7-3-4-3.5-6.6-0.6-2.5-0.3-5.1 0.7-7.5s2.6-4.4 4.8-5.8c2.1-1.4 4.6-2.2 7.2-2.2 0.7 0 1.4 0.1 2 0.2 0.5 0.1 0.9 0.6 0.8 1.1s-0.6 0.9-1.1 0.8c-0.6-0.1-1.1-0.1-1.7-0.1-2.2 0-4.3 0.6-6.1 1.9-1.8 1.2-3.2 2.9-4.1 4.9s-1.1 4.2-0.6 6.4c0.4 2.1 1.5 4.1 3 5.6s3.5 2.6 5.6 3c2.1 0.4 4.3 0.2 6.4-0.6 2-0.8 3.7-2.2 4.9-4.1 1.2-1.8 1.9-3.9 1.9-6.1 0-1.3-0.2-2.5-0.6-3.7-0.2-0.5 0.1-1.1 0.6-1.3s1.1 0.1 1.3 0.6c0.5 1.4 0.8 2.9 0.7 4.3 0 2.6-0.8 5.1-2.2 7.2s-3.5 3.8-5.8 4.8c-1.6 0.8-3.3 1.1-5 1.1z"></path><path d="M29.704 2.8c0.4 0.4 0.4 1 0 1.4l-4.7 5c-0.2 0.2-0.5 0.3-0.7 0.3-0.3 0-0.5-0.1-0.7-0.3l-2.3-2.5c-0.4-0.4-0.4-1 0-1.4s1-0.4 1.4 0l1.6 1.7 3.9-4.2c0.4-0.4 1.1-0.4 1.5 0z"></path></svg><span class="p-l-5">41k+ enrolled</span></div></div></div></div></div></div><div class="row space-between"><span class="article-course-widget_learner_info__3k8vr"><span class="article-course-widget_learner_info_count__YOXa_">35,262+</span>  learners have attended these Courses.</span><div class="row"><a class="tappable disabled article-course-widget_arrow_class__8sYn6" data-direction="left"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__left__SCnEL" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></a><a class="tappable article-course-widget_active_arrow_class__lFmjM article-course-widget_arrow_class__8sYn6" data-direction="right"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></a></div></div></div><h3 id="build-the-corpus-vocabulary" level="3">Build the Corpus Vocabulary</h3><p>Let's preprocess the text of the Bible to create a vocabulary of words that we will use to train the word embedding model. This includes <strong>removing punctuation and numbers</strong>, <strong>lowercasing</strong> all the words, and <strong>filtering out empty strings</strong> and lines with fewer than three words.</p><p>Calculate the vocabulary size and the size of the embeddings, which is the length of the dense vector representation of each word. Create a <strong>tokenizer</strong> and fit it on the normalized text, and create mappings from words to ids and vice versa.</p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-python" style="white-space: pre;"><span style="color: rgb(249, 38, 114);">import</span><span> nltk
</span><span>nltk.download(</span><span style="color: rgb(152, 195, 121);">'punkt'</span><span>)
</span><span></span><span style="color: rgb(249, 38, 114);">import</span><span> tensorflow </span><span style="color: rgb(249, 38, 114);">as</span><span> tf
</span><span></span><span style="color: rgb(249, 38, 114);">from</span><span> nltk.corpus </span><span style="color: rgb(249, 38, 114);">import</span><span> gutenberg
</span><span></span><span style="color: rgb(249, 38, 114);">from</span><span> string </span><span style="color: rgb(249, 38, 114);">import</span><span> punctuation
</span><span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># import tf.keras</span><span>
</span><span></span><span style="color: rgb(249, 38, 114);">from</span><span> keras.preprocessing </span><span style="color: rgb(249, 38, 114);">import</span><span> text
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># download and load the bible text from gutenberg</span><span>
</span><span>nltk.download(</span><span style="color: rgb(152, 195, 121);">'gutenberg'</span><span>)
</span><span>bible_text = gutenberg.sents(</span><span style="color: rgb(152, 195, 121);">'bible-kjv.txt'</span><span>) 
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># remove punctuation and numbers from the text</span><span>
</span><span>remove_chars = punctuation + </span><span style="color: rgb(152, 195, 121);">'0123456789'</span><span>
</span><span>normalized_bible = [[word.lower() </span><span style="color: rgb(249, 38, 114);">for</span><span> word </span><span style="color: rgb(249, 38, 114);">in</span><span> sent </span><span style="color: rgb(249, 38, 114);">if</span><span> word </span><span style="color: rgb(249, 38, 114);">not</span><span> </span><span style="color: rgb(249, 38, 114);">in</span><span> remove_chars] </span><span style="color: rgb(249, 38, 114);">for</span><span> sent </span><span style="color: rgb(249, 38, 114);">in</span><span> bible_text]
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># join the tokens back into a string</span><span>
</span><span>normalized_bible_text = [</span><span style="color: rgb(152, 195, 121);">' '</span><span>.join(tok_sent) </span><span style="color: rgb(249, 38, 114);">for</span><span> tok_sent </span><span style="color: rgb(249, 38, 114);">in</span><span> normalized_bible]
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># remove empty strings and lines with fewer than three words</span><span>
</span><span>filtered_bible_text = </span><span style="color: rgb(230, 192, 123);">list</span><span>(</span><span style="color: rgb(230, 192, 123);">filter</span><span>(</span><span style="color: rgb(86, 182, 194);">None</span><span>, normalized_bible_text))
</span><span>filtered_bible_text = [tok_sent </span><span style="color: rgb(249, 38, 114);">for</span><span> tok_sent </span><span style="color: rgb(249, 38, 114);">in</span><span> filtered_bible_text </span><span style="color: rgb(249, 38, 114);">if</span><span> </span><span style="color: rgb(230, 192, 123);">len</span><span>(tok_sent.split()) &gt; </span><span style="color: rgb(209, 154, 102);">2</span><span>]
</span>
<span></span><span style="color: rgb(230, 192, 123);">print</span><span>(</span><span style="color: rgb(152, 195, 121);">'Total number of lines in the original corpus:'</span><span>, </span><span style="color: rgb(230, 192, 123);">len</span><span>(bible_text))
</span><span></span><span style="color: rgb(230, 192, 123);">print</span><span>(</span><span style="color: rgb(152, 195, 121);">'\nOriginal sample line:'</span><span>, bible_text[</span><span style="color: rgb(209, 154, 102);">5</span><span>])
</span><span></span><span style="color: rgb(230, 192, 123);">print</span><span>(</span><span style="color: rgb(152, 195, 121);">'\nProcessed sample line:'</span><span>, filtered_bible_text[</span><span style="color: rgb(209, 154, 102);">5</span><span>])
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># create a tokenizer and fit it on the text</span><span>
</span>tokenizer = text.Tokenizer()
tokenizer.fit_on_texts(filtered_bible_text)

<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># create mapping dictionaries for words to ids and ids to words</span><span>
</span>word_to_id = tokenizer.word_index
<span>id_to_word = {v:k </span><span style="color: rgb(249, 38, 114);">for</span><span> k, v </span><span style="color: rgb(249, 38, 114);">in</span><span> word_to_id.items()}
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># calculate the vocabulary size</span><span>
</span><span>vocab_size = </span><span style="color: rgb(230, 192, 123);">len</span><span>(word_to_id) + </span><span style="color: rgb(209, 154, 102);">1</span><span> 
</span><span>embedding_size = </span><span style="color: rgb(209, 154, 102);">100</span><span>
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># convert the text to a list of word ids</span><span>
</span><span>word_ids = [[word_to_id[w] </span><span style="color: rgb(249, 38, 114);">for</span><span> w </span><span style="color: rgb(249, 38, 114);">in</span><span> text.text_to_word_sequence(doc)] </span><span style="color: rgb(249, 38, 114);">for</span><span> doc </span><span style="color: rgb(249, 38, 114);">in</span><span> filtered_bible_text]
</span><span></span><span style="color: rgb(230, 192, 123);">print</span><span>(</span><span style="color: rgb(152, 195, 121);">'Vocabulary size:'</span><span>, vocab_size)
</span><span></span><span style="color: rgb(230, 192, 123);">print</span><span>(</span><span style="color: rgb(152, 195, 121);">'Vocabulary sample:'</span><span>, </span><span style="color: rgb(230, 192, 123);">list</span><span>(word_to_id.items())[:</span><span style="color: rgb(209, 154, 102);">10</span><span>])
</span>
</code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip t47d874cc-331b-4973-b112-94ea62e8f18e place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.t47d874cc-331b-4973-b112-94ea62e8f18e {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.t47d874cc-331b-4973-b112-94ea62e8f18e.place-top {
        margin-top: -10px;
    }
    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-bottom {
        margin-top: 10px;
    }
    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-left {
        margin-left: -10px;
    }
    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-right {
        margin-left: 10px;
    }
    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t47d874cc-331b-4973-b112-94ea62e8f18e.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><p><strong>Output</strong></p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-plaintext" style="white-space: pre;"><span>[nltk_data] Downloading package gutenberg to /root/nltk_data...
</span>[nltk_data]   Package gutenberg is already up-to-date!
Total number of lines in the original corpus: 30103

Original sample line: ['And', 'the', 'Spirit', 'of', 'God', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters', '.']

Processed sample line: and the spirit of god moved upon the face of the waters.
Vocabulary size: 12726
Vocabulary sample: [('the', 1), ('and', 2), ('of', 3), ('to', 4), ('that', 5), ('in', 6), ('he', 7), ('shall', 8), ('unto', 9), ('for', 10)]
</code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip t37ddd5c8-16de-4f99-abde-0c818f598103 place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.t37ddd5c8-16de-4f99-abde-0c818f598103 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.t37ddd5c8-16de-4f99-abde-0c818f598103.place-top {
        margin-top: -10px;
    }
    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-bottom {
        margin-top: 10px;
    }
    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-left {
        margin-left: -10px;
    }
    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-right {
        margin-left: 10px;
    }
    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t37ddd5c8-16de-4f99-abde-0c818f598103.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><h3 id="build-a-skip-gram---target,-context-,-relevancy--generator" level="3">Build a Skip-gram [(target, context), relevancy] Generator</h3><p>Generate skip grams from the preprocessed text. A skip-gram is a pair of words (the target word and the context word) and a label indicating whether the context word appears within a fixed window size of the target word in the input text. Skip grams are used as training data for the word embedding model.</p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-python" style="white-space: pre;"><span style="color: rgb(177, 142, 177); font-style: italic;"># generate skip-grams</span><span>
</span><span>skip_grams = [tf.keras.preprocessing.sequence.skipgrams(wid, vocabulary_size=vocab_size, window_size=</span><span style="color: rgb(209, 154, 102);">10</span><span>) </span><span style="color: rgb(249, 38, 114);">for</span><span> wid </span><span style="color: rgb(249, 38, 114);">in</span><span> word_ids]
</span><span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># view sample skip-grams</span><span>
</span><span>pairs, labels = skip_grams[</span><span style="color: rgb(209, 154, 102);">0</span><span>][</span><span style="color: rgb(209, 154, 102);">0</span><span>], skip_grams[</span><span style="color: rgb(209, 154, 102);">0</span><span>][</span><span style="color: rgb(209, 154, 102);">1</span><span>]
</span><span></span><span style="color: rgb(249, 38, 114);">for</span><span> i </span><span style="color: rgb(249, 38, 114);">in</span><span> </span><span style="color: rgb(230, 192, 123);">range</span><span>(</span><span style="color: rgb(209, 154, 102);">10</span><span>):
</span><span>    </span><span style="color: rgb(230, 192, 123);">print</span><span>(</span><span style="color: rgb(152, 195, 121);">"({:s} ({:d}), {:s} ({:d})) -&gt; {:d}"</span><span>.</span><span style="color: rgb(230, 192, 123);">format</span><span>(
</span><span>          id_to_word[pairs[i][</span><span style="color: rgb(209, 154, 102);">0</span><span>]], pairs[i][</span><span style="color: rgb(209, 154, 102);">0</span><span>], 
</span><span>          id_to_word[pairs[i][</span><span style="color: rgb(209, 154, 102);">1</span><span>]], pairs[i][</span><span style="color: rgb(209, 154, 102);">1</span><span>], 
</span>          labels[i]))

</code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5 place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-top {
        margin-top: -10px;
    }
    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-bottom {
        margin-top: 10px;
    }
    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-left {
        margin-left: -10px;
    }
    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-right {
        margin-left: 10px;
    }
    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t00a7d4eb-78b6-4cc8-bec1-969fc4c3fea5.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><p><strong>Output</strong></p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-plaintext" style="white-space: pre;"><span>(bible (6037), grayheaded (7497)) -&gt; 0
</span>(bible (6037), lowliness (8668)) -&gt; 0
(the (1), king (50)) -&gt; 1
(the (1), particularly (8570)) -&gt; 0
(king (50), james (1323)) -&gt; 1
(bible (6037), king (50)) -&gt; 1
(james (1323), king (50)) -&gt; 1
(king (50), cause (304)) -&gt; 0
(the (1), nursed (7168)) -&gt; 0
(king (50), gently (7579)) -&gt; 0
</code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip te5f3d513-a33c-4d18-bcbc-c6e1357d0a58 place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.te5f3d513-a33c-4d18-bcbc-c6e1357d0a58 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-top {
        margin-top: -10px;
    }
    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-bottom {
        margin-top: 10px;
    }
    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-left {
        margin-left: -10px;
    }
    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-right {
        margin-left: 10px;
    }
    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .te5f3d513-a33c-4d18-bcbc-c6e1357d0a58.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><h3 id="build-the-skip-gram-model-architecture" level="3">Build the Skip-Gram Model Architecture</h3><p>The next step is to define the word embedding model's architecture using <span class="highlight--red">Keras's functional API</span>. The model has two embedding layers for the target and context words, which are concatenated and passed through a dense layer with a sigmoid activation function to predict the probability of the context word appearing within a fixed window of the target word.</p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-python" style="white-space: pre;"><span style="color: rgb(249, 38, 114);">from</span><span> tensorflow.keras.layers </span><span style="color: rgb(249, 38, 114);">import</span><span> Concatenate, Dense, Embedding, Reshape
</span><span></span><span style="color: rgb(249, 38, 114);">from</span><span> tensorflow.keras.models </span><span style="color: rgb(249, 38, 114);">import</span><span> Model
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># Define the input layers for the target and context words</span><span>
</span><span>target_word_input = tf.keras.Input(shape=(</span><span style="color: rgb(209, 154, 102);">1</span><span>,))
</span><span>context_word_input = tf.keras.Input(shape=(</span><span style="color: rgb(209, 154, 102);">1</span><span>,))
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># Build skip-gram architecture</span><span>
</span>target_word_model = Embedding(vocab_size, embedding_size,
<span>                              embeddings_initializer=</span><span style="color: rgb(152, 195, 121);">"glorot_uniform"</span><span>)(target_word_input)
</span>target_word_model = Reshape((embedding_size,))(target_word_model)

context_word_model = Embedding(vocab_size, embedding_size,
<span>                               embeddings_initializer=</span><span style="color: rgb(152, 195, 121);">"glorot_uniform"</span><span>)(context_word_input)
</span>context_word_model = Reshape((embedding_size,))(context_word_model)

<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># Concatenate the output of the target and context models</span><span>
</span><span>merged = Concatenate(axis=</span><span style="color: rgb(209, 154, 102);">1</span><span>)([target_word_model, context_word_model])
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># Add a dense layer and sigmoid activation</span><span>
</span><span>output = Dense(</span><span style="color: rgb(209, 154, 102);">1</span><span>, kernel_initializer=</span><span style="color: rgb(152, 195, 121);">"glorot_uniform"</span><span>, activation=</span><span style="color: rgb(152, 195, 121);">"sigmoid"</span><span>)(merged)
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># Define the model</span><span>
</span>model = Model(inputs=[target_word_input, context_word_input], outputs=output)

<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># Compile the model</span><span>
</span><span>model.</span><span style="color: rgb(230, 192, 123);">compile</span><span>(loss=</span><span style="color: rgb(152, 195, 121);">"mean_squared_error"</span><span>, optimizer=</span><span style="color: rgb(152, 195, 121);">"adam"</span><span>)
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># View model summary</span><span>
</span><span></span><span style="color: rgb(230, 192, 123);">print</span><span>(model.summary())
</span></code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip tf752211d-8e74-46ff-8186-871ba8287079 place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.tf752211d-8e74-46ff-8186-871ba8287079 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.tf752211d-8e74-46ff-8186-871ba8287079.place-top {
        margin-top: -10px;
    }
    .tf752211d-8e74-46ff-8186-871ba8287079.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .tf752211d-8e74-46ff-8186-871ba8287079.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .tf752211d-8e74-46ff-8186-871ba8287079.place-bottom {
        margin-top: 10px;
    }
    .tf752211d-8e74-46ff-8186-871ba8287079.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .tf752211d-8e74-46ff-8186-871ba8287079.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .tf752211d-8e74-46ff-8186-871ba8287079.place-left {
        margin-left: -10px;
    }
    .tf752211d-8e74-46ff-8186-871ba8287079.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .tf752211d-8e74-46ff-8186-871ba8287079.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .tf752211d-8e74-46ff-8186-871ba8287079.place-right {
        margin-left: 10px;
    }
    .tf752211d-8e74-46ff-8186-871ba8287079.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .tf752211d-8e74-46ff-8186-871ba8287079.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><p><strong>Output</strong></p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-plaintext" style="white-space: pre;"><span>Model: "model"
</span>__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 1)]          0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1)]          0           []                               
                                                                                                  
 embedding (Embedding)          (None, 1, 100)       1272600     ['input_3[0][0]']                
                                                                                                  
 embedding_1 (Embedding)        (None, 1, 100)       1272600     ['input_4[0][0]']                
                                                                                                  
 reshape (Reshape)              (None, 100)          0           ['embedding[0][0]']              
                                                                                                  
 reshape_1 (Reshape)            (None, 100)          0           ['embedding_1[0][0]']            
                                                                                                  
 concatenate (Concatenate)      (None, 200)          0           ['reshape[0][0]',                
                                                                  'reshape_1[0][0]']              
                                                                                                  
 dense (Dense)                  (None, 1)            201         ['concatenate[0][0]']            
                                                                                                  
==================================================================================================
Total params: 2,545,401
Trainable params: 2,545,401
Non-trainable params: 0
__________________________________________________________________________________________________
None
</code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip tb176e925-a802-477c-b4ce-87a76aca4051 place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.tb176e925-a802-477c-b4ce-87a76aca4051 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.tb176e925-a802-477c-b4ce-87a76aca4051.place-top {
        margin-top: -10px;
    }
    .tb176e925-a802-477c-b4ce-87a76aca4051.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .tb176e925-a802-477c-b4ce-87a76aca4051.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .tb176e925-a802-477c-b4ce-87a76aca4051.place-bottom {
        margin-top: 10px;
    }
    .tb176e925-a802-477c-b4ce-87a76aca4051.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .tb176e925-a802-477c-b4ce-87a76aca4051.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .tb176e925-a802-477c-b4ce-87a76aca4051.place-left {
        margin-left: -10px;
    }
    .tb176e925-a802-477c-b4ce-87a76aca4051.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .tb176e925-a802-477c-b4ce-87a76aca4051.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .tb176e925-a802-477c-b4ce-87a76aca4051.place-right {
        margin-left: 10px;
    }
    .tb176e925-a802-477c-b4ce-87a76aca4051.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .tb176e925-a802-477c-b4ce-87a76aca4051.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><h3 id="train-the-model" level="3">Train the Model</h3><p>In order to train the word embedding model on the skip grams we'll use the fit method. The model is trained for a specified number of epochs, the number of times the model sees the entire dataset during training.</p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-python" style="white-space: pre;"><span style="color: rgb(177, 142, 177); font-style: italic;"># train the model on the skip-grams</span><span>
</span><span></span><span style="color: rgb(249, 38, 114);">for</span><span> epoch </span><span style="color: rgb(249, 38, 114);">in</span><span> </span><span style="color: rgb(230, 192, 123);">range</span><span>(</span><span style="color: rgb(209, 154, 102);">1</span><span>, </span><span style="color: rgb(209, 154, 102);">6</span><span>):
</span><span>    total_loss = </span><span style="color: rgb(209, 154, 102);">0</span><span>
</span><span>    </span><span style="color: rgb(249, 38, 114);">for</span><span> i, elem </span><span style="color: rgb(249, 38, 114);">in</span><span> </span><span style="color: rgb(230, 192, 123);">enumerate</span><span>(skip_grams):
</span><span>        skip_first_elem = np.array(</span><span style="color: rgb(230, 192, 123);">list</span><span>(</span><span style="color: rgb(230, 192, 123);">zip</span><span>(*elem[</span><span style="color: rgb(209, 154, 102);">0</span><span>]))[</span><span style="color: rgb(209, 154, 102);">0</span><span>], dtype=</span><span style="color: rgb(152, 195, 121);">'int32'</span><span>)
</span><span>        skip_second_elem = np.array(</span><span style="color: rgb(230, 192, 123);">list</span><span>(</span><span style="color: rgb(230, 192, 123);">zip</span><span>(*elem[</span><span style="color: rgb(209, 154, 102);">0</span><span>]))[</span><span style="color: rgb(209, 154, 102);">1</span><span>], dtype=</span><span style="color: rgb(152, 195, 121);">'int32'</span><span>)
</span><span>        labels = np.array(elem[</span><span style="color: rgb(209, 154, 102);">1</span><span>], dtype=</span><span style="color: rgb(152, 195, 121);">'int32'</span><span>)
</span>        X = [skip_first_elem, skip_second_elem]
        Y = labels
<span>        </span><span style="color: rgb(249, 38, 114);">if</span><span> i % </span><span style="color: rgb(209, 154, 102);">10000</span><span> == </span><span style="color: rgb(209, 154, 102);">0</span><span>:
</span><span>            </span><span style="color: rgb(230, 192, 123);">print</span><span>(</span><span style="color: rgb(152, 195, 121);">'Processed {} skip-gram pairs'</span><span>.</span><span style="color: rgb(230, 192, 123);">format</span><span>(i))
</span>        total_loss += model.train_on_batch(X,Y)  

<span>    </span><span style="color: rgb(230, 192, 123);">print</span><span>(</span><span style="color: rgb(152, 195, 121);">'Epoch: {} Loss: {}'</span><span>.</span><span style="color: rgb(230, 192, 123);">format</span><span>(epoch, total_loss))
</span></code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5 place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-top {
        margin-top: -10px;
    }
    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-bottom {
        margin-top: 10px;
    }
    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-left {
        margin-left: -10px;
    }
    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-right {
        margin-left: 10px;
    }
    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .ta2b23cbf-eddb-46dd-8c0f-2eed58bcaeb5.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><p><strong>Output</strong></p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-plaintext" style="white-space: pre;"><span>Processed 0 skip-gram pairs
</span>Processed 10000 skip-gram pairs
Processed 20000 skip-gram pairs
Epoch: 1 Loss: 2560.6447135005146 
Processed 0 skip-gram pairs
Processed 10000 skip-gram pairs 
Processed 20000 skip-gram pairs 
Epoch: 2 Loss: 2367.486852501519 
Processed 0 skip-gram pairs
Processed 10000 skip-gram pairs
Processed 20000 skip-gram pairs 
Epoch: 3 Loss: 2343.08078927733 
Processed 0 skip-gram pairs
Processed 10000 skip-gram pairs
Processed 20000 skip-gram pairs
Epoch: 4 Loss: 2325.2062594543386 
Processed 0 skip-gram pairs 
Processed 10000 skip-gram pairs 
Processed 20000 skip-gram pairs
Epoch: 5 Loss: 2313.4975586438086
</code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip t6da9a044-205b-410b-a5e0-3e01ce37eeee place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.t6da9a044-205b-410b-a5e0-3e01ce37eeee {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-top {
        margin-top: -10px;
    }
    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-bottom {
        margin-top: 10px;
    }
    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-left {
        margin-left: -10px;
    }
    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-right {
        margin-left: 10px;
    }
    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t6da9a044-205b-410b-a5e0-3e01ce37eeee.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><h3 id="get-word-embeddings" level="3">Get Word Embeddings</h3><p>To see results from the model, we first need to extract the trained word embeddings from the word embedding model. The word embeddings are the weights of the embedding layer, which are the <strong>dense vector representations</strong> of the words in the vocabulary. The shape of the weights tensor is (<span class="highlight--red">vocab_size</span>, <span class="highlight--red">embedding_size</span>), where <span class="highlight--red">vocab_size</span> is the size of the vocabulary and <span class="highlight--red">embedding_size</span> is the length of the dense vector representation of each word.</p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-python" style="white-space: pre;"><span style="color: rgb(249, 38, 114);">import</span><span> matplotlib.pyplot </span><span style="color: rgb(249, 38, 114);">as</span><span> plt
</span><span></span><span style="color: rgb(249, 38, 114);">from</span><span> sklearn.manifold </span><span style="color: rgb(249, 38, 114);">import</span><span> TSNE
</span><span></span><span style="color: rgb(249, 38, 114);">from</span><span> sklearn.metrics.pairwise </span><span style="color: rgb(249, 38, 114);">import</span><span> euclidean_distances
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># get the embeddings for the words in the vocabulary</span><span>
</span><span>weights = model.layers[</span><span style="color: rgb(209, 154, 102);">2</span><span>].get_weights()[</span><span style="color: rgb(209, 154, 102);">0</span><span>]
</span>
distance_matrix = euclidean_distances(weights)
<span></span><span style="color: rgb(230, 192, 123);">print</span><span>(distance_matrix.shape)
</span>
<span>similar_words = {search_term: [id2word[idx] </span><span style="color: rgb(249, 38, 114);">for</span><span> idx </span><span style="color: rgb(249, 38, 114);">in</span><span> distance_matrix[word2id[search_term]-</span><span style="color: rgb(209, 154, 102);">1</span><span>].argsort()[</span><span style="color: rgb(209, 154, 102);">1</span><span>:</span><span style="color: rgb(209, 154, 102);">6</span><span>]+</span><span style="color: rgb(209, 154, 102);">1</span><span>] 
</span><span>                   </span><span style="color: rgb(249, 38, 114);">for</span><span> search_term </span><span style="color: rgb(249, 38, 114);">in</span><span> [</span><span style="color: rgb(152, 195, 121);">'god'</span><span>, </span><span style="color: rgb(152, 195, 121);">'jesus'</span><span>, </span><span style="color: rgb(152, 195, 121);">'noah'</span><span>, </span><span style="color: rgb(152, 195, 121);">'egypt'</span><span>, </span><span style="color: rgb(152, 195, 121);">'john'</span><span>, </span><span style="color: rgb(152, 195, 121);">'gospel'</span><span>, </span><span style="color: rgb(152, 195, 121);">'moses'</span><span>,</span><span style="color: rgb(152, 195, 121);">'famine'</span><span>]}
</span>
<span></span><span style="color: rgb(230, 192, 123);">print</span><span>(similar_words)
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># reduce the dimensions of the embeddings using t-SNE</span><span>
</span><span>tsne = TSNE(n_components=</span><span style="color: rgb(209, 154, 102);">2</span><span>, random_state=</span><span style="color: rgb(209, 154, 102);">0</span><span>)
</span>vectors_2d = tsne.fit_transform(weights)

<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># create a list of the words in the vocabulary</span><span>
</span><span>words = [id2word[i] </span><span style="color: rgb(249, 38, 114);">for</span><span> i </span><span style="color: rgb(249, 38, 114);">in</span><span> </span><span style="color: rgb(230, 192, 123);">range</span><span>(</span><span style="color: rgb(209, 154, 102);">1</span><span>, vocab_size)]
</span>
<span></span><span style="color: rgb(177, 142, 177); font-style: italic;"># plot the similar words</span><span>
</span><span>fig, ax = plt.subplots(figsize=(</span><span style="color: rgb(209, 154, 102);">20</span><span>,</span><span style="color: rgb(209, 154, 102);">10</span><span>))
</span><span></span><span style="color: rgb(249, 38, 114);">for</span><span> word </span><span style="color: rgb(249, 38, 114);">in</span><span> similar_words:
</span><span>    ax.scatter(vectors_2d[word2id[word]-</span><span style="color: rgb(209, 154, 102);">1</span><span>, </span><span style="color: rgb(209, 154, 102);">0</span><span>], vectors_2d[word2id[word]-</span><span style="color: rgb(209, 154, 102);">1</span><span>, </span><span style="color: rgb(209, 154, 102);">1</span><span>], c=</span><span style="color: rgb(152, 195, 121);">'red'</span><span>, label=word)
</span><span>    </span><span style="color: rgb(249, 38, 114);">for</span><span> sim_word </span><span style="color: rgb(249, 38, 114);">in</span><span> similar_words[word]:
</span><span>        ax.scatter(vectors_2d[word2id[sim_word]-</span><span style="color: rgb(209, 154, 102);">1</span><span>, </span><span style="color: rgb(209, 154, 102);">0</span><span>], vectors_2d[word2id[sim_word]-</span><span style="color: rgb(209, 154, 102);">1</span><span>, </span><span style="color: rgb(209, 154, 102);">1</span><span>], c=</span><span style="color: rgb(152, 195, 121);">'blue'</span><span>)
</span><span>        ax.annotate(sim_word, (vectors_2d[word2id[sim_word]-</span><span style="color: rgb(209, 154, 102);">1</span><span>, </span><span style="color: rgb(209, 154, 102);">0</span><span>], vectors_2d[word2id[sim_word]-</span><span style="color: rgb(209, 154, 102);">1</span><span>, </span><span style="color: rgb(209, 154, 102);">1</span><span>]))
</span>ax.legend()
plt.show()

</code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip t86168e6c-c73c-47d3-bb81-2adecb800796 place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.t86168e6c-c73c-47d3-bb81-2adecb800796 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.t86168e6c-c73c-47d3-bb81-2adecb800796.place-top {
        margin-top: -10px;
    }
    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-bottom {
        margin-top: 10px;
    }
    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-left {
        margin-left: -10px;
    }
    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-right {
        margin-left: 10px;
    }
    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t86168e6c-c73c-47d3-bb81-2adecb800796.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><p><strong>Output</strong></p><pre><div class="code-box_snippetContainer__cJ6zK"><pre style="display: block; overflow-x: auto; padding: 0.5em; color: rgb(171, 178, 191); background: rgb(40, 44, 52);"><code class="language-plaintext" style="white-space: pre;"><span>(12726, 12726)
</span>{'god': ['true', 'effect', 'abound', 'waiteth', 'open'],
 'jesus': ['grievous', 'windows', 'glory', 'lamb', 'did'],
 'noah': ['teacheth', 'walls', 'residue', 'gathered', 'awake'],
 'egypt': ['seir', 'beersheba', 'grievous', '108', 'synagogues'],
 'john': ['gilead', 'fatherless', 'breadth', 'dwell', 'forasmuch'],
 'gospel': ['seventy', 'cause', 'boards', 'clothed', 'nevertheless'],
 'moses': ['meet', 'reach', 'youth', 'died', 'scatter'],
 'famine': ['dogs', 'blasphemy', '33', 'restored', 'jezebel']}
</code></pre><button type="button" class="btn-icon cursor code-box_copyIcon__nChUJ" data-for="copy" data-tip="Copied" data-place="left" data-effect="solid" data-event="click" data-scroll-hide="true" data-iscapture="true" currentitem="false"><svg fill="currentColor" class="code-box_copy_icon__87vHM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path d="M25.629 27.591v-18.051h-14.127v18.051h14.127zM25.629 7.005q1.026 0 1.811 0.755t0.785 1.781v18.051q0 1.026-0.785 1.811t-1.811 0.785h-14.127q-1.026 0-1.811-0.785t-0.785-1.811v-18.051q0-1.026 0.785-1.781t1.811-0.755h14.127zM21.766 1.813v2.596h-15.455v18.051h-2.536v-18.051q0-1.026 0.755-1.811t1.781-0.785h15.455z"></path></svg><div class="__react_component_tooltip t8fcdcf43-18dd-49a5-b87a-7e8003a22b14 place-top type-dark" id="copy" data-id="tooltip"><style aria-hidden="true">
  	.t8fcdcf43-18dd-49a5-b87a-7e8003a22b14 {
	    color: #fff;
	    background: #222;
	    border: 1px solid transparent;
	    border-radius: undefinedpx;
	    padding: 8px 21px;
  	}

  	.t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-top {
        margin-top: -10px;
    }
    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-top::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: 2;
        width: 20px;
        height: 12px;
    }
    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-top::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        bottom: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(135deg);
    }

    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-bottom {
        margin-top: 10px;
    }
    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-bottom::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 18px;
        height: 10px;
    }
    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-bottom::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        top: -6px;
        left: 50%;
        margin-left: -6px;
        transform: rotate(45deg);
    }

    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-left {
        margin-left: -10px;
    }
    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-left::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-left::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        right: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(45deg);
    }

    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-right {
        margin-left: 10px;
    }
    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-right::before {
        content: "";
        background-color: inherit;
        position: absolute;
        z-index: -1;
        width: 10px;
        height: 18px;
    }
    .t8fcdcf43-18dd-49a5-b87a-7e8003a22b14.place-right::after {
        content: "";
        position: absolute;
        width: 10px;
        height: 10px;
        border-top-right-radius: undefinedpx;
        border: 1px solid transparent;
        background-color: #222;
        z-index: -2;
        left: -6px;
        top: 50%;
        margin-top: -6px;
        transform: rotate(-135deg);
    }
  </style></div></button></div></pre><p><img alt="dense vector representations example" loading="lazy" width="864" height="200" decoding="async" data-nimg="1" class="markdown_image_container__jjYk1 markdown_loading__y_n2Y" src="./Skip-Gram Model in NLP - Scaler Topics_files/dense-vector-representations-example.webp" style="color: transparent; height: auto; max-width: 100%;"></p></section>
<section class="summary"><h2 id="conclusion" level="2">Conclusion</h2><ul>
<li>In conclusion, the <span class="highlight--red">skip-gram model</span> is a popular method for generating word embeddings, dense vector representations of words in a vocabulary.</li>
<li>The <span class="highlight--red">skip-gram model</span> takes a large corpus of text as input and trains a neural network to predict the context words that appear within a target word's fixed window based on the text's co-occurrence.</li>
<li>The word embeddings can be extracted from the weights of the <span class="highlight--red">embedding layer</span> in the trained model and can be used as input to other natural language processing tasks, such as <span class="highlight--red">text classification</span>, <span class="highlight--red">sentiment analysis</span>, and <span class="highlight--red">machine translation</span>.</li>
<li>The skip-gram model has been shown to produce high-quality word embeddings that capture the semantic and syntactic relationships between words in the text, making it a useful tool for a wide range of NLP applications.</li>
</ul></section></div><div class="quiz_quiz_container__aDoYh column"><div id="topic-challenge-container-570512" class="quiz_overlay_heading__tVUdM text-c h1">Challenge Time!</div><div class="quiz_content_box__JFlKa column flex-ac"><div class="show-in-tablet"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/topics_challenges.webp" alt="quiz" height="64" width="64" loading="lazy"></div><div class="hide-in-tablet"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/topics_challenges.webp" alt="quiz" height="176" width="176" loading="lazy"></div><span class="quiz_instruction_text__pHO0O"> Time to test your skills and win rewards!</span><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><a class="tappable quiz_start_button__HAKmW bold text-c">Start Challenge</a></div><span class="m-t-l"><span class="bold"> Note: </span>Rewards will be credited after the next product update.</span></div></div></div><div class="contentFooter_footer__tOsSU"><div class="collaborators_collab_container__9Z1bc"><div class="collaborators_primary_contributors__wdNuw"><span><div class="column"><span class="collaborators_title__NK1fS">This article is written by <br></span><div class="collaborators_collab_user__g4mhR"><div class="collaborators_user_profile__gu379 align-c"><div class=""><div><img class="avatar_avatar__u_XeA collaborators_user_img__hTG9R" src="./Skip-Gram Model in NLP - Scaler Topics_files/unnamed.jpg" alt="Cathrine Jeeva" width="35" height="35" loading="lazy"></div></div><div class="full-width collaborators_user_details__o640W"><div class="collaborators_name__qKgMh">Cathrine Jeeva</div><div class="collaborators_designation__zMibs"></div></div></div></div></div></span></div><div class="collaborators_collab_sidebar_ui__o4fdY collaborators_sidebar_container__Hxv5g hide-in-tablet collaborators_transition__t3FSm"><div class="collaborators_sidebar_close_btn__6H6jf"><a class="Tappable-module_root__N7ll5 btn btn-icon btn-inverted m-r-10"><svg fill="currentColor" class="collaborators_close_btn__PZbSB" data-testid="close-id" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M25.313 8.563l-7.438 7.438 7.438 7.438-1.875 1.875-7.438-7.438-7.438 7.438-1.875-1.875 7.438-7.438-7.438-7.438 1.875-1.875 7.438 7.438 7.438-7.438z"></path></svg></a></div><div class="collaborators_collab_content__vFmbN"><div class="collaborators_collab_heading__t_gco">Author &amp; Contributors</div><div>Author</div><div class="collaborators_collab_user__g4mhR"><div class="collaborators_user_profile__gu379 align-c"><div class="collaborators_contributor__FhXTM"><div><img class="avatar_avatar__u_XeA collaborators_user_img__hTG9R" src="./Skip-Gram Model in NLP - Scaler Topics_files/unnamed.jpg" alt="Cathrine Jeeva" width="35" height="35" loading="lazy"></div></div><div class="full-width collaborators_user_details__o640W"><div class="collaborators_name__qKgMh">Cathrine Jeeva</div><div class="collaborators_designation__zMibs"></div></div></div><div class="collaborators_user_sidebar_div__pjBxN"><div class="collaborators_user_social_media__OrNe6"></div></div></div></div></div><div class="show-in-tablet" style="height: 0px;"></div></div><div class="contentBanner_details__cn6xR"><div class="contentBanner_time_container__X2lEh"><div class="contentBanner_article_time_detail__mbPC9"><span class="contentBanner_updatedAlign__Rs2Y3">Updated - 4 May 2023</span><span class="contentBanner_list__G8x9c"><svg fill="currentColor" class="contentBanner_dot__SVc4Y" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M27.714 16c0 6.467-5.247 11.714-11.714 11.714s-11.714-5.247-11.714-11.714 5.247-11.714 11.714-11.714 11.714 5.247 11.714 11.714z"></path></svg>8 mins read</span><span class="contentBanner_list__G8x9c hide-in-mobile"><svg fill="currentColor" class="contentBanner_dot__SVc4Y" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M27.714 16c0 6.467-5.247 11.714-11.714 11.714s-11.714-5.247-11.714-11.714 5.247-11.714 11.714-11.714 11.714 5.247 11.714 11.714z"></path></svg>Published : 22 Feb 2023</span></div><span class="h6 show-in-mobile">Published : 22 Feb 2023</span><div class="userActions_user_actions__AO_AZ contentBanner_icon__nC0Ex hide-in-tablet"><span class="userActions_bookmark_action__zYWdn"><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><div><svg fill="currentColor" class="userActions_actionItem__TXwv3" name="Bookmark2" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M8 28.167c-0.368 0-0.667-0.298-0.667-0.667v0-22c0.001-0.92 0.747-1.666 1.667-1.667h14c0.92 0.001 1.666 0.747 1.667 1.667v22c0 0 0 0 0 0 0 0.368-0.298 0.667-0.667 0.667-0.131 0-0.253-0.038-0.356-0.103l0.003 0.002-7.647-4.779-7.645 4.779c-0.1 0.064-0.222 0.101-0.353 0.101-0 0-0.001 0-0.001 0h0zM16 21.833c0 0 0 0 0 0 0.131 0 0.253 0.038 0.356 0.103l-0.003-0.002 6.98 4.363v-20.797c0-0.184-0.149-0.333-0.333-0.333v0h-14c-0.184 0-0.333 0.149-0.333 0.333v0 20.8l6.979-4.363c0.1-0.065 0.223-0.103 0.354-0.104h0z"></path></svg></div></div></span><span class="contentBanner_like_hide__adi16"><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><div class="row flex-ac"><svg fill="currentColor" class="userActions_actionItem__TXwv3" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M16 27.673c-0.12-0-0.232-0.032-0.329-0.087l0.003 0.002c-2.408-1.422-4.492-2.958-6.407-4.68l0.036 0.032c-1.68-1.474-3.137-3.139-4.357-4.975l-0.057-0.092c-1.229-1.789-1.988-3.986-2.056-6.356l-0-0.017c0-0 0-0 0-0 0-3.959 3.209-7.168 7.168-7.168 2.499 0 4.699 1.279 5.982 3.218l0.017 0.027c1.3-1.964 3.5-3.241 5.997-3.241 3.958 0 7.167 3.207 7.169 7.165v0c-0.070 2.384-0.828 4.577-2.082 6.405l0.026-0.041c-1.277 1.928-2.735 3.593-4.387 5.042l-0.028 0.024c-1.879 1.69-3.963 3.226-6.189 4.548l-0.181 0.1c-0.093 0.057-0.205 0.091-0.324 0.095l-0.001 0zM10 5.673c-3.218 0.002-5.827 2.609-5.833 5.826v0.001c0 7.269 9.897 13.565 11.833 14.727 2.196-1.34 4.099-2.76 5.86-4.336l-0.038 0.033c2.743-2.472 6.011-6.287 6.011-10.425-0-3.222-2.612-5.834-5.835-5.834-2.411 0-4.48 1.462-5.37 3.548l-0.014 0.038c-0.103 0.243-0.34 0.41-0.615 0.41s-0.512-0.167-0.614-0.406l-0.002-0.004c-0.9-2.122-2.965-3.584-5.372-3.584-0.003 0-0.005 0-0.008 0h0z"></path></svg><span class="userActions_count__EVdwg"></span></div></div></span><span><div class="shareButton_share__Vm9x8 shareButton_buttonHover__AmSQt"><svg fill="currentColor" class="userActions_actionItem__TXwv3" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M8 11.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM8 19.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M22 20.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM22 28.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M22 2.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM22 10.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M11.364 14.505c-0 0-0 0-0 0-0.234 0-0.441-0.121-0.56-0.304l-0.002-0.003c-0.066-0.102-0.106-0.227-0.106-0.361 0-0.234 0.121-0.44 0.303-0.559l0.003-0.002 7.272-4.675c0.102-0.066 0.227-0.106 0.361-0.106 0.234 0 0.44 0.121 0.559 0.303l0.002 0.003c0.066 0.102 0.106 0.227 0.106 0.361 0 0.234-0.121 0.44-0.303 0.559l-0.003 0.002-7.272 4.675c-0.102 0.067-0.226 0.106-0.36 0.107h-0z"></path><path d="M18.635 23.503c-0 0-0 0-0 0-0.134 0-0.258-0.039-0.362-0.107l0.003 0.002-7.271-4.675c-0.186-0.12-0.307-0.327-0.307-0.561 0-0.134 0.039-0.258 0.107-0.363l-0.002 0.003c0.12-0.186 0.327-0.307 0.561-0.307 0.134 0 0.258 0.039 0.363 0.107l-0.003-0.002 7.272 4.675c0.186 0.12 0.307 0.327 0.307 0.561 0 0.368-0.298 0.667-0.667 0.667-0.001 0-0.001 0-0.002 0h0z"></path></svg></div></span></div></div></div><div class="contentFooter_user_actions_tags__yioOD"><div class="contentFooter_user_actions__OqqlL"><div class="row flex-ac userActionsFooter_user_actions__acYTk"><div class="row"><span class=""><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><div class="row flex-ac"><svg fill="currentColor" class="userActionsFooter_actionItem__UiK6k userActionsFooter_liked__owG0b" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M16 27.673c-0.12-0-0.232-0.032-0.329-0.087l0.003 0.002c-2.408-1.422-4.492-2.958-6.407-4.68l0.036 0.032c-1.68-1.474-3.137-3.139-4.357-4.975l-0.057-0.092c-1.229-1.789-1.988-3.986-2.056-6.356l-0-0.017c0-0 0-0 0-0 0-3.959 3.209-7.168 7.168-7.168 2.499 0 4.699 1.279 5.982 3.218l0.017 0.027c1.3-1.964 3.5-3.241 5.997-3.241 3.958 0 7.167 3.207 7.169 7.165v0c-0.070 2.384-0.828 4.577-2.082 6.405l0.026-0.041c-1.277 1.928-2.735 3.593-4.387 5.042l-0.028 0.024c-1.879 1.69-3.963 3.226-6.189 4.548l-0.181 0.1c-0.093 0.057-0.205 0.091-0.324 0.095l-0.001 0zM10 5.673c-3.218 0.002-5.827 2.609-5.833 5.826v0.001c0 7.269 9.897 13.565 11.833 14.727 2.196-1.34 4.099-2.76 5.86-4.336l-0.038 0.033c2.743-2.472 6.011-6.287 6.011-10.425-0-3.222-2.612-5.834-5.835-5.834-2.411 0-4.48 1.462-5.37 3.548l-0.014 0.038c-0.103 0.243-0.34 0.41-0.615 0.41s-0.512-0.167-0.614-0.406l-0.002-0.004c-0.9-2.122-2.965-3.584-5.372-3.584-0.003 0-0.005 0-0.008 0h0z"></path></svg><span></span></div></div></span></div><div class="userActionsFooter_scroll_container__jeQq_" role="button" data-name="scroll" data-testid="scroll" tabindex="0"><svg fill="currentColor" class="icons_icon_arrow__2GBht userActionsFooter_up_arrow__MqJFI userActionsFooter_actionItem__UiK6k" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg>Scroll to top!</div><div class="row"><span><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><div><svg fill="currentColor" class="userActionsFooter_actionItem__UiK6k userActionsFooter_bookmark__YRSyB" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M8 28.167c-0.368 0-0.667-0.298-0.667-0.667v0-22c0.001-0.92 0.747-1.666 1.667-1.667h14c0.92 0.001 1.666 0.747 1.667 1.667v22c0 0 0 0 0 0 0 0.368-0.298 0.667-0.667 0.667-0.131 0-0.253-0.038-0.356-0.103l0.003 0.002-7.647-4.779-7.645 4.779c-0.1 0.064-0.222 0.101-0.353 0.101-0 0-0.001 0-0.001 0h0zM16 21.833c0 0 0 0 0 0 0.131 0 0.253 0.038 0.356 0.103l-0.003-0.002 6.98 4.363v-20.797c0-0.184-0.149-0.333-0.333-0.333v0h-14c-0.184 0-0.333 0.149-0.333 0.333v0 20.8l6.979-4.363c0.1-0.065 0.223-0.103 0.354-0.104h0z"></path></svg></div></div></span><span><div class="shareButton_share__Vm9x8 shareButton_buttonHover__AmSQt"><svg fill="currentColor" class="userActionsFooter_actionItem__UiK6k" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M8 11.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM8 19.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M22 20.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM22 28.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M22 2.333c2.577 0 4.667 2.089 4.667 4.667s-2.089 4.667-4.667 4.667c-2.577 0-4.667-2.089-4.667-4.667v0c0-2.577 2.089-4.667 4.667-4.667v0zM22 10.333c1.841 0 3.333-1.492 3.333-3.333s-1.492-3.333-3.333-3.333c-1.841 0-3.333 1.492-3.333 3.333v0c0 1.841 1.492 3.333 3.333 3.333v0z"></path><path d="M11.364 14.505c-0 0-0 0-0 0-0.234 0-0.441-0.121-0.56-0.304l-0.002-0.003c-0.066-0.102-0.106-0.227-0.106-0.361 0-0.234 0.121-0.44 0.303-0.559l0.003-0.002 7.272-4.675c0.102-0.066 0.227-0.106 0.361-0.106 0.234 0 0.44 0.121 0.559 0.303l0.002 0.003c0.066 0.102 0.106 0.227 0.106 0.361 0 0.234-0.121 0.44-0.303 0.559l-0.003 0.002-7.272 4.675c-0.102 0.067-0.226 0.106-0.36 0.107h-0z"></path><path d="M18.635 23.503c-0 0-0 0-0 0-0.134 0-0.258-0.039-0.362-0.107l0.003 0.002-7.271-4.675c-0.186-0.12-0.307-0.327-0.307-0.561 0-0.134 0.039-0.258 0.107-0.363l-0.002 0.003c0.12-0.186 0.327-0.307 0.561-0.307 0.134 0 0.258 0.039 0.363 0.107l-0.003-0.002 7.272 4.675c0.186 0.12 0.307 0.327 0.307 0.561 0 0.368-0.298 0.667-0.667 0.667-0.001 0-0.001 0-0.002 0h0z"></path></svg></div></span></div></div></div><div class="contentFooter_tags___qVn3"><div class="chip chip--default chips_chip__FKn4E chips_chipItem__BLQJW tags_tag__5cAJ7 contentFooter_tag__rOe9T" data-name="tag" data-id="popular_tag">NLP</div></div></div><div class="starrating_container__ObR2h"><div>How would you rate this article?</div><div class="m-t-20 starrating_starContainer__G0Mha"><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><a class="Tappable-module_root__N7ll5 m-r-20 starrating_btn_hover__mv6sW"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/verybad.svg" alt="Very Bad" width="32" height="32" loading="lazy"></a><a class="Tappable-module_root__N7ll5 m-r-20 starrating_btn_hover__mv6sW"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/bad.svg" alt="Bad" width="32" height="32" loading="lazy"></a><a class="Tappable-module_root__N7ll5 m-r-20 starrating_btn_hover__mv6sW"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/average.svg" alt="Average" width="32" height="32" loading="lazy"></a><a class="Tappable-module_root__N7ll5 m-r-20 starrating_btn_hover__mv6sW"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/good.svg" alt="Good" width="32" height="32" loading="lazy"></a><a class="Tappable-module_root__N7ll5 m-r-20 starrating_btn_hover__mv6sW"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/lovedit.svg" alt="Loved It!" width="32" height="32" loading="lazy"></a></div></div></div></div><div class="view_navStep__TE_SH view_content_container__RWK3L"><div class="column"><a class="tappable btn view_stepButton__qBaYP" href="https://www.scaler.com/topics/nlp/cbow/">Prev</a><div class="m-t-xs view_article_title__9TJ53">Continuous Bag of Words (CBOW) Model in NLP</div></div><div class="column"><a class="tappable btn view_stepButton__qBaYP view_next__7_a5W" href="https://www.scaler.com/topics/nlp/word-embedding-visualization/">Next</a><div class="m-t-xs view_article_title__9TJ53">Building the Word2vec Model Using Gensim</div></div></div></div><div class="engagement-panel-desktop_engagement_bar__y0urM"><div class="row full-width view_ar_container__LNAHP engagement-panel-desktop_container___LIK_"><div class="row flex-c"><a class="Tappable-module_root__N7ll5 engagement-panel-desktop_nextItemBtn__Av_yG" href="https://www.scaler.com/topics/nlp/cbow/"><svg fill="currentColor" class="icons_icon_chevron__cl99H icons_icon_chevron__left__TwvkN" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M9.875 20.563l-1.875-1.875 8-8 8 8-1.875 1.875-6.125-6.125z"></path></svg></a><a class="Tappable-module_root__N7ll5 row flex-c engagement-panel-desktop_hubTitle__fX69J"><svg fill="currentColor" class="m-r-10 engagement-panel-desktop_icon_bold__9fwB5" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M27 8.933h-15c-0.515 0-0.933-0.418-0.933-0.933v0c0-0.515 0.418-0.933 0.933-0.933h15c0.515 0 0.933 0.418 0.933 0.933v0c0 0.515-0.418 0.933-0.933 0.933v0z"></path><path d="M26.999 16.933h-14.999c-0.515 0-0.933-0.418-0.933-0.933v0c0-0.515 0.418-0.933 0.933-0.933h14.999c0.515 0 0.933 0.418 0.933 0.933v0c0 0.515-0.418 0.933-0.933 0.933v0z"></path><path d="M26.999 24.933h-14.999c-0.515 0-0.933-0.418-0.933-0.933v0c0-0.515 0.418-0.933 0.933-0.933h14.999c0.515 0 0.933 0.418 0.933 0.933v0c0 0.515-0.418 0.933-0.933 0.933v0z"></path><path d="M7 8.933h-2c-0.515 0-0.933-0.418-0.933-0.933v0c0-0.515 0.418-0.933 0.933-0.933h2c0.515 0 0.933 0.418 0.933 0.933v0c0 0.515-0.418 0.933-0.933 0.933v0z"></path><path d="M7 16.933h-2c-0.515 0-0.933-0.418-0.933-0.933v0c0-0.515 0.418-0.933 0.933-0.933h2c0.515 0 0.933 0.418 0.933 0.933v0c0 0.515-0.418 0.933-0.933 0.933v0z"></path><path d="M7 24.933h-2c-0.515 0-0.933-0.418-0.933-0.933v0c0-0.515 0.418-0.933 0.933-0.933h2c0.515 0 0.933 0.418 0.933 0.933v0c0 0.515-0.418 0.933-0.933 0.933v0z"></path></svg>Article Outline</a><a class="Tappable-module_root__N7ll5 engagement-panel-desktop_nextItemBtn__Av_yG" href="https://www.scaler.com/topics/nlp/word-embedding-visualization/"><svg fill="currentColor" class="icons_icon_chevron__cl99H icons_icon_chevron__right__YxLYH" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M9.875 20.563l-1.875-1.875 8-8 8 8-1.875 1.875-6.125-6.125z"></path></svg></a></div><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW row flex-c engagement-panel-desktop_log_in__fdN7H"><div class="signin-alert-popup_overLay__Xq3de"></div><svg fill="currentColor" stroke="currentColor" class="m-r-10 engagement-panel-desktop_icon_bold__9fwB5 engagement-panel-desktop_log_in_text__usnmu" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14 16.56c-0.309 0-0.56-0.251-0.56-0.56v0-12c0-0.309 0.251-0.56 0.56-0.56s0.56 0.251 0.56 0.56v10.88l3.104-2.328c0.092-0.070 0.209-0.112 0.336-0.112s0.244 0.042 0.337 0.113l-0.001-0.001 3.104 2.328v-10.88c0-0.309 0.251-0.56 0.56-0.56s0.56 0.251 0.56 0.56v12c0 0.309-0.251 0.56-0.56 0.56-0.127 0-0.244-0.042-0.337-0.113l0.001 0.001-3.664-2.748-3.664 2.748c-0.092 0.070-0.209 0.112-0.336 0.112v0z"></path><path d="M6 27.56c-0.309 0-0.56-0.251-0.56-0.56v0-20c0-0 0-0.001 0-0.001 0-0.983 0.397-1.873 1.040-2.519l-0 0c0.638-0.642 1.523-1.040 2.5-1.040 0.003 0 0.006 0 0.010 0h17.011c0.309 0 0.56 0.251 0.56 0.56v0 20c0 0.309-0.251 0.56-0.56 0.56v0h-17.013c0 0-0 0-0 0-1.337 0-2.421 1.080-2.427 2.415v0.025c0 0.309-0.251 0.56-0.56 0.56v0zM8.987 4.56c-0.002 0-0.004 0-0.007 0-0.668 0-1.273 0.272-1.71 0.711l-0 0c-0.439 0.442-0.711 1.051-0.711 1.723 0 0.001 0 0.002 0 0.003v-0 17.402c0.629-0.595 1.48-0.96 2.416-0.96 0.004 0 0.008 0 0.012 0h16.453v-18.88z"></path><path d="M24 28.56h-18c-0.309 0-0.56-0.251-0.56-0.56v0-1c0-0.309 0.251-0.56 0.56-0.56s0.56 0.251 0.56 0.56v0 0.44h17.44c0.309 0 0.56 0.251 0.56 0.56s-0.251 0.56-0.56 0.56v0z"></path></svg><span class="engagement-panel-desktop_log_in_text__usnmu m-r-5">Log in </span>to check your progress</div><a class="m-l-a" href="https://www.scaler.com/topics/nlp/skip-gram-model/#topic-challenge-container-570512"><div class="row flex-c engagement-panel-desktop_challenge_box__XqHPf"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__down__msycO m-r-xxs" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg><span>Quiz</span></div></a></div></div></div><div class="view_right_section__M6YCz relative p-b-m"><div class="article-right-sec_container__0u7GM"><div class="column article-right-sec_course_promo_box__J5K2B"><div class="article-right-sec_hideMe__9AP73"><div class="row align-c article-right-sec_video_heading__sgAIj"><svg fill="currentColor" stroke="" class="article-right-sec_course_icon__iPRAX" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M26.259 23.289h-20.518c-1.193 0-2.16-0.967-2.16-2.16v0-14.588c0-1.193 0.967-2.16 2.16-2.16v0h20.518c1.193 0 2.16 0.967 2.16 2.16v0 14.588c0 1.193-0.967 2.16-2.16 2.16v0zM5.741 5.501c-0.574 0-1.040 0.466-1.040 1.040v0 14.588c0 0.574 0.466 1.040 1.040 1.040v0h20.518c0.574 0 1.040-0.466 1.040-1.040v0-14.588c0-0.574-0.466-1.040-1.040-1.040v0z"></path><path d="M19.764 27.619h-7.53c-0.309 0-0.56-0.251-0.56-0.56v0c0-0.309 0.251-0.56 0.56-0.56h7.53c0.309 0 0.56 0.251 0.56 0.56v0c0 0.309-0.251 0.56-0.56 0.56v0z"></path><path d="M14.023 9.322c0.116 0 0.223 0.035 0.312 0.096l-0.002-0.001 5.93 3.953c0.151 0.102 0.249 0.272 0.249 0.466s-0.098 0.364-0.247 0.465l-0.002 0.001-5.93 3.953c-0.087 0.059-0.195 0.094-0.31 0.094-0.309 0-0.56-0.25-0.56-0.559v-7.906c0-0.309 0.251-0.56 0.56-0.56v0zM18.943 13.835l-4.36-2.906v5.813z"></path></svg><span class="bold p-l-xxs">Learn via video course</span></div><div class=""><div class="m-t-xs article-right-sec_right_course_widget__MQpD_"></div></div><a class="tappable article-right-sec_view_all_courses__ichTc full-width m-t-xxs" href="https://www.scaler.com/topics/courses/"><div class="hide-in-mobile row align-c">View All Courses<svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP m-l-xxs" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a></div><div class=""><div class="row align-c article-right-sec_video_heading__sgAIj"><svg fill="currentColor" stroke="" class="article-right-sec_course_icon__iPRAX" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M26.259 23.289h-20.518c-1.193 0-2.16-0.967-2.16-2.16v0-14.588c0-1.193 0.967-2.16 2.16-2.16v0h20.518c1.193 0 2.16 0.967 2.16 2.16v0 14.588c0 1.193-0.967 2.16-2.16 2.16v0zM5.741 5.501c-0.574 0-1.040 0.466-1.040 1.040v0 14.588c0 0.574 0.466 1.040 1.040 1.040v0h20.518c0.574 0 1.040-0.466 1.040-1.040v0-14.588c0-0.574-0.466-1.040-1.040-1.040v0z"></path><path d="M19.764 27.619h-7.53c-0.309 0-0.56-0.251-0.56-0.56v0c0-0.309 0.251-0.56 0.56-0.56h7.53c0.309 0 0.56 0.251 0.56 0.56v0c0 0.309-0.251 0.56-0.56 0.56v0z"></path><path d="M14.023 9.322c0.116 0 0.223 0.035 0.312 0.096l-0.002-0.001 5.93 3.953c0.151 0.102 0.249 0.272 0.249 0.466s-0.098 0.364-0.247 0.465l-0.002 0.001-5.93 3.953c-0.087 0.059-0.195 0.094-0.31 0.094-0.309 0-0.56-0.25-0.56-0.559v-7.906c0-0.309 0.251-0.56 0.56-0.56v0zM18.943 13.835l-4.36-2.906v5.813z"></path></svg><span class="bold p-l-xxs">Video Courses</span></div><div class="column full-width p-xs course_widget_list_course_box__mQXF6"><div class="course_widget_list_course_lists__aoiPp"><a class="Tappable-module_root__N7ll5 course_widget_list_card_btn__LQ6hs full-width" href="https://www.scaler.com/topics/course/javascript-beginners/"><div class="row full-width course_widget_list_card___wugn"><img loading="lazy" width="56" height="56" src="./Skip-Gram Model in NLP - Scaler Topics_files/mrinal_bhattacharya.webp" class="course_widget_list_mobile_cover_img__vdK3z" alt="JavaScript Course With Certification: Unlocking the Power of JavaScript"><div class="course_widget_list_course_details__b7Z6x"><span class="course_widget_list_course_details_title__MaHR9 bold course_widget_list_popup_title__GDP3x">JavaScript Course With Certification: Unlocking the Power of JavaScript</span><div class="row course_widget_list_data_container__fbT4a"><span class="course_widget_list_instructor__ojdAr">Mrinal Bhattacharya</span><div class="row align-c p-l-xs"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/free.svg" height="14" width="7" loading="lazy"><span class="course_widget_list_free_text__bVF71">Free</span></div></div></div></div><img src="./Skip-Gram Model in NLP - Scaler Topics_files/play_button.svg" alt="play" width="32" height="32" class="hide-in-mobile" loading="lazy"></a><a class="Tappable-module_root__N7ll5 course_widget_list_card_btn__LQ6hs full-width" href="https://www.scaler.com/topics/course/dbms/"><div class="row full-width course_widget_list_card___wugn"><img loading="lazy" width="56" height="56" src="./Skip-Gram Model in NLP - Scaler Topics_files/srikant-varma_instructor.webp" class="course_widget_list_mobile_cover_img__vdK3z" alt="DBMS Course - Master the Fundamentals and Advanced Concepts"><div class="course_widget_list_course_details__b7Z6x"><span class="course_widget_list_course_details_title__MaHR9 bold course_widget_list_popup_title__GDP3x">DBMS Course - Master the Fundamentals and Advanced Concepts</span><div class="row course_widget_list_data_container__fbT4a"><span class="course_widget_list_instructor__ojdAr">Srikanth Varma</span><div class="row align-c p-l-xs"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/free.svg" height="14" width="7" loading="lazy"><span class="course_widget_list_free_text__bVF71">Free</span></div></div></div></div><img src="./Skip-Gram Model in NLP - Scaler Topics_files/play_button.svg" alt="play" width="32" height="32" class="hide-in-mobile" loading="lazy"></a></div><a class="Tappable-module_root__N7ll5 course_widget_list_view_all___KPYb full-width m-t-xxs" href="https://www.scaler.com/topics/courses/"><div class="show-in-mobile">View All</div><div class="hide-in-mobile row align-c">View All Courses<svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP m-l-xxs" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a></div></div></div><div class="column event-article-section_cards_list__ZoWPk"></div><div class="article-right-sec_scroll_container__ou_ph" role="button" data-name="scroll" data-testid="scroll" tabindex="0"><svg fill="currentColor" class="icons_icon_arrow__2GBht m-5" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></div></div></div><div class="styles_explore_list__QDwsT"><div class="sr-container"><div class="styles_category_container__DEnFp"><div class="flex-c row m-0"><svg fill="currentColor" stroke="" class="bold styles_category_icon__w1WIB hide-in-mobile hide-in-tablet category-card_courses_color__qRHyP" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M26.259 23.289h-20.518c-1.193 0-2.16-0.967-2.16-2.16v0-14.588c0-1.193 0.967-2.16 2.16-2.16v0h20.518c1.193 0 2.16 0.967 2.16 2.16v0 14.588c0 1.193-0.967 2.16-2.16 2.16v0zM5.741 5.501c-0.574 0-1.040 0.466-1.040 1.040v0 14.588c0 0.574 0.466 1.040 1.040 1.040v0h20.518c0.574 0 1.040-0.466 1.040-1.040v0-14.588c0-0.574-0.466-1.040-1.040-1.040v0z"></path><path d="M19.764 27.619h-7.53c-0.309 0-0.56-0.251-0.56-0.56v0c0-0.309 0.251-0.56 0.56-0.56h7.53c0.309 0 0.56 0.251 0.56 0.56v0c0 0.309-0.251 0.56-0.56 0.56v0z"></path><path d="M14.023 9.322c0.116 0 0.223 0.035 0.312 0.096l-0.002-0.001 5.93 3.953c0.151 0.102 0.249 0.272 0.249 0.466s-0.098 0.364-0.247 0.465l-0.002 0.001-5.93 3.953c-0.087 0.059-0.195 0.094-0.31 0.094-0.309 0-0.56-0.25-0.56-0.559v-7.906c0-0.309 0.251-0.56 0.56-0.56v0zM18.943 13.835l-4.36-2.906v5.813z"></path></svg><span class="styles_category_title__wVtO3">Free Courses by top Scaler instructors</span></div><div class="styles_exploreAll__PwhwW show-in-mobile show-in-tablet"><a class="Tappable-module_root__N7ll5" href="https://www.scaler.com/topics/courses/">View All</a></div></div><div class="horizontal-scroll-view horizontal-scroll_container__jCbjd horizontal-scroll-view__shadow-right"><div class="horizontal-scroll-view__items hide-in-tablet m-t-m horizontal-scroll-view__itemsFlexStart" data-testid="horizontal-scroll id"><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/java-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/Java-master-image.webp" alt="Java Course - Mastering the Fundamentals" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">Java Course - Mastering the Fundamentals</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Tarun Luthra</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Embark on your programming journey with our comprehensive Free Java Course for Beginners. Master the fundamentals of Java and gain the skills needed for advanced Java development. This easy-to-follow course is designed with beginners in mind, offering a structured learning path to specialize in Java programming. With no prerequisites, this course empowers you to learn Java at your own pace and take the first step toward a promising career in tech.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">79118</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/python-for-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_pybeg.webp" alt="Python Course for Beginners With Certification: Mastering the Essentials" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">Python Course for Beginners With Certification: Mastering the Essentials</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Rahul Janghu</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Welcome to the free Python course online for beginners, designed to help you kickstart your programming journey. This comprehensive Python course offers a certificate upon completion, covering essential topics like basic Python fundamentals, data structures, object-oriented programming, and more. With 9 hours and 48 minutes of content, you'll gain the knowledge and confidence to start working on your Python projects.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>4.90</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">69256</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/cpp-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/cpp_card_master.webp" alt="C++ Course: Learn the Essentials" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">C++ Course: Learn the Essentials</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Prateek Narang</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Gain programming expertise with our Free C++ Course! Covering basics to advanced concepts, this online program provides a comprehensive curriculum encompassing environment setup, variables, conditional statements, loops, functions, pointers, arrays, sorting, character arrays, strings, and more. Perfect for beginners or seasoned programmers looking to enhance their skills and earn a certificate.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">41285</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/dbms/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_dbms.webp" alt="DBMS Course - Master the Fundamentals and Advanced Concepts" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">DBMS Course - Master the Fundamentals and Advanced Concepts</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Srikanth Varma</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Scaler Topics free DBMS course is designed to help beginners learn about the fundamental concepts of database management systems. The course is completely online, and it comes with a free certificate of completion that you can add to your resume or LinkedIn profile. You'll learn about the most popular DBMS like MySQL, Oracle, and SQL Server, as well as the theoretical foundations of databases.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">36088</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/javascript-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/Course_Listing_312x136_MrinalBhattacharya" alt="JavaScript Course With Certification: Unlocking the Power of JavaScript" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">JavaScript Course With Certification: Unlocking the Power of JavaScript</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Mrinal Bhattacharya</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Kickstart your journey into web development with this free JavaScript course online with a certificate. Designed for beginners, this comprehensive JavaScript online course covers the essential concepts and skills needed to master Javascript, one of the most popular and widely used programming languages in the world. With a course duration of 10 hours and 9 minutes, you'll learn everything from the basics to advanced techniques, all at your own pace.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>4.8</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">35420</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/python-sql-data-science/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_pds.webp" alt="Python and SQL for Data Science" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">Python and SQL for Data Science</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Srikanth Varma</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Introducing the Free Data Science with Python and SQL Certification Course Online, a comprehensive beginner's program designed to help aspiring data scientists learn the essential skills in the rapidly growing field of data science. This course offers a unique blend of practical and theoretical knowledge, combining the powerful programming language Python and the versatile database management system SQL to help you analyze, visualize, and interpret data efficiently.
</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">29505</div></div></div></div></div></a></div><a class="tappable btn btn-primary btn-icon btn-round horizontal-scroll-view__control horizontal-scroll-view__control--right horizontal-scroll_scrollArrow__A0mnS hide-in-tablet h1" data-direction="right"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></a></div><div class="all-courses_courseListContainer__Sju9b"><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/java-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/Java-master-image.webp" alt="Java Course - Mastering the Fundamentals" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">Java Course - Mastering the Fundamentals</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Tarun Luthra</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Embark on your programming journey with our comprehensive Free Java Course for Beginners. Master the fundamentals of Java and gain the skills needed for advanced Java development. This easy-to-follow course is designed with beginners in mind, offering a structured learning path to specialize in Java programming. With no prerequisites, this course empowers you to learn Java at your own pace and take the first step toward a promising career in tech.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">79118</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/python-for-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_pybeg.webp" alt="Python Course for Beginners With Certification: Mastering the Essentials" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">Python Course for Beginners With Certification: Mastering the Essentials</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Rahul Janghu</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Welcome to the free Python course online for beginners, designed to help you kickstart your programming journey. This comprehensive Python course offers a certificate upon completion, covering essential topics like basic Python fundamentals, data structures, object-oriented programming, and more. With 9 hours and 48 minutes of content, you'll gain the knowledge and confidence to start working on your Python projects.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>4.90</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">69256</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/cpp-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/cpp_card_master.webp" alt="C++ Course: Learn the Essentials" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">C++ Course: Learn the Essentials</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Prateek Narang</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Gain programming expertise with our Free C++ Course! Covering basics to advanced concepts, this online program provides a comprehensive curriculum encompassing environment setup, variables, conditional statements, loops, functions, pointers, arrays, sorting, character arrays, strings, and more. Perfect for beginners or seasoned programmers looking to enhance their skills and earn a certificate.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">41285</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/dbms/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_dbms.webp" alt="DBMS Course - Master the Fundamentals and Advanced Concepts" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">DBMS Course - Master the Fundamentals and Advanced Concepts</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Srikanth Varma</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Scaler Topics free DBMS course is designed to help beginners learn about the fundamental concepts of database management systems. The course is completely online, and it comes with a free certificate of completion that you can add to your resume or LinkedIn profile. You'll learn about the most popular DBMS like MySQL, Oracle, and SQL Server, as well as the theoretical foundations of databases.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">36088</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/javascript-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/Course_Listing_312x136_MrinalBhattacharya" alt="JavaScript Course With Certification: Unlocking the Power of JavaScript" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">JavaScript Course With Certification: Unlocking the Power of JavaScript</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Mrinal Bhattacharya</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Kickstart your journey into web development with this free JavaScript course online with a certificate. Designed for beginners, this comprehensive JavaScript online course covers the essential concepts and skills needed to master Javascript, one of the most popular and widely used programming languages in the world. With a course duration of 10 hours and 9 minutes, you'll learn everything from the basics to advanced techniques, all at your own pace.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>4.8</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">35420</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/python-sql-data-science/"><div class="all-courses_course_card_box__BNbG3 full-width full-height row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_pds.webp" alt="Python and SQL for Data Science" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">Python and SQL for Data Science</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Srikanth Varma</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Introducing the Free Data Science with Python and SQL Certification Course Online, a comprehensive beginner's program designed to help aspiring data scientists learn the essential skills in the rapidly growing field of data science. This course offers a unique blend of practical and theoretical knowledge, combining the powerful programming language Python and the versatile database management system SQL to help you analyze, visualize, and interpret data efficiently.
</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">29505</div></div></div></div></div></a></div><div class="styles_viewAllContainer__pklHF"><a class="tappable styles_viewAll__z_L54 hide-in-mobile hide-in-tablet" data-name="courses" data-id="explore_all_courses" href="https://www.scaler.com/topics/courses/">View All</a></div></div></div></div><div class="column p-s m-t-s full-width social-validation_container__973K_"><div class="column p-s full-width space-between social-validation_premium_badge_container__pLCZ3 social-validation_video_component__gR4zh"><div class="row space-between social-validation_video_text_alignment__bfKaI"><div class="column p-r-xxs"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/premium_tag.svg" alt="premium tags" layout="fixed" height="24" width="119" class="m-0 m-b-xs" loading="lazy"><div class="social-validation_badge_text__npQpl">Learn from<img src="./Skip-Gram Model in NLP - Scaler Topics_files/scaler_logo.svg" alt="scaler logo" height="13" width="90" class="social-validation_scaler_logo__REvDY" loading="lazy">India’s best tech learning company</div><div class="social-validation_video_header_subtext__1nkkf m-b-s">Learn industry - relevant skills with top tech veterans</div><div class="row full-width m-b-s social-validation_premium_details__cGO0q"><div class="social-validation_premium_data__Djsr9 social-validation_separator_class__VDdX3 social-validation_unset_width__RSpXe relative p-r-xs m-r-xs"><div class="row"><div class="social-validation_icons__8gxE9 m-r-xxs"><svg fill="currentColor" class="social-validation_icon_color__P7BZ7 row align-c" version="1.1" xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 36 28"><path d="M5.586 3.586c0.375-0.375 0.884-0.586 1.414-0.586h12c0.265 0 0.52 0.105 0.707 0.293l7 7c0.187 0.188 0.293 0.442 0.293 0.707v16c0 0.53-0.211 1.039-0.586 1.414s-0.884 0.586-1.414 0.586h-18c-0.53 0-1.039-0.211-1.414-0.586s-0.586-0.884-0.586-1.414v-22c0-0.53 0.211-1.039 0.586-1.414zM18.586 5h-11.586v22h18v-15.586l-6.414-6.414z"></path><path d="M19 3c0.552 0 1 0.448 1 1v6h6c0.552 0 1 0.448 1 1s-0.448 1-1 1h-7c-0.552 0-1-0.448-1-1v-7c0-0.552 0.448-1 1-1z"></path></svg></div><div class="col social-validation_premium_data_text__X__Vg"><div class="social-validation_data_heading__YLZAD social-validation_text_size_video__GtEHw bold">Future-Proof Curriculum</div><div class="social-validation_data_text__tnNOG social-validation_text_size_video__GtEHw">Designed in Collaboration with Top Engineering Leaders</div></div></div></div><div class="social-validation_premium_data__Djsr9 social-validation_separator_class__VDdX3 social-validation_unset_width__RSpXe relative p-r-xs m-r-xs"><div class="row"><div class="social-validation_icons__8gxE9 m-r-xxs"><svg fill="currentColor" class="social-validation_icon_color__P7BZ7 row align-c" version="1.1" xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 32 32"><path d="M11.199 7.957c-3.086 0-5.588 2.502-5.588 5.588s2.502 5.588 5.588 5.588c3.086 0 5.588-2.502 5.588-5.588s-2.502-5.588-5.588-5.588zM3.611 13.545c0-4.191 3.397-7.588 7.588-7.588s7.588 3.397 7.588 7.588c0 4.191-3.397 7.588-7.588 7.588s-7.588-3.397-7.588-7.588z"></path><path d="M21.090 6.369h0.003c1.989 0 3.897 0.79 5.303 2.197s2.197 3.314 2.197 5.303-0.79 3.897-2.197 5.303c-1.406 1.407-3.314 2.197-5.303 2.197-0.552 0-1-0.448-1-1s0.448-1 1-1c1.459 0 2.858-0.579 3.889-1.611s1.611-2.43 1.611-3.889c0-1.459-0.58-2.858-1.611-3.889s-2.429-1.611-3.888-1.611c-0.507 0.002-1.013 0.070-1.502 0.203-0.533 0.145-1.082-0.17-1.227-0.703s0.17-1.082 0.703-1.227c0.659-0.179 1.339-0.27 2.021-0.272z"></path><path d="M10.906 21.364c-1.605 0-3.186 0.386-4.61 1.126s-2.649 1.811-3.572 3.124c-0.318 0.452-0.941 0.561-1.393 0.243s-0.561-0.941-0.243-1.393c1.107-1.576 2.577-2.862 4.286-3.749s3.606-1.351 5.532-1.351 3.823 0.463 5.532 1.351c1.709 0.888 3.179 2.174 4.286 3.749 0.318 0.452 0.209 1.076-0.243 1.393s-1.076 0.209-1.393-0.243c-0.923-1.313-2.148-2.385-3.572-3.124s-3.005-1.126-4.61-1.126z"></path><path d="M25.704 22.493c-1.424-0.74-3.005-1.125-4.61-1.124-0.552 0-1-0.447-1.001-0.999s0.447-1 0.999-1.001c1.926-0.001 3.824 0.462 5.533 1.349s3.179 2.174 4.286 3.751c0.317 0.452 0.208 1.076-0.244 1.393s-1.076 0.208-1.393-0.244c-0.922-1.313-2.147-2.385-3.571-3.125z"></path></svg></div><div class="col social-validation_premium_data_text__X__Vg"><div class="social-validation_data_heading__YLZAD social-validation_text_size_video__GtEHw bold">Personal 1:1 Mentorship</div><div class="social-validation_data_text__tnNOG social-validation_text_size_video__GtEHw">1:1 career guidance with Industry Experts to ensure you succeed</div></div></div></div></div><div class="row full-width social-validation_column_mobile__sxLBt social-validation_video_component_buttons__NAw_4"><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW row flex-c social-validation_full_width_tablet__HGEJG"><div class="signin-alert-popup_overLay__Xq3de"></div><a class="Tappable-module_root__N7ll5 social-validation_button__lRMr_ social-validation_highlight__5pznd social-validation_full_width_tablet__HGEJG">Talk to Counsellor</a></div><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW social-validation_signin_alert_popup__iEKnU"><div class="signin-alert-popup_overLay__Xq3de"></div><a class="Tappable-module_root__N7ll5 Header_exp_scaler__idDAV Header_hide_in_small_screen__rcYLc social-validation_button__lRMr_ social-validation_video_buttons__HwnDC social-validation_experince_scaler_button__9mNMl" target="_blank">Experience Scaler for Free</a></div></div></div><div class="row flex-c full-width social-validation_video_tag_container__8_cl2"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/thumbnail_desktop.svg" alt="video thumbnail" height="268" class="cursor full-width social-validation_video_tag__zwFwI" loading="lazy"></div></div></div></div><div class="exit-intent_modal_main_container__h4vtY hide-in-mobile"><div class="exit-intent_modal_container__O2C8_"><svg fill="currentColor" class="exit-intent_close_icon__lxzbB" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M25.313 8.563l-7.438 7.438 7.438 7.438-1.875 1.875-7.438-7.438-7.438 7.438-1.875-1.875 7.438-7.438-7.438-7.438 1.875-1.875 7.438 7.438 7.438-7.438z"></path></svg><div class="exit-intent_modal_title__WjdtZ"><span class="m-r-xxs"><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/confetti-ball.svg" alt="happy" width="40" height="40" loading="lazy"></span>We’ve a lot more for you to learn from</div><div class="exit-intent_modal_heading__NAT_9"><span class="exit-intent_modal_heading__free_course__Po7pk">Free Courses</span> by Top Scaler Instructors</div><div class="hide-in-mobile exit-intent_coursesList__lx1Sg"><div class="exit-intent_modal_body__t3brF"><a class="all-courses_linkContainer__xmZjN exit-intent_card_container__dVeKU" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/javascript-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height exit-intent_cardBox__0PZUA row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/Course_Listing_312x136_MrinalBhattacharya" alt="JavaScript Course With Certification: Unlocking the Power of JavaScript" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">JavaScript Course With Certification: Unlocking the Power of JavaScript</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Mrinal Bhattacharya</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Kickstart your journey into web development with this free JavaScript course online with a certificate. Designed for beginners, this comprehensive JavaScript online course covers the essential concepts and skills needed to master Javascript, one of the most popular and widely used programming languages in the world. With a course duration of 10 hours and 9 minutes, you'll learn everything from the basics to advanced techniques, all at your own pace.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>4.8</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">35420</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN exit-intent_card_container__dVeKU" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/cpp-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height exit-intent_cardBox__0PZUA row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/cpp_card_master.webp" alt="C++ Course: Learn the Essentials" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">C++ Course: Learn the Essentials</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Prateek Narang</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Gain programming expertise with our Free C++ Course! Covering basics to advanced concepts, this online program provides a comprehensive curriculum encompassing environment setup, variables, conditional statements, loops, functions, pointers, arrays, sorting, character arrays, strings, and more. Perfect for beginners or seasoned programmers looking to enhance their skills and earn a certificate.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">41285</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN exit-intent_card_container__dVeKU" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/python-sql-data-science/"><div class="all-courses_course_card_box__BNbG3 full-width full-height exit-intent_cardBox__0PZUA row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_pds.webp" alt="Python and SQL for Data Science" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">Python and SQL for Data Science</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Srikanth Varma</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Introducing the Free Data Science with Python and SQL Certification Course Online, a comprehensive beginner's program designed to help aspiring data scientists learn the essential skills in the rapidly growing field of data science. This course offers a unique blend of practical and theoretical knowledge, combining the powerful programming language Python and the versatile database management system SQL to help you analyze, visualize, and interpret data efficiently.
</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">29505</div></div></div></div></div></a></div></div><div class="full-width show-in-mobile"><div class="course-promo-widget_container__ZP0uC"><div><a class="tappable row border-bottom course-promo-widget_course_row__iQuP5" href="https://www.scaler.com/topics/course/java-beginners/"><img loading="lazy" class="course-promo-widget_instructor_image__8UeLD" src="https://www.scaler.com/topics/images/instructor-tarun.webp" alt="Tarun Luthra" height="56" width="56"><div class="m-l-xxs"><div class="course-promo-widget_course_name__vLsrI">Java Course - Mastering the Fundamentals</div><div class="course-promo-widget_instructor_name__n_H0k">By Tarun Luthra</div><div class="row flex-ac course-promo-widget_highliter__Psg62"><svg fill="currentColor" class="course-promo-widget_star__rsdml" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg><span class="course-promo-widget_star_rating___7FSQ">5</span><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/user-circle-check.svg" class="course-promo-widget_user_registered_icon__EdhwC" height="12" width="12" loading="lazy"><span class="course-promo-widget_user_registered__yGnuK">Enrolled:79118</span></div></div><div class="row flex-ac course-promo-widget_right_arrow__Wvhaj"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP course-promo-widget_right_arrow_icon__ymabr" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a><a class="tappable row border-bottom course-promo-widget_course_row__iQuP5" href="https://www.scaler.com/topics/course/python-for-beginners/"><img loading="lazy" class="course-promo-widget_instructor_image__8UeLD" src="https://www.scaler.com/topics/images/rahul_janghu.webp" alt="Rahul Janghu" height="56" width="56"><div class="m-l-xxs"><div class="course-promo-widget_course_name__vLsrI">Python Course for Beginners With Certification: Mastering the Essentials</div><div class="course-promo-widget_instructor_name__n_H0k">By Rahul Janghu</div><div class="row flex-ac course-promo-widget_highliter__Psg62"><svg fill="currentColor" class="course-promo-widget_star__rsdml" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg><span class="course-promo-widget_star_rating___7FSQ">4.90</span><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/user-circle-check.svg" class="course-promo-widget_user_registered_icon__EdhwC" height="12" width="12" loading="lazy"><span class="course-promo-widget_user_registered__yGnuK">Enrolled:69256</span></div></div><div class="row flex-ac course-promo-widget_right_arrow__Wvhaj"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP course-promo-widget_right_arrow_icon__ymabr" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a><a class="tappable row border-bottom course-promo-widget_course_row__iQuP5" href="https://www.scaler.com/topics/course/cpp-beginners/"><img loading="lazy" class="course-promo-widget_instructor_image__8UeLD" src="https://www.scaler.com/topics/images/instructor-prateek.webp" alt="Prateek Narang" height="56" width="56"><div class="m-l-xxs"><div class="course-promo-widget_course_name__vLsrI">C++ Course: Learn the Essentials</div><div class="course-promo-widget_instructor_name__n_H0k">By Prateek Narang</div><div class="row flex-ac course-promo-widget_highliter__Psg62"><svg fill="currentColor" class="course-promo-widget_star__rsdml" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg><span class="course-promo-widget_star_rating___7FSQ">5</span><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/user-circle-check.svg" class="course-promo-widget_user_registered_icon__EdhwC" height="12" width="12" loading="lazy"><span class="course-promo-widget_user_registered__yGnuK">Enrolled:41285</span></div></div><div class="row flex-ac course-promo-widget_right_arrow__Wvhaj"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP course-promo-widget_right_arrow_icon__ymabr" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a><a class="tappable row border-bottom course-promo-widget_course_row__iQuP5" href="https://www.scaler.com/topics/course/dbms/"><img loading="lazy" class="course-promo-widget_instructor_image__8UeLD" src="./Skip-Gram Model in NLP - Scaler Topics_files/srikant-varma_instructor.webp" alt="Srikanth Varma" height="56" width="56"><div class="m-l-xxs"><div class="course-promo-widget_course_name__vLsrI">DBMS Course - Master the Fundamentals and Advanced Concepts</div><div class="course-promo-widget_instructor_name__n_H0k">By Srikanth Varma</div><div class="row flex-ac course-promo-widget_highliter__Psg62"><svg fill="currentColor" class="course-promo-widget_star__rsdml" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg><span class="course-promo-widget_star_rating___7FSQ">5</span><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/user-circle-check.svg" class="course-promo-widget_user_registered_icon__EdhwC" height="12" width="12" loading="lazy"><span class="course-promo-widget_user_registered__yGnuK">Enrolled:36088</span></div></div><div class="row flex-ac course-promo-widget_right_arrow__Wvhaj"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP course-promo-widget_right_arrow_icon__ymabr" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a></div></div></div><div class="exit-intent_button_container__Tn1kQ"><a class="tappable exit-intent_viewAll__E3TXv" data-name="courses" data-id="explore_all_courses" href="https://www.scaler.com/topics/courses/">View All</a></div></div></div><div class="show-in-mobile "><div class="popoverMobile_popup__xtxK4 show-in-tablet exit-intent_popup__H38O_" style="height: 70%;"><div class="full-height"><div class="exit-intent_modal_container__O2C8_"><svg fill="currentColor" class="exit-intent_close_icon__lxzbB" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M25.313 8.563l-7.438 7.438 7.438 7.438-1.875 1.875-7.438-7.438-7.438 7.438-1.875-1.875 7.438-7.438-7.438-7.438 1.875-1.875 7.438 7.438 7.438-7.438z"></path></svg><div class="exit-intent_modal_title__WjdtZ"><span class="m-r-xxs"><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/confetti-ball.svg" alt="happy" width="40" height="40" loading="lazy"></span>We’ve a lot more for you to learn from</div><div class="exit-intent_modal_heading__NAT_9"><span class="exit-intent_modal_heading__free_course__Po7pk">Free Courses</span> by Top Scaler Instructors</div><div class="hide-in-mobile exit-intent_coursesList__lx1Sg"><div class="exit-intent_modal_body__t3brF"><a class="all-courses_linkContainer__xmZjN exit-intent_card_container__dVeKU" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/javascript-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height exit-intent_cardBox__0PZUA row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/Course_Listing_312x136_MrinalBhattacharya" alt="JavaScript Course With Certification: Unlocking the Power of JavaScript" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">JavaScript Course With Certification: Unlocking the Power of JavaScript</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Mrinal Bhattacharya</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Kickstart your journey into web development with this free JavaScript course online with a certificate. Designed for beginners, this comprehensive JavaScript online course covers the essential concepts and skills needed to master Javascript, one of the most popular and widely used programming languages in the world. With a course duration of 10 hours and 9 minutes, you'll learn everything from the basics to advanced techniques, all at your own pace.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>4.8</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">35420</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN exit-intent_card_container__dVeKU" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/cpp-beginners/"><div class="all-courses_course_card_box__BNbG3 full-width full-height exit-intent_cardBox__0PZUA row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/cpp_card_master.webp" alt="C++ Course: Learn the Essentials" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">C++ Course: Learn the Essentials</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Prateek Narang</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Gain programming expertise with our Free C++ Course! Covering basics to advanced concepts, this online program provides a comprehensive curriculum encompassing environment setup, variables, conditional statements, loops, functions, pointers, arrays, sorting, character arrays, strings, and more. Perfect for beginners or seasoned programmers looking to enhance their skills and earn a certificate.</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">41285</div></div></div></div></div></a><a class="all-courses_linkContainer__xmZjN exit-intent_card_container__dVeKU" target="_self" rel="noreferrer" href="https://www.scaler.com/topics/course/python-sql-data-science/"><div class="all-courses_course_card_box__BNbG3 full-width full-height exit-intent_cardBox__0PZUA row"><div class="generic-card_generic_card_thumbnail__rOopA generic-card_course_card__DQUM6 row flex-c"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/course_card_image_pds.webp" alt="Python and SQL for Data Science" class="generic-card_image_container__w9tXL generic-card_course_image__n7cof" loading="eager"></div><div class="homepage-lists_card_detail__fJ9w5 column p-t-xs p-b-xxs p-l-xs p-r-xs  all-courses_course_desc__gYBDz homepage-lists_course_text__8b_xS"><div data-testid="heading" class="homepage-lists_card_heading__QotVu">Python and SQL for Data Science</div><span class="all-courses_course_instructor__2WVhs">A Course by  <span class="bold">Srikanth Varma</span></span><p class="homepage-lists_description__ud9fr h5 hide-in-tablet all-courses_course_card_description__XijFr">Introducing the Free Data Science with Python and SQL Certification Course Online, a comprehensive beginner's program designed to help aspiring data scientists learn the essential skills in the rapidly growing field of data science. This course offers a unique blend of practical and theoretical knowledge, combining the powerful programming language Python and the versatile database management system SQL to help you analyze, visualize, and interpret data efficiently.
</p><div class="homepage-lists_hub_footer__sJgXZ row flex-ac"><div class="row full-width p-t-xxs p-r-xxs flex-ac space-between p-t-s"><div class="homepage-lists_star_rating___ENJa"><svg fill="currentColor" class="m-r-xxs homepage-lists_star_icon__JG1vY" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M14.83 2.868c0.342-0.239 0.75-0.368 1.168-0.368s0.826 0.128 1.168 0.368c0.338 0.236 0.596 0.569 0.741 0.955l2.759 6.936c0.003 0.007 0.007 0.013 0.013 0.017s0.013 0.007 0.020 0.007l7.402 0.476c0.411 0.036 0.802 0.194 1.124 0.452s0.559 0.607 0.683 1 0.127 0.815 0.011 1.211c-0.116 0.396-0.347 0.748-0.664 1.013l-5.655 4.714c-0.013 0.011-0.022 0.025-0.028 0.040s-0.006 0.032-0.002 0.047c0 0-0-0 0 0l1.821 7.163c0.107 0.395 0.094 0.812-0.037 1.2-0.133 0.391-0.38 0.734-0.71 0.983s-0.727 0.393-1.14 0.413c-0.413 0.020-0.822-0.084-1.175-0.3l-0.015-0.009-6.307-4.005c-0.004-0.003-0.009-0.004-0.014-0.004s-0.009 0.001-0.013 0.004c-0 0 0-0 0 0l-5.876 3.721c-0.389 0.235-0.839 0.347-1.292 0.323s-0.889-0.184-1.251-0.459c-0.361-0.275-0.632-0.652-0.777-1.082-0.143-0.426-0.157-0.885-0.038-1.319l1.684-6.629c0-0-0 0 0 0 0.004-0.016 0.003-0.033-0.002-0.049s-0.015-0.030-0.027-0.040l-5.653-4.714c-0.317-0.264-0.548-0.617-0.664-1.013s-0.112-0.817 0.011-1.211c0.124-0.394 0.361-0.742 0.683-1s0.713-0.416 1.124-0.452l0.023-0.002 7.38-0.476c0.007-0 0.014-0.003 0.020-0.007s0.010-0.010 0.013-0.017l0.008-0.020 2.746-6.913c0.145-0.386 0.403-0.719 0.741-0.956zM15.998 4.5c-0.008 0-0.015 0.002-0.022 0.007s-0.011 0.011-0.014 0.018l-0.010 0.026-2.747 6.915c-0.139 0.366-0.38 0.684-0.694 0.916-0.317 0.234-0.695 0.372-1.089 0.395l-7.353 0.475c-0.015 0.002-0.029 0.008-0.040 0.018-0.013 0.010-0.023 0.024-0.028 0.040s-0.005 0.033-0 0.049c0.005 0.016 0.014 0.030 0.027 0.041 0 0 0-0 0 0l5.647 4.709c0.001 0-0.001-0 0 0 0.302 0.251 0.529 0.583 0.652 0.955s0.138 0.774 0.043 1.156l-0.001 0.005-1.694 6.667c-0.014 0.051-0.013 0.106 0.004 0.156s0.049 0.095 0.091 0.127c0.042 0.032 0.094 0.051 0.147 0.054 0.051 0.003 0.102-0.009 0.146-0.034l5.854-3.707c0.327-0.205 0.705-0.312 1.090-0.309 0.384 0.003 0.759 0.114 1.081 0.322l6.285 3.991c0.010 0.005 0.020 0.008 0.031 0.007 0.012-0.001 0.024-0.005 0.033-0.012s0.017-0.017 0.021-0.029c0.004-0.011 0.004-0.024 0.001-0.035l-0.006-0.021-1.825-7.181c-0.095-0.382-0.080-0.782 0.043-1.156s0.348-0.703 0.65-0.954c0.001-0 0.001-0.001 0.002-0.001l5.649-4.71c0.013-0.011 0.022-0.025 0.027-0.041s0.005-0.033-0-0.049-0.015-0.030-0.028-0.040c-0.012-0.009-0.026-0.015-0.040-0.018l-7.351-0.473c-0.001-0-0.002-0-0.003-0-0.394-0.024-0.773-0.162-1.090-0.397-0.314-0.233-0.555-0.551-0.693-0.917l-2.76-6.941c-0.003-0.007-0.008-0.014-0.014-0.018s-0.014-0.007-0.022-0.007z"></path></svg>5</div><div class="row flex-ac homepage-lists_registration_count__6efIG"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/user-check-dark.svg" class="m-r-xxs homepage-lists_registered_icon__uQ_cv" loading="lazy">29505</div></div></div></div></div></a></div></div><div class="full-width show-in-mobile"><div class="course-promo-widget_container__ZP0uC"><div><a class="tappable row border-bottom course-promo-widget_course_row__iQuP5" href="https://www.scaler.com/topics/course/java-beginners/"><img loading="lazy" class="course-promo-widget_instructor_image__8UeLD" src="https://www.scaler.com/topics/images/instructor-tarun.webp" alt="Tarun Luthra" height="56" width="56"><div class="m-l-xxs"><div class="course-promo-widget_course_name__vLsrI">Java Course - Mastering the Fundamentals</div><div class="course-promo-widget_instructor_name__n_H0k">By Tarun Luthra</div><div class="row flex-ac course-promo-widget_highliter__Psg62"><svg fill="currentColor" class="course-promo-widget_star__rsdml" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg><span class="course-promo-widget_star_rating___7FSQ">5</span><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/user-circle-check.svg" class="course-promo-widget_user_registered_icon__EdhwC" height="12" width="12" loading="lazy"><span class="course-promo-widget_user_registered__yGnuK">Enrolled:79118</span></div></div><div class="row flex-ac course-promo-widget_right_arrow__Wvhaj"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP course-promo-widget_right_arrow_icon__ymabr" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a><a class="tappable row border-bottom course-promo-widget_course_row__iQuP5" href="https://www.scaler.com/topics/course/python-for-beginners/"><img loading="lazy" class="course-promo-widget_instructor_image__8UeLD" src="https://www.scaler.com/topics/images/rahul_janghu.webp" alt="Rahul Janghu" height="56" width="56"><div class="m-l-xxs"><div class="course-promo-widget_course_name__vLsrI">Python Course for Beginners With Certification: Mastering the Essentials</div><div class="course-promo-widget_instructor_name__n_H0k">By Rahul Janghu</div><div class="row flex-ac course-promo-widget_highliter__Psg62"><svg fill="currentColor" class="course-promo-widget_star__rsdml" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg><span class="course-promo-widget_star_rating___7FSQ">4.90</span><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/user-circle-check.svg" class="course-promo-widget_user_registered_icon__EdhwC" height="12" width="12" loading="lazy"><span class="course-promo-widget_user_registered__yGnuK">Enrolled:69256</span></div></div><div class="row flex-ac course-promo-widget_right_arrow__Wvhaj"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP course-promo-widget_right_arrow_icon__ymabr" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a><a class="tappable row border-bottom course-promo-widget_course_row__iQuP5" href="https://www.scaler.com/topics/course/cpp-beginners/"><img loading="lazy" class="course-promo-widget_instructor_image__8UeLD" src="https://www.scaler.com/topics/images/instructor-prateek.webp" alt="Prateek Narang" height="56" width="56"><div class="m-l-xxs"><div class="course-promo-widget_course_name__vLsrI">C++ Course: Learn the Essentials</div><div class="course-promo-widget_instructor_name__n_H0k">By Prateek Narang</div><div class="row flex-ac course-promo-widget_highliter__Psg62"><svg fill="currentColor" class="course-promo-widget_star__rsdml" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg><span class="course-promo-widget_star_rating___7FSQ">5</span><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/user-circle-check.svg" class="course-promo-widget_user_registered_icon__EdhwC" height="12" width="12" loading="lazy"><span class="course-promo-widget_user_registered__yGnuK">Enrolled:41285</span></div></div><div class="row flex-ac course-promo-widget_right_arrow__Wvhaj"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP course-promo-widget_right_arrow_icon__ymabr" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a><a class="tappable row border-bottom course-promo-widget_course_row__iQuP5" href="https://www.scaler.com/topics/course/dbms/"><img loading="lazy" class="course-promo-widget_instructor_image__8UeLD" src="./Skip-Gram Model in NLP - Scaler Topics_files/srikant-varma_instructor.webp" alt="Srikanth Varma" height="56" width="56"><div class="m-l-xxs"><div class="course-promo-widget_course_name__vLsrI">DBMS Course - Master the Fundamentals and Advanced Concepts</div><div class="course-promo-widget_instructor_name__n_H0k">By Srikanth Varma</div><div class="row flex-ac course-promo-widget_highliter__Psg62"><svg fill="currentColor" class="course-promo-widget_star__rsdml" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg><span class="course-promo-widget_star_rating___7FSQ">5</span><img src="https://d1g0iq4cbcvjcd.cloudfront.net/topics/images/user-circle-check.svg" class="course-promo-widget_user_registered_icon__EdhwC" height="12" width="12" loading="lazy"><span class="course-promo-widget_user_registered__yGnuK">Enrolled:36088</span></div></div><div class="row flex-ac course-promo-widget_right_arrow__Wvhaj"><svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP course-promo-widget_right_arrow_icon__ymabr" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></div></a></div></div></div><div class="exit-intent_button_container__Tn1kQ"><a class="tappable exit-intent_viewAll__E3TXv" data-name="courses" data-id="explore_all_courses" href="https://www.scaler.com/topics/courses/">View All</a></div></div></div></div><div class="popoverMobile_backdrop__KWrmO show-in-tablet"></div></div><footer><div class="full-width feedback_container__imOut"><div role="button" tabindex="0" class="signin-alert-popup_signInWrapper__Kr4eW"><div class="signin-alert-popup_overLay__Xq3de"></div><div class="row flex-c feedback_feedback_container__YUVyH"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/suggestion_bulb.svg" alt="topics" width="24" height="24" loading="lazy"><div class="feedback_description__POrxt">Got suggestions? <a class="Tappable-module_root__N7ll5 topics_link feedback_highlighted_text_bottom__CBT21">We would love to hear your feedback.</a></div></div></div></div><div><div class="sidebar_sidebar_ui__IJWgB hide-in-tablet sidebar_transition__MTYhS feedback_feedback_content__e6Ole"><div class="feedback_form_container__0L_1Q"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/filled_bulb_pink.svg" alt="topics" width="48" height="48" loading="lazy"><span class="feedback_feedback_form_text___aJ6l">Your feedback is important to help us improve</span><form class="p-v-10"><textarea placeholder="Your question and comment here" name="feedback" class="feedback_feedback_form__RcrvD"></textarea></form></div><div class="feedback_btn_container__PVJpo"><a class="Tappable-module_root__N7ll5 feedback_btn_effect__U_NEY"><span class="feedback_close_btn__LOmia">Close</span></a><a class="Tappable-module_root__N7ll5 Tappable-module_disabled__XhpfV topics_btn feedback_submit_btn_effect__m1pbm feedback_submit_btn__YzwTC"><span>Submit</span> <svg fill="currentColor" class="icons_icon_arrow__2GBht icons_icon_arrow__right__WUCHP m-l-5" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M5.313 16l10.688-10.688 10.688 10.688-1.938 1.875-7.438-7.438v16.25h-2.625v-16.25l-7.5 7.438z"></path></svg></a></div></div></div><div class="Footer_footer_main__jhKFJ"><div class="Footer_footer_container__0Gbr1"><div class="Footer_scaler_topics_container__NhfHg"><div class="row flex-ac Footer_scaler_topics__x_37L"><a href="https://www.scaler.com/topics/"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/logo.svg" alt="topics logo" width="53" height="40" loading="lazy"></a><div class="Footer_separator___ExiD"></div><div class="Footer_about_scaler_topic__xVnKx"><div class="bold">A Free learning platform</div><div class="row flex-ac">made with &nbsp;<img src="./Skip-Gram Model in NLP - Scaler Topics_files/icon_heart.svg" alt="heart icon" width="16" height="16" loading="lazy"> &nbsp; by &nbsp;<a href="https://www.scaler.com/?utm_source=topics&amp;utm_medium=footer"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/scaler_logo.svg" alt="scaler logo" width="60" height="8" loading="lazy"></a></div></div></div><div class="row wrap flex-ac Footer_social_media_icons__Cmgt6"><a href="https://www.instagram.com/scaler_official/" target="_blank" rel="noreferrer"><div class="row Footer_social_media_bubble__AMyOI"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/instagram_footer.svg" alt="Instagram" width="32" height="32" loading="lazy"></div></a><a href="https://www.youtube.com/c/SCALER" target="_blank" rel="noreferrer"><div class="row Footer_social_media_bubble__AMyOI"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/youtube_footer.svg" alt="Youtube" width="32" height="32" loading="lazy"></div></a><a href="https://twitter.com/scaler_official" target="_blank" rel="noreferrer"><div class="row Footer_social_media_bubble__AMyOI"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/twitter_footer.svg" alt="Twitter" width="32" height="32" loading="lazy"></div></a><a href="https://www.facebook.com/scalerofficial" target="_blank" rel="noreferrer"><div class="row Footer_social_media_bubble__AMyOI"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/fb_footer.svg" alt="Facebook" width="32" height="32" loading="lazy"></div></a><a href="https://www.linkedin.com/school/scalerofficial/mycompany/" target="_blank" rel="noreferrer"><div class="row Footer_social_media_bubble__AMyOI"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/linkedin_footer.svg" alt="Linkedin" width="32" height="32" loading="lazy"></div></a><a href="https://discord.com/invite/gD2ZTC5j8K" target="_blank" rel="noreferrer"><div class="row Footer_social_media_bubble__AMyOI"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/discord_footer.svg" alt="Discord" width="32" height="32" loading="lazy"></div></a></div></div><div class="Footer_explore_container__EfzLo"><div class="Footer_footer__column__xAs3n"><div class="Footer_footer__heading__f3vN5">Explore Scaler</div><div class="Footer_underLineClassName__gYjXL"></div><ul class="Footer_footer__contents__4EKIb"><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/academy/?utm_source=topics&amp;utm_medium=footer" target="_blank" rel="noreferrer">Academy</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/data-science-course/?utm_source=topics&amp;utm_medium=footer" target="_blank" rel="noreferrer">Data Science &amp; ML</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/neovarsity/?utm_source=topics&amp;utm_medium=footer" target="_blank" rel="noreferrer">Neovarsity</a></li></ul></div><div class="Footer_footer__column__xAs3n"><div class="Footer_footer__heading__f3vN5">Explore Topics</div><div class="Footer_underLineClassName__gYjXL"></div><ul class="Footer_footer__contents__4EKIb"><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/topics/courses/">Courses</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/topics/challenges/">Challenges</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/topics/contests/">Contest</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/topics/hubs/">Topics</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/topics/articles/">Articles</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/topics/events/">Events</a></li></ul></div><div class="Footer_footer__column__xAs3n"><div class="Footer_footer__heading__f3vN5">Resources</div><div class="Footer_underLineClassName__gYjXL"></div><ul class="Footer_footer__contents__4EKIb"><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/about/?utm_source=topics&amp;utm_medium=footer">About Us</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/blog/?utm_source=topics&amp;utm_medium=footer">Blog</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/careers/?utm_source=topics&amp;utm_medium=footer">Careers</a></li><li class="Footer_footer__list___R5w0"><a class="Footer_footer__link__PbMJQ" href="https://www.scaler.com/review/?utm_source=topics&amp;utm_medium=footer">Review</a></li></ul></div></div><div class="Footer_download_app_container__7I8po"><div class="row flex-ac wrap Footer_download_heading_text__0unCX"><div class="bold">Download the &nbsp;</div><img src="./Skip-Gram Model in NLP - Scaler Topics_files/scaler_logo.svg" alt="scaler logo" width="112.5" height="15" loading="lazy"><div class="bold">app!</div></div><div class="Footer_download_subheading_text__b2GAe">Get all scaler resources under one roof!</div><div class="Footer_download_container__ZVMHW"><div><div class="row m-b-xs"><div class="column flex-c"><div class="row flex-ac Footer_rating__85Peu">4.4<svg fill="currentColor" class="Footer_rating__star__IOBaM" version="1.1" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 32 32"><path d="M7.569 30.625c-0.335 0-0.667-0.103-0.949-0.309-0.529-0.382-0.775-1.039-0.631-1.675l1.963-8.65-6.659-5.84c-0.489-0.427-0.676-1.104-0.475-1.724 0.201-0.618 0.747-1.056 1.395-1.115l8.811-0.8 3.485-8.153c0.257-0.599 0.843-0.986 1.492-0.986 0.651 0 1.235 0.386 1.492 0.983l3.484 8.155 8.81 0.8c0.649 0.058 1.195 0.497 1.397 1.115 0.201 0.619 0.014 1.296-0.476 1.724l-6.659 5.839 1.964 8.651c0.144 0.636-0.102 1.293-0.63 1.675-0.527 0.381-1.229 0.411-1.783 0.078l-7.598-4.541-7.598 4.543c-0.257 0.153-0.544 0.23-0.832 0.23z"></path></svg></div><div class="Footer_rating__subtext__FS9tD">1.71 K Reviews</div></div><div class="Footer_rating__separator__uK_xK"></div><div class="column flex-c"><div class="row flex-ac Footer_rating__85Peu">100K+</div><div class="Footer_rating__subtext__FS9tD">Downloads</div></div></div><div class="row"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/topics_footer_web.svg" alt="QR Code" width="48" height="48" class="Footer_qr_code__F2XYl" loading="lazy"><div class="Footer_download_subsection__SvcVD"><a href="https://app.scaler.com/XBSh"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/playstore.svg" alt="Playstore Icon" width="92" height="28" class="Footer_mobile_spacer__Jt_yy" loading="lazy"></a></div></div></div><img src="./Skip-Gram Model in NLP - Scaler Topics_files/app_download_phone.webp" alt="Playstore Icon" width="130" height="130" class="Footer_download_app_phone__38Crd" loading="lazy"></div><a href="https://app.scaler.com/XBSh"><img src="./Skip-Gram Model in NLP - Scaler Topics_files/playstore.svg" alt="Playstore Icon" width="92" height="28" class="full-width row flex-ac Footer_mobile_spacer__Jt_yy Footer_mobile_playstore_icon__Dxy6L" loading="lazy"></a></div></div><div class="Footer_horizontal_separator__72YMO"></div><div class="Footer_seo_container__LpX49"><div class="Footer_seo_heading__F__ls">Popular Free Certification Courses</div><div class="full-width row wrap m-t-xxs Footer_mobile_link_display__A2mzt"><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/java-beginners/" title="Free Java Course Online" class="Footer_link_title__iX4E6">Java Course for Beginners</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/cpp-beginners/" title="Free C++ Course Online" class="Footer_link_title__iX4E6">C++ Course with Certificate</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/python-for-beginners/" title="Free Python Course Online" class="Footer_link_title__iX4E6">Python Course for Beginners</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/javascript-beginners/" title="Free Javascript Course Online" class="Footer_link_title__iX4E6">Javascript Free Course for Beginners</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/python-for-data-science/" title="Free Data Science Course Online" class="Footer_link_title__iX4E6">Data Science Course for Beginners</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/dbms/" title="Free DBMS Course Online" class="Footer_link_title__iX4E6">DBMS Course</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/python-sql-data-science/" title="Free Python for Data Science Course Online" class="Footer_link_title__iX4E6">Python and SQL for Data Science Course</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/dsa-interviews-java/" title="Free DSA Java Interview Questions Online" class="Footer_link_title__iX4E6">DSA Problem Solving for Interviews</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/instagram-system-design/" title="Free Instagram Design Course Online" class="Footer_link_title__iX4E6">Instagram System Design Course</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/course/dynamic-programming/" title="Free Dynamic Programming Course Online" class="Footer_link_title__iX4E6">Dynamic Programming Course</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/courses/" title="All Courses" class="Footer_link_title__iX4E6">All Courses</a></div></div></div><div class="Footer_seo_container__LpX49"><div class="Footer_seo_heading__F__ls">Popular Tutorials</div><div class="full-width row wrap m-t-xxs Footer_mobile_link_display__A2mzt"><div class="row flex-ac"><a href="https://www.scaler.com/topics/python/" title="Python Tutorial Online" class="Footer_link_title__iX4E6">Python Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/java/" title="Java Tutorial Online" class="Footer_link_title__iX4E6">Java Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/dbms/" title="DBMS Tutorial Online" class="Footer_link_title__iX4E6">DBMS Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/javascript/" title="Javascript Tutorial Online" class="Footer_link_title__iX4E6">Javascript Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/cpp/" title="C++ Tutorial Online" class="Footer_link_title__iX4E6">C++ Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/sql/" title="SQL Tutorial Online" class="Footer_link_title__iX4E6">SQL Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/software-engineering/" title="Software Engineering Tutorial Online" class="Footer_link_title__iX4E6">Software Engineering Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/data-science/" title="Data Science Tutorial Online" class="Footer_link_title__iX4E6">Data Science Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/pandas/" title="Pandas Tutorial Online" class="Footer_link_title__iX4E6">Pandas Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/deep-learning/" title="Deep Learning Tutorial Online" class="Footer_link_title__iX4E6">Deep Learning Tutorial</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/hubs/" title="All Tutorials" class="Footer_link_title__iX4E6">All Tutorials</a></div></div></div><div class="Footer_seo_container__LpX49"><div class="Footer_seo_heading__F__ls">Compilers</div><div class="full-width row wrap m-t-xxs Footer_mobile_link_display__A2mzt"><div class="row flex-ac"><a href="https://www.scaler.com/topics/python/online-python-compiler/" title="Python Compiler Online" class="Footer_link_title__iX4E6">Python Compiler</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/java/online-java-compiler/" title="Java Compiler Online" class="Footer_link_title__iX4E6">Java Compiler</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/javascript/online-javascript-compiler/" title="Javascript Compiler Online" class="Footer_link_title__iX4E6">Javascript Compiler</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/c/online-c-compiler/" title="C Compiler Online" class="Footer_link_title__iX4E6">C Compiler</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/cpp/online-cpp-compiler/" title="C++ Compiler Online" class="Footer_link_title__iX4E6">C++ Compiler</a></div></div></div><div class="Footer_seo_container__LpX49"><div class="Footer_seo_heading__F__ls">Tools</div><div class="full-width row wrap m-t-xxs Footer_mobile_link_display__A2mzt"><div class="row flex-ac"><a href="https://www.scaler.com/topics/javascript/json-validator/" title="Json Validator Online" class="Footer_link_title__iX4E6">Json Validator</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/sql/sql-formatter/" title="SQL Formatter Online" class="Footer_link_title__iX4E6">SQL Formatter</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/tools/xml-formatter/" title="XML Formatter Online" class="Footer_link_title__iX4E6">XML Formatter</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/css/css-formatter/" title="CSS Formatter Online" class="Footer_link_title__iX4E6">CSS Formatter</a><span class="Footer_seo_separator__FOJzU"></span></div><div class="row flex-ac"><a href="https://www.scaler.com/topics/javascript/javascript-formatter/" title="JavaScript Formatter Online" class="Footer_link_title__iX4E6">JavaScript Formatter</a></div></div></div><div class="full-width column flex-c Footer_seo_container__LpX49"><div class="m-t-xxs Footer_links__29v39 Footer_copyright__YJEl8"><div>Copyright 2023 InterviewBit Technologies Pvt. Ltd. All Rights Reserved.</div></div><div class="row flex-ac m-t-xxs Footer_links__29v39"><a href="https://www.scaler.com/privacy/?utm_source=topics&amp;utm_medium=footer">Privacy Policy</a><div class="Footer_link_separator__rUm4Q"></div><a href="https://www.scaler.com/terms/?utm_source=topics&amp;utm_medium=footer">Terms of Use</a><div class="Footer_link_separator__rUm4Q"></div><a href="https://www.scaler.com/contact/?utm_source=topics&amp;utm_medium=footer">Contact Us</a></div></div></div></footer></main></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="anonymous">{"props":{"pageProps":{"propsReq":{"pageClass":"no-border","articleInfo":{"article":{"title":"Skip-Gram Model in NLP","slug":"skip-gram-model","published_at":"2023-02-22T00:00:00.000Z","last_updated_at":"2023-05-04T00:00:00.000Z","read_time":8,"description":"Learn about Skip Gram Model","cover_image_alt":"Skip-Gram Model in NLP","cover_image":"https://www.scaler.com/topics/images/skip-gram-model-fi.webp","cover_image_thumbnail":"https://www.scaler.com/topics/images/skip-gram-model-thumbnail.webp","popular":false,"quiz_id":570512,"content":"---\ntitle: Skip-Gram Model in NLP - Scaler Topics\ndescription: With this article by Scaler Topics Learn about Skip-Gram Model in NLP with examples, explanations, and applications, read to know more\ncategory: NLP\nauthor: Navaneeth Malingan\n---\n\n:::section{.abstract}\n## Overview\nThe skip-gram model is a method for **learning word embeddings**, which are continuous, dense, and low-dimensional representations of words in a vocabulary. It is trained using **large amounts of unstructured text** data and can **capture the context** and semantic similarity between words.\n\n:::\n\n\n\n:::section{.main}\n## Introduction\nThe skip-gram model was introduced by Mikolov et al. in their paper \"[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781 \"{rel=noopener nofollow}\")\" (`2013`). The skip-gram model is a way of teaching a computer to understand the **meaning of words based on the context** they are used in. An example would be training a computer to understand the word \"dog\" by looking at sentences where \"dog\" appears and seeing the words that come before and after it. By doing this, the computer will be able to understand how the word \"dog\" is commonly used and will be able to use that understanding in other ways.\n\nHere's an example to illustrate the concept:\n\nLet's say you have the sentence. \n\n**The dog fetched the ball.**\n\nIf you are trying to train a skip-gram model for the word \"dog\", the goal of the model is to predict the context words \"the\" and \"fetched\" given the input word \"dog\". So, the training data for the model would be pairs of the form (input word = \"dog\", context word = \"the\"), (input word = \"dog\", context word = \"fetched\").\n\n:::\n\n:::section{.main}\n## Architecture of Skip-Gram Model\n\nThe architecture of the skip-gram model consists of an **input layer**, an **output layer**, and a **hidden layer**. The input layer is the word to be predicted, and the output layer is the context words. The hidden layer represents the embedding of the input word learned during training. The skip-gram model uses a feedforward neural network with a single hidden layer, as shown in the diagram below:\n\n![skip gram architecture](https://www.scaler.com/topics/images/skip-gram-architecture.webp)\n\n\n\n**Input Layer --\u003e Hidden Layer --\u003e Output Layer**\n\nThe input and output layers are connected to the hidden layer through weights, adjusted during training to minimize the prediction error. The skip-gram model uses a **negative sampling objective function** to optimize the weights and learn the embeddings.\n\nThe skip-gram model is a method for learning word embeddings that captures the **context and semantic similarity** between words in a vocabulary. It is trained using a feedforward neural network with a single hidden layer and is widely used in NLP tasks.\n\n:::\n\n:::section{.main}\n## Implementing the Skip-gram Model\n\nTo implement a skip-gram model for word embeddings, you will need a **large corpus of text in a single language** and tools for preprocessing and tokenizing the text. You can download and access the text using the **Natural Language Toolkit (NLTK)** library.\n\nWe can use `TensorFlow` with the **Keras API** to build and train the model. A skip-gram generator can create training data for the model in pairs of words (the target word and the context word) and labels indicating whether the context word appears within a fixed window size of the target word in the input text.\n\nThe model architecture should include **embedding layers** for the target and context words and a dense layer with a **sigmoid activation** function to predict the probability of the context word appearing within a fixed window of the target word. The trained word embeddings can be extracted from the model once trained. The model can then be compiled with a loss function, an optimizer, and fit on the skip grams.\n\n### Build the Corpus Vocabulary\n\nLet's preprocess the text of the Bible to create a vocabulary of words that we will use to train the word embedding model. This includes **removing punctuation and numbers**, **lowercasing** all the words, and **filtering out empty strings** and lines with fewer than three words. \n\nCalculate the vocabulary size and the size of the embeddings, which is the length of the dense vector representation of each word. Create a **tokenizer** and fit it on the normalized text, and create mappings from words to ids and vice versa.\n\n```python\nimport nltk\nnltk.download('punkt')\nimport tensorflow as tf\nfrom nltk.corpus import gutenberg\nfrom string import punctuation\n# import tf.keras\nfrom keras.preprocessing import text\n\n# download and load the bible text from gutenberg\nnltk.download('gutenberg')\nbible_text = gutenberg.sents('bible-kjv.txt') \n\n# remove punctuation and numbers from the text\nremove_chars = punctuation + '0123456789'\nnormalized_bible = [[word.lower() for word in sent if word not in remove_chars] for sent in bible_text]\n\n# join the tokens back into a string\nnormalized_bible_text = [' '.join(tok_sent) for tok_sent in normalized_bible]\n\n# remove empty strings and lines with fewer than three words\nfiltered_bible_text = list(filter(None, normalized_bible_text))\nfiltered_bible_text = [tok_sent for tok_sent in filtered_bible_text if len(tok_sent.split()) \u003e 2]\n\nprint('Total number of lines in the original corpus:', len(bible_text))\nprint('\\nOriginal sample line:', bible_text[5])\nprint('\\nProcessed sample line:', filtered_bible_text[5])\n\n# create a tokenizer and fit it on the text\ntokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(filtered_bible_text)\n\n# create mapping dictionaries for words to ids and ids to words\nword_to_id = tokenizer.word_index\nid_to_word = {v:k for k, v in word_to_id.items()}\n\n# calculate the vocabulary size\nvocab_size = len(word_to_id) + 1 \nembedding_size = 100\n\n# convert the text to a list of word ids\nword_ids = [[word_to_id[w] for w in text.text_to_word_sequence(doc)] for doc in filtered_bible_text]\nprint('Vocabulary size:', vocab_size)\nprint('Vocabulary sample:', list(word_to_id.items())[:10])\n\n```\n\n**Output**\n```plaintext\n[nltk_data] Downloading package gutenberg to /root/nltk_data...\n[nltk_data]   Package gutenberg is already up-to-date!\nTotal number of lines in the original corpus: 30103\n\nOriginal sample line: ['And', 'the', 'Spirit', 'of', 'God', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters', '.']\n\nProcessed sample line: and the spirit of god moved upon the face of the waters.\nVocabulary size: 12726\nVocabulary sample: [('the', 1), ('and', 2), ('of', 3), ('to', 4), ('that', 5), ('in', 6), ('he', 7), ('shall', 8), ('unto', 9), ('for', 10)]\n```\n\n### Build a Skip-gram [(target, context), relevancy] Generator\n\nGenerate skip grams from the preprocessed text. A skip-gram is a pair of words (the target word and the context word) and a label indicating whether the context word appears within a fixed window size of the target word in the input text. Skip grams are used as training data for the word embedding model.\n\n```python\n# generate skip-grams\nskip_grams = [tf.keras.preprocessing.sequence.skipgrams(wid, vocabulary_size=vocab_size, window_size=10) for wid in word_ids]\n# view sample skip-grams\npairs, labels = skip_grams[0][0], skip_grams[0][1]\nfor i in range(10):\n    print(\"({:s} ({:d}), {:s} ({:d})) -\u003e {:d}\".format(\n          id_to_word[pairs[i][0]], pairs[i][0], \n          id_to_word[pairs[i][1]], pairs[i][1], \n          labels[i]))\n\n```\n\n**Output**\n```plaintext\n(bible (6037), grayheaded (7497)) -\u003e 0\n(bible (6037), lowliness (8668)) -\u003e 0\n(the (1), king (50)) -\u003e 1\n(the (1), particularly (8570)) -\u003e 0\n(king (50), james (1323)) -\u003e 1\n(bible (6037), king (50)) -\u003e 1\n(james (1323), king (50)) -\u003e 1\n(king (50), cause (304)) -\u003e 0\n(the (1), nursed (7168)) -\u003e 0\n(king (50), gently (7579)) -\u003e 0\n```\n\n### Build the Skip-Gram Model Architecture\n\nThe next step is to define the word embedding model's architecture using `Keras's functional API`. The model has two embedding layers for the target and context words, which are concatenated and passed through a dense layer with a sigmoid activation function to predict the probability of the context word appearing within a fixed window of the target word.\n\n```python\nfrom tensorflow.keras.layers import Concatenate, Dense, Embedding, Reshape\nfrom tensorflow.keras.models import Model\n\n# Define the input layers for the target and context words\ntarget_word_input = tf.keras.Input(shape=(1,))\ncontext_word_input = tf.keras.Input(shape=(1,))\n\n# Build skip-gram architecture\ntarget_word_model = Embedding(vocab_size, embedding_size,\n                              embeddings_initializer=\"glorot_uniform\")(target_word_input)\ntarget_word_model = Reshape((embedding_size,))(target_word_model)\n\ncontext_word_model = Embedding(vocab_size, embedding_size,\n                               embeddings_initializer=\"glorot_uniform\")(context_word_input)\ncontext_word_model = Reshape((embedding_size,))(context_word_model)\n\n# Concatenate the output of the target and context models\nmerged = Concatenate(axis=1)([target_word_model, context_word_model])\n\n# Add a dense layer and sigmoid activation\noutput = Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\")(merged)\n\n# Define the model\nmodel = Model(inputs=[target_word_input, context_word_input], outputs=output)\n\n# Compile the model\nmodel.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n\n# View model summary\nprint(model.summary())\n```\n\n**Output**\n```plaintext\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n embedding (Embedding)          (None, 1, 100)       1272600     ['input_3[0][0]']                \n                                                                                                  \n embedding_1 (Embedding)        (None, 1, 100)       1272600     ['input_4[0][0]']                \n                                                                                                  \n reshape (Reshape)              (None, 100)          0           ['embedding[0][0]']              \n                                                                                                  \n reshape_1 (Reshape)            (None, 100)          0           ['embedding_1[0][0]']            \n                                                                                                  \n concatenate (Concatenate)      (None, 200)          0           ['reshape[0][0]',                \n                                                                  'reshape_1[0][0]']              \n                                                                                                  \n dense (Dense)                  (None, 1)            201         ['concatenate[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 2,545,401\nTrainable params: 2,545,401\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n```\n\n### Train the Model\nIn order to train the word embedding model on the skip grams we'll use the fit method. The model is trained for a specified number of epochs, the number of times the model sees the entire dataset during training.\n\n```python\n# train the model on the skip-grams\nfor epoch in range(1, 6):\n    total_loss = 0\n    for i, elem in enumerate(skip_grams):\n        skip_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n        skip_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n        labels = np.array(elem[1], dtype='int32')\n        X = [skip_first_elem, skip_second_elem]\n        Y = labels\n        if i % 10000 == 0:\n            print('Processed {} skip-gram pairs'.format(i))\n        total_loss += model.train_on_batch(X,Y)  \n\n    print('Epoch: {} Loss: {}'.format(epoch, total_loss))\n```\n\n**Output**\n\n```plaintext\nProcessed 0 skip-gram pairs\nProcessed 10000 skip-gram pairs\nProcessed 20000 skip-gram pairs\nEpoch: 1 Loss: 2560.6447135005146 \nProcessed 0 skip-gram pairs\nProcessed 10000 skip-gram pairs \nProcessed 20000 skip-gram pairs \nEpoch: 2 Loss: 2367.486852501519 \nProcessed 0 skip-gram pairs\nProcessed 10000 skip-gram pairs\nProcessed 20000 skip-gram pairs \nEpoch: 3 Loss: 2343.08078927733 \nProcessed 0 skip-gram pairs\nProcessed 10000 skip-gram pairs\nProcessed 20000 skip-gram pairs\nEpoch: 4 Loss: 2325.2062594543386 \nProcessed 0 skip-gram pairs \nProcessed 10000 skip-gram pairs \nProcessed 20000 skip-gram pairs\nEpoch: 5 Loss: 2313.4975586438086\n```\n\n### Get Word Embeddings\nTo see results from the model, we first need to extract the trained word embeddings from the word embedding model. The word embeddings are the weights of the embedding layer, which are the **dense vector representations** of the words in the vocabulary. The shape of the weights tensor is (`vocab_size`, `embedding_size`), where `vocab_size` is the size of the vocabulary and `embedding_size` is the length of the dense vector representation of each word.\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics.pairwise import euclidean_distances\n\n# get the embeddings for the words in the vocabulary\nweights = model.layers[2].get_weights()[0]\n\ndistance_matrix = euclidean_distances(weights)\nprint(distance_matrix.shape)\n\nsimilar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:6]+1] \n                   for search_term in ['god', 'jesus', 'noah', 'egypt', 'john', 'gospel', 'moses','famine']}\n\nprint(similar_words)\n\n# reduce the dimensions of the embeddings using t-SNE\ntsne = TSNE(n_components=2, random_state=0)\nvectors_2d = tsne.fit_transform(weights)\n\n# create a list of the words in the vocabulary\nwords = [id2word[i] for i in range(1, vocab_size)]\n\n# plot the similar words\nfig, ax = plt.subplots(figsize=(20,10))\nfor word in similar_words:\n    ax.scatter(vectors_2d[word2id[word]-1, 0], vectors_2d[word2id[word]-1, 1], c='red', label=word)\n    for sim_word in similar_words[word]:\n        ax.scatter(vectors_2d[word2id[sim_word]-1, 0], vectors_2d[word2id[sim_word]-1, 1], c='blue')\n        ax.annotate(sim_word, (vectors_2d[word2id[sim_word]-1, 0], vectors_2d[word2id[sim_word]-1, 1]))\nax.legend()\nplt.show()\n\n```\n\n**Output**\n\n```plaintext\n(12726, 12726)\n{'god': ['true', 'effect', 'abound', 'waiteth', 'open'],\n 'jesus': ['grievous', 'windows', 'glory', 'lamb', 'did'],\n 'noah': ['teacheth', 'walls', 'residue', 'gathered', 'awake'],\n 'egypt': ['seir', 'beersheba', 'grievous', '108', 'synagogues'],\n 'john': ['gilead', 'fatherless', 'breadth', 'dwell', 'forasmuch'],\n 'gospel': ['seventy', 'cause', 'boards', 'clothed', 'nevertheless'],\n 'moses': ['meet', 'reach', 'youth', 'died', 'scatter'],\n 'famine': ['dogs', 'blasphemy', '33', 'restored', 'jezebel']}\n ```\n\n![dense vector representations example](https://www.scaler.com/topics/images/dense-vector-representations-example.webp)\n\n\n:::\n\n:::section{.summary}\n## Conclusion\n* In conclusion, the `skip-gram model` is a popular method for generating word embeddings, dense vector representations of words in a vocabulary. \n* The `skip-gram model` takes a large corpus of text as input and trains a neural network to predict the context words that appear within a target word's fixed window based on the text's co-occurrence. \n* The word embeddings can be extracted from the weights of the `embedding layer` in the trained model and can be used as input to other natural language processing tasks, such as `text classification`, `sentiment analysis`, and `machine translation`. \n* The skip-gram model has been shown to produce high-quality word embeddings that capture the semantic and syntactic relationships between words in the text, making it a useful tool for a wide range of NLP applications.\n\n:::","course_video_data":[],"collaborators":{"authors":[{"name":"Cathrine Jeeva","slug":"8a7592775cee","email":"cathrinejeeva36@gmail.com","image":"https://lh3.googleusercontent.com/a/AGNmyxagufcaO3g3hr_8MPQH3o4n_uu0B5XLBY7jii9Z5g=s96-c","linkedin_profile":null,"company":null,"designation":null,"github_profile":null,"headline":null}],"co_authors":[],"reviewers":[]},"tags":[{"title":"NLP","slug":"nlp"}],"programs":["data_science"]},"treeMap":{"-1":{"slug":"-1","title":"","read":false,"current":false,"isExpanded":false,"link":"","children":["module_introduction-to-nlp","module_extracting-information-from-text","module_information-retrieval","module_introduction-to-nltk","module_introduction-to-gensim","module_n-grams-for-language-model","module_grammars-for-nlp","module_semantics-in-nlp","module_introduction-to-textblob","module_introduction-to-spacy","module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","module_hmms-and-speech-recognition","module_hello-transformers","module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","module_projects-3cfc2b32-03b9-4491-b6ed-1c7a511960eb"],"parent":"","prev":"","next":"","image":null},"module_introduction-to-nlp":{"slug":"module_introduction-to-nlp","title":"Introduction to NLP","read":false,"current":false,"isExpanded":false,"link":"","children":["what-is-nlp","text-processing-in-nlp","what-is-text-normalization-in-nlp","text-representation-in-nlp"],"parent":"-1","prev":"","next":"","image":null},"what-is-nlp":{"slug":"what-is-nlp","title":"Introduction to NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/what-is-nlp/","children":[],"parent":"module_introduction-to-nlp","prev":"","next":"text-processing-in-nlp","image":null},"text-processing-in-nlp":{"slug":"text-processing-in-nlp","title":"Text Processing in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/text-processing-in-nlp/","children":[],"parent":"module_introduction-to-nlp","prev":"what-is-nlp","next":"what-is-text-normalization-in-nlp","image":null},"what-is-text-normalization-in-nlp":{"slug":"what-is-text-normalization-in-nlp","title":"Normalization of Text in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/what-is-text-normalization-in-nlp/","children":[],"parent":"module_introduction-to-nlp","prev":"text-processing-in-nlp","next":"text-representation-in-nlp","image":null},"text-representation-in-nlp":{"slug":"text-representation-in-nlp","title":"Basic Text Representation in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/text-representation-in-nlp/","children":[],"parent":"module_introduction-to-nlp","prev":"what-is-text-normalization-in-nlp","next":"extract-information-from-text-in-nlp","image":null},"module_extracting-information-from-text":{"slug":"module_extracting-information-from-text","title":"Extracting Information from Text","read":false,"current":false,"isExpanded":false,"link":"","children":["extract-information-from-text-in-nlp","relation-extration-in-nlp","name-entity-recognition-nlp","text-similarity-nlp"],"parent":"-1","prev":"","next":"","image":null},"extract-information-from-text-in-nlp":{"slug":"extract-information-from-text-in-nlp","title":"How to Extract Information from Text in NLP?","read":false,"current":false,"isExpanded":false,"link":"/nlp/extract-information-from-text-in-nlp/","children":[],"parent":"module_extracting-information-from-text","prev":"text-representation-in-nlp","next":"relation-extration-in-nlp","image":null},"relation-extration-in-nlp":{"slug":"relation-extration-in-nlp","title":"Relation Extraction in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/relation-extration-in-nlp/","children":[],"parent":"module_extracting-information-from-text","prev":"extract-information-from-text-in-nlp","next":"name-entity-recognition-nlp","image":null},"name-entity-recognition-nlp":{"slug":"name-entity-recognition-nlp","title":"What is Name Entity Recognition in NLP?","read":false,"current":false,"isExpanded":false,"link":"/nlp/name-entity-recognition-nlp/","children":[],"parent":"module_extracting-information-from-text","prev":"relation-extration-in-nlp","next":"text-similarity-nlp","image":null},"text-similarity-nlp":{"slug":"text-similarity-nlp","title":"Text Similarity in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/text-similarity-nlp/","children":[],"parent":"module_extracting-information-from-text","prev":"name-entity-recognition-nlp","next":"information-retrieval-nlp","image":null},"module_information-retrieval":{"slug":"module_information-retrieval","title":"Information retrieval","read":false,"current":false,"isExpanded":false,"link":"","children":["information-retrieval-nlp","nlp-ir-models","ir-evaluation-nlp","ir-application-in-nlp"],"parent":"-1","prev":"","next":"","image":null},"information-retrieval-nlp":{"slug":"information-retrieval-nlp","title":"Introduction to Information Retrieval in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/information-retrieval-nlp/","children":[],"parent":"module_information-retrieval","prev":"text-similarity-nlp","next":"nlp-ir-models","image":null},"nlp-ir-models":{"slug":"nlp-ir-models","title":"Models for IR in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/nlp-ir-models/","children":[],"parent":"module_information-retrieval","prev":"information-retrieval-nlp","next":"ir-evaluation-nlp","image":null},"ir-evaluation-nlp":{"slug":"ir-evaluation-nlp","title":"Evaluation of IR in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/ir-evaluation-nlp/","children":[],"parent":"module_information-retrieval","prev":"nlp-ir-models","next":"ir-application-in-nlp","image":null},"ir-application-in-nlp":{"slug":"ir-application-in-nlp","title":"Application of IR in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/ir-application-in-nlp/","children":[],"parent":"module_information-retrieval","prev":"ir-evaluation-nlp","next":"getting-started-with-nltk-in-nlp","image":null},"module_introduction-to-nltk":{"slug":"module_introduction-to-nltk","title":"Introduction to NLTK","read":false,"current":false,"isExpanded":false,"link":"","children":["getting-started-with-nltk-in-nlp","nltk-in-nlp-python"],"parent":"-1","prev":"","next":"","image":null},"getting-started-with-nltk-in-nlp":{"slug":"getting-started-with-nltk-in-nlp","title":"Getting Started with NLTK in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/getting-started-with-nltk-in-nlp/","children":[],"parent":"module_introduction-to-nltk","prev":"ir-application-in-nlp","next":"nltk-in-nlp-python","image":null},"nltk-in-nlp-python":{"slug":"nltk-in-nlp-python","title":"Quickstart With Python’s NLTK in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/nltk-in-nlp-python/","children":[],"parent":"module_introduction-to-nltk","prev":"getting-started-with-nltk-in-nlp","next":"gensim-nlp","image":null},"module_introduction-to-gensim":{"slug":"module_introduction-to-gensim","title":"Introduction to Gensim","read":false,"current":false,"isExpanded":false,"link":"","children":["gensim-nlp","genism-application"],"parent":"-1","prev":"","next":"","image":null},"gensim-nlp":{"slug":"gensim-nlp","title":"Introduction to Gensim in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/gensim-nlp/","children":[],"parent":"module_introduction-to-gensim","prev":"nltk-in-nlp-python","next":"genism-application","image":null},"genism-application":{"slug":"genism-application","title":"Gensim Applications","read":false,"current":false,"isExpanded":false,"link":"/nlp/genism-application/","children":[],"parent":"module_introduction-to-gensim","prev":"gensim-nlp","next":"ngrams-in-nlp","image":null},"module_n-grams-for-language-model":{"slug":"module_n-grams-for-language-model","title":"N-grams for Language Model","read":false,"current":false,"isExpanded":false,"link":"","children":["ngrams-in-nlp","probability-theory-nlp","n-gram-model-in-nlp","backoff-in-nlp","language-models-in-nlp","generalization-and-zeros-in-nlp"],"parent":"-1","prev":"","next":"","image":null},"ngrams-in-nlp":{"slug":"ngrams-in-nlp","title":"Introduction to N-grams in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/ngrams-in-nlp/","children":[],"parent":"module_n-grams-for-language-model","prev":"genism-application","next":"probability-theory-nlp","image":null},"probability-theory-nlp":{"slug":"probability-theory-nlp","title":"Introduction to Probability Theory in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/probability-theory-nlp/","children":[],"parent":"module_n-grams-for-language-model","prev":"ngrams-in-nlp","next":"n-gram-model-in-nlp","image":null},"n-gram-model-in-nlp":{"slug":"n-gram-model-in-nlp","title":"Simple (Unsmoothed) N-gram in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/n-gram-model-in-nlp/","children":[],"parent":"module_n-grams-for-language-model","prev":"probability-theory-nlp","next":"backoff-in-nlp","image":null},"backoff-in-nlp":{"slug":"backoff-in-nlp","title":"Backoff in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/backoff-in-nlp/","children":[],"parent":"module_n-grams-for-language-model","prev":"n-gram-model-in-nlp","next":"language-models-in-nlp","image":null},"language-models-in-nlp":{"slug":"language-models-in-nlp","title":"Evaluating Language Models in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/language-models-in-nlp/","children":[],"parent":"module_n-grams-for-language-model","prev":"backoff-in-nlp","next":"generalization-and-zeros-in-nlp","image":null},"generalization-and-zeros-in-nlp":{"slug":"generalization-and-zeros-in-nlp","title":"Generalization and Zeros in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/generalization-and-zeros-in-nlp/","children":[],"parent":"module_n-grams-for-language-model","prev":"language-models-in-nlp","next":"introduction-to-grammar-in-nlp","image":null},"module_grammars-for-nlp":{"slug":"module_grammars-for-nlp","title":"Grammars for NLP","read":false,"current":false,"isExpanded":false,"link":"","children":["introduction-to-grammar-in-nlp","lexicalized-and-probabilistic-parsing","sentence-level-constructions-nlp","parser-in-nlp","earley-algorithm"],"parent":"-1","prev":"","next":"","image":null},"introduction-to-grammar-in-nlp":{"slug":"introduction-to-grammar-in-nlp","title":"Introduction to Grammar in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/introduction-to-grammar-in-nlp/","children":[],"parent":"module_grammars-for-nlp","prev":"generalization-and-zeros-in-nlp","next":"lexicalized-and-probabilistic-parsing","image":null},"lexicalized-and-probabilistic-parsing":{"slug":"lexicalized-and-probabilistic-parsing","title":"Lexicalized and Probabilistic Parsing","read":false,"current":false,"isExpanded":false,"link":"/nlp/lexicalized-and-probabilistic-parsing/","children":[],"parent":"module_grammars-for-nlp","prev":"introduction-to-grammar-in-nlp","next":"sentence-level-constructions-nlp","image":null},"sentence-level-constructions-nlp":{"slug":"sentence-level-constructions-nlp","title":"Sentence-Level Constructions","read":false,"current":false,"isExpanded":false,"link":"/nlp/sentence-level-constructions-nlp/","children":[],"parent":"module_grammars-for-nlp","prev":"lexicalized-and-probabilistic-parsing","next":"parser-in-nlp","image":null},"parser-in-nlp":{"slug":"parser-in-nlp","title":"A Basic Parser in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/parser-in-nlp/","children":[],"parent":"module_grammars-for-nlp","prev":"sentence-level-constructions-nlp","next":"earley-algorithm","image":null},"earley-algorithm":{"slug":"earley-algorithm","title":"The Earley Algorithm","read":false,"current":false,"isExpanded":false,"link":"/nlp/earley-algorithm/","children":[],"parent":"module_grammars-for-nlp","prev":"parser-in-nlp","next":"elements-of-semantic-analysis","image":null},"module_semantics-in-nlp":{"slug":"module_semantics-in-nlp","title":"Semantics in NLP ","read":false,"current":true,"isExpanded":true,"link":"","children":["elements-of-semantic-analysis","computational-desiderata-for-representations","nlp-language-structure","syntax-driven-semantic-analysis-in-nlp","word-classes-and-part-of-speech-tagging-in-nlp","wordnet-in-nlp","word2vec","cbow","skip-gram-model","word-embedding-visualization","glove-embeddings"],"parent":"-1","prev":"","next":"","image":null},"elements-of-semantic-analysis":{"slug":"elements-of-semantic-analysis","title":"Elements of Semantic Analysis in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/elements-of-semantic-analysis/","children":[],"parent":"module_semantics-in-nlp","prev":"earley-algorithm","next":"computational-desiderata-for-representations","image":null},"computational-desiderata-for-representations":{"slug":"computational-desiderata-for-representations","title":"Computational Desiderata for Representations","read":false,"current":false,"isExpanded":false,"link":"/nlp/computational-desiderata-for-representations/","children":[],"parent":"module_semantics-in-nlp","prev":"elements-of-semantic-analysis","next":"nlp-language-structure","image":null},"nlp-language-structure":{"slug":"nlp-language-structure","title":"Meaning | Structure of Language in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/nlp-language-structure/","children":[],"parent":"module_semantics-in-nlp","prev":"computational-desiderata-for-representations","next":"syntax-driven-semantic-analysis-in-nlp","image":null},"syntax-driven-semantic-analysis-in-nlp":{"slug":"syntax-driven-semantic-analysis-in-nlp","title":"Syntax-Driven Semantic Analysis in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/syntax-driven-semantic-analysis-in-nlp/","children":[],"parent":"module_semantics-in-nlp","prev":"nlp-language-structure","next":"word-classes-and-part-of-speech-tagging-in-nlp","image":null},"word-classes-and-part-of-speech-tagging-in-nlp":{"slug":"word-classes-and-part-of-speech-tagging-in-nlp","title":"Word Classes and Part-of-Speech Tagging in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/word-classes-and-part-of-speech-tagging-in-nlp/","children":[],"parent":"module_semantics-in-nlp","prev":"syntax-driven-semantic-analysis-in-nlp","next":"wordnet-in-nlp","image":null},"wordnet-in-nlp":{"slug":"wordnet-in-nlp","title":"Wordnet in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/wordnet-in-nlp/","children":[],"parent":"module_semantics-in-nlp","prev":"word-classes-and-part-of-speech-tagging-in-nlp","next":"word2vec","image":null},"word2vec":{"slug":"word2vec","title":"Word2Vec in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/word2vec/","children":[],"parent":"module_semantics-in-nlp","prev":"wordnet-in-nlp","next":"cbow","image":null},"cbow":{"slug":"cbow","title":"Continuous Bag of Words (CBOW) Model in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/cbow/","children":[],"parent":"module_semantics-in-nlp","prev":"word2vec","next":"skip-gram-model","image":null},"skip-gram-model":{"slug":"skip-gram-model","title":"Skip-Gram Model in NLP","read":false,"current":true,"isExpanded":true,"link":"/nlp/skip-gram-model/","children":[],"parent":"module_semantics-in-nlp","prev":"cbow","next":"word-embedding-visualization","image":null},"word-embedding-visualization":{"slug":"word-embedding-visualization","title":"Building the Word2vec Model Using Gensim","read":false,"current":false,"isExpanded":false,"link":"/nlp/word-embedding-visualization/","children":[],"parent":"module_semantics-in-nlp","prev":"skip-gram-model","next":"glove-embeddings","image":null},"glove-embeddings":{"slug":"glove-embeddings","title":"GloVe in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/glove-embeddings/","children":[],"parent":"module_semantics-in-nlp","prev":"word-embedding-visualization","next":"nlp-textblob","image":null},"module_introduction-to-textblob":{"slug":"module_introduction-to-textblob","title":"Introduction to TextBlob","read":false,"current":false,"isExpanded":false,"link":"","children":["nlp-textblob"],"parent":"-1","prev":"","next":"","image":null},"nlp-textblob":{"slug":"nlp-textblob","title":"Introduction to TextBlob in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/nlp-textblob/","children":[],"parent":"module_introduction-to-textblob","prev":"glove-embeddings","next":"statistical-model-spacy","image":null},"module_introduction-to-spacy":{"slug":"module_introduction-to-spacy","title":"Introduction to Spacy ","read":false,"current":false,"isExpanded":false,"link":"","children":["statistical-model-spacy","processing-pipeline-spacy"],"parent":"-1","prev":"","next":"","image":null},"statistical-model-spacy":{"slug":"statistical-model-spacy","title":"spaCy’s Statistical Models","read":false,"current":false,"isExpanded":false,"link":"/nlp/statistical-model-spacy/","children":[],"parent":"module_introduction-to-spacy","prev":"nlp-textblob","next":"processing-pipeline-spacy","image":null},"processing-pipeline-spacy":{"slug":"processing-pipeline-spacy","title":"spaCy’s Processing Pipeline","read":false,"current":false,"isExpanded":false,"link":"/nlp/processing-pipeline-spacy/","children":[],"parent":"module_introduction-to-spacy","prev":"statistical-model-spacy","next":"topic-modelling-in-natural-language-processing","image":null},"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299":{"slug":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","title":"NLP Topic Modeling","read":false,"current":false,"isExpanded":false,"link":"","children":["topic-modelling-in-natural-language-processing","what-is-pca","pca-techniques","non-negative-matrix-factorization","latent-semantic-allocation","plsa-probabilistic-latent-semantic-analysis","lda2vec","tbert-topic-bert"],"parent":"-1","prev":"","next":"","image":null},"topic-modelling-in-natural-language-processing":{"slug":"topic-modelling-in-natural-language-processing","title":"Introduction to Topic Modelling in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/topic-modelling-in-natural-language-processing/","children":[],"parent":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","prev":"processing-pipeline-spacy","next":"what-is-pca","image":null},"what-is-pca":{"slug":"what-is-pca","title":"Principal Component Analysis (PCA)","read":false,"current":false,"isExpanded":false,"link":"/nlp/what-is-pca/","children":[],"parent":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","prev":"topic-modelling-in-natural-language-processing","next":"pca-techniques","image":null},"pca-techniques":{"slug":"pca-techniques","title":"Techniques for PCA","read":false,"current":false,"isExpanded":false,"link":"/nlp/pca-techniques/","children":[],"parent":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","prev":"what-is-pca","next":"non-negative-matrix-factorization","image":null},"non-negative-matrix-factorization":{"slug":"non-negative-matrix-factorization","title":"Non-Negative Matrix Factorization","read":false,"current":false,"isExpanded":false,"link":"/nlp/non-negative-matrix-factorization/","children":[],"parent":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","prev":"pca-techniques","next":"latent-semantic-allocation","image":null},"latent-semantic-allocation":{"slug":"latent-semantic-allocation","title":"LSA – Latent Semantic Allocation","read":false,"current":false,"isExpanded":false,"link":"/nlp/latent-semantic-allocation/","children":[],"parent":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","prev":"non-negative-matrix-factorization","next":"plsa-probabilistic-latent-semantic-analysis","image":null},"plsa-probabilistic-latent-semantic-analysis":{"slug":"plsa-probabilistic-latent-semantic-analysis","title":"PLSA – Probabilistic Latent Semantic Analysis","read":false,"current":false,"isExpanded":false,"link":"/nlp/plsa-probabilistic-latent-semantic-analysis/","children":[],"parent":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","prev":"latent-semantic-allocation","next":"lda2vec","image":null},"lda2vec":{"slug":"lda2vec","title":"lda2vec – deep learning model","read":false,"current":false,"isExpanded":false,"link":"/nlp/lda2vec/","children":[],"parent":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","prev":"plsa-probabilistic-latent-semantic-analysis","next":"tbert-topic-bert","image":null},"tbert-topic-bert":{"slug":"tbert-topic-bert","title":"tBERT – Topic BERT in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/tbert-topic-bert/","children":[],"parent":"module_nlp-topic-modeling-86a2098d-16c0-4753-915c-e08ad15e6299","prev":"lda2vec","next":"architecture-of-automatic-speech-recognition","image":null},"module_hmms-and-speech-recognition":{"slug":"module_hmms-and-speech-recognition","title":"HMMs and Speech Recognition","read":false,"current":false,"isExpanded":false,"link":"","children":["architecture-of-automatic-speech-recognition","acoustic-properties-of-speech","decoding-methods"],"parent":"-1","prev":"","next":"","image":null},"architecture-of-automatic-speech-recognition":{"slug":"architecture-of-automatic-speech-recognition","title":"Speech Recognition Architecture","read":false,"current":false,"isExpanded":false,"link":"/nlp/architecture-of-automatic-speech-recognition/","children":[],"parent":"module_hmms-and-speech-recognition","prev":"tbert-topic-bert","next":"acoustic-properties-of-speech","image":null},"acoustic-properties-of-speech":{"slug":"acoustic-properties-of-speech","title":"Acoustic Properties of Speech","read":false,"current":false,"isExpanded":false,"link":"/nlp/acoustic-properties-of-speech/","children":[],"parent":"module_hmms-and-speech-recognition","prev":"architecture-of-automatic-speech-recognition","next":"decoding-methods","image":null},"decoding-methods":{"slug":"decoding-methods","title":"Advanced Methods for Decoding","read":false,"current":false,"isExpanded":false,"link":"/nlp/decoding-methods/","children":[],"parent":"module_hmms-and-speech-recognition","prev":"acoustic-properties-of-speech","next":"nlp-transformers-application","image":null},"module_hello-transformers":{"slug":"module_hello-transformers","title":"Hello Transformers","read":false,"current":false,"isExpanded":false,"link":"","children":["nlp-transformers-application","transformer-encoder-decoder","positional-encoding","transformer-decoder","encoder-and-decoder","bert-model","pre-training-bert","masked-language-model-explained","bert-next-sentence-prediction","subword-tokenization-algorithms","pre-trained-models","huggingface-transformers","fine-tuning-bert","bert-question-answering","bert-variants"],"parent":"-1","prev":"","next":"","image":null},"nlp-transformers-application":{"slug":"nlp-transformers-application","title":"Applications of Transformers","read":false,"current":false,"isExpanded":false,"link":"/nlp/nlp-transformers-application/","children":[],"parent":"module_hello-transformers","prev":"decoding-methods","next":"transformer-encoder-decoder","image":null},"transformer-encoder-decoder":{"slug":"transformer-encoder-decoder","title":"What are Encoder in Transformers","read":false,"current":false,"isExpanded":false,"link":"/nlp/transformer-encoder-decoder/","children":[],"parent":"module_hello-transformers","prev":"nlp-transformers-application","next":"positional-encoding","image":null},"positional-encoding":{"slug":"positional-encoding","title":"Learning position with Positional Encoding","read":false,"current":false,"isExpanded":false,"link":"/nlp/positional-encoding/","children":[],"parent":"module_hello-transformers","prev":"transformer-encoder-decoder","next":"transformer-decoder","image":null},"transformer-decoder":{"slug":"transformer-decoder","title":"What is Decoder in Transformers","read":false,"current":false,"isExpanded":false,"link":"/nlp/transformer-decoder/","children":[],"parent":"module_hello-transformers","prev":"positional-encoding","next":"encoder-and-decoder","image":null},"encoder-and-decoder":{"slug":"encoder-and-decoder","title":"Putting Encoder - Decoder Together","read":false,"current":false,"isExpanded":false,"link":"/nlp/encoder-and-decoder/","children":[],"parent":"module_hello-transformers","prev":"transformer-decoder","next":"bert-model","image":null},"bert-model":{"slug":"bert-model","title":"BERT Model in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/bert-model/","children":[],"parent":"module_hello-transformers","prev":"encoder-and-decoder","next":"pre-training-bert","image":null},"pre-training-bert":{"slug":"pre-training-bert","title":"Pre-training the BERT model","read":false,"current":false,"isExpanded":false,"link":"/nlp/pre-training-bert/","children":[],"parent":"module_hello-transformers","prev":"bert-model","next":"masked-language-model-explained","image":null},"masked-language-model-explained":{"slug":"masked-language-model-explained","title":"Masked Language Modeling in BERT","read":false,"current":false,"isExpanded":false,"link":"/nlp/masked-language-model-explained/","children":[],"parent":"module_hello-transformers","prev":"pre-training-bert","next":"bert-next-sentence-prediction","image":null},"bert-next-sentence-prediction":{"slug":"bert-next-sentence-prediction","title":"Next sentence prediction with BERT","read":false,"current":false,"isExpanded":false,"link":"/nlp/bert-next-sentence-prediction/","children":[],"parent":"module_hello-transformers","prev":"masked-language-model-explained","next":"subword-tokenization-algorithms","image":null},"subword-tokenization-algorithms":{"slug":"subword-tokenization-algorithms","title":"Subword Tokenization Algorithms","read":false,"current":false,"isExpanded":false,"link":"/nlp/subword-tokenization-algorithms/","children":[],"parent":"module_hello-transformers","prev":"bert-next-sentence-prediction","next":"pre-trained-models","image":null},"pre-trained-models":{"slug":"pre-trained-models","title":"Hands-with BERT in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/pre-trained-models/","children":[],"parent":"module_hello-transformers","prev":"subword-tokenization-algorithms","next":"huggingface-transformers","image":null},"huggingface-transformers":{"slug":"huggingface-transformers","title":"Extracting embeddings from pre-trained BERT| Huggingface Transformers","read":false,"current":false,"isExpanded":false,"link":"/nlp/huggingface-transformers/","children":[],"parent":"module_hello-transformers","prev":"pre-trained-models","next":"fine-tuning-bert","image":null},"fine-tuning-bert":{"slug":"fine-tuning-bert","title":"fine-tuning BERT for downstream tasks","read":false,"current":false,"isExpanded":false,"link":"/nlp/fine-tuning-bert/","children":[],"parent":"module_hello-transformers","prev":"huggingface-transformers","next":"bert-question-answering","image":null},"bert-question-answering":{"slug":"bert-question-answering","title":"Question-answering with BERT","read":false,"current":false,"isExpanded":false,"link":"/nlp/bert-question-answering/","children":[],"parent":"module_hello-transformers","prev":"fine-tuning-bert","next":"bert-variants","image":null},"bert-variants":{"slug":"bert-variants","title":"Exploring Variants of BERT (Overview)","read":false,"current":false,"isExpanded":false,"link":"/nlp/bert-variants/","children":[],"parent":"module_hello-transformers","prev":"bert-question-answering","next":"pragmatics-in-nlp","image":null},"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a":{"slug":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","title":"Miscellaneous","read":false,"current":false,"isExpanded":false,"link":"","children":["pragmatics-in-nlp","discourse-in-nlp","siamese-networks-in-nlp","learning-without-supervision-in-nlp","non-linear-classification-text-in-nlp","nlp-text-classification-using-scikit-learn","introduction-to-nlp-with-keras","how-to-use-nlp-on-cloud","adversarial-search-in-nlp","constraint-satisfaction-problem-in-ai","bleu-score-in-nlp","fuzzy-search-in-nlp","nlp-engines","rasa-chatbots","stanford-nlp","spark-nlp","google-nlp","elmo-nlp"],"parent":"-1","prev":"","next":"","image":null},"pragmatics-in-nlp":{"slug":"pragmatics-in-nlp","title":"Pragmatics in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/pragmatics-in-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"bert-variants","next":"discourse-in-nlp","image":null},"discourse-in-nlp":{"slug":"discourse-in-nlp","title":"Discourse in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/discourse-in-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"pragmatics-in-nlp","next":"siamese-networks-in-nlp","image":null},"siamese-networks-in-nlp":{"slug":"siamese-networks-in-nlp","title":"Siamese Networks in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/siamese-networks-in-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"discourse-in-nlp","next":"learning-without-supervision-in-nlp","image":null},"learning-without-supervision-in-nlp":{"slug":"learning-without-supervision-in-nlp","title":"Learning without Supervision in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/learning-without-supervision-in-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"siamese-networks-in-nlp","next":"non-linear-classification-text-in-nlp","image":null},"non-linear-classification-text-in-nlp":{"slug":"non-linear-classification-text-in-nlp","title":"Non Linear Classification Text in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/non-linear-classification-text-in-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"learning-without-supervision-in-nlp","next":"nlp-text-classification-using-scikit-learn","image":null},"nlp-text-classification-using-scikit-learn":{"slug":"nlp-text-classification-using-scikit-learn","title":"NLP Text Classification Using Scikit-Learn","read":false,"current":false,"isExpanded":false,"link":"/nlp/nlp-text-classification-using-scikit-learn/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"non-linear-classification-text-in-nlp","next":"introduction-to-nlp-with-keras","image":null},"introduction-to-nlp-with-keras":{"slug":"introduction-to-nlp-with-keras","title":"Introduction to NLP with Keras","read":false,"current":false,"isExpanded":false,"link":"/nlp/introduction-to-nlp-with-keras/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"nlp-text-classification-using-scikit-learn","next":"how-to-use-nlp-on-cloud","image":null},"how-to-use-nlp-on-cloud":{"slug":"how-to-use-nlp-on-cloud","title":"How to use NLP on Cloud","read":false,"current":false,"isExpanded":false,"link":"/nlp/how-to-use-nlp-on-cloud/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"introduction-to-nlp-with-keras","next":"adversarial-search-in-nlp","image":null},"adversarial-search-in-nlp":{"slug":"adversarial-search-in-nlp","title":"Adversarial Search in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/adversarial-search-in-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"how-to-use-nlp-on-cloud","next":"constraint-satisfaction-problem-in-ai","image":null},"constraint-satisfaction-problem-in-ai":{"slug":"constraint-satisfaction-problem-in-ai","title":"Constraint Satisfaction Problem in AI","read":false,"current":false,"isExpanded":false,"link":"/nlp/constraint-satisfaction-problem-in-ai/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"adversarial-search-in-nlp","next":"bleu-score-in-nlp","image":null},"bleu-score-in-nlp":{"slug":"bleu-score-in-nlp","title":"Bleu Score in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/bleu-score-in-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"constraint-satisfaction-problem-in-ai","next":"fuzzy-search-in-nlp","image":null},"fuzzy-search-in-nlp":{"slug":"fuzzy-search-in-nlp","title":"Fuzzy Search in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/fuzzy-search-in-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"bleu-score-in-nlp","next":"nlp-engines","image":null},"nlp-engines":{"slug":"nlp-engines","title":"Top NLP Engines","read":false,"current":false,"isExpanded":false,"link":"/nlp/nlp-engines/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"fuzzy-search-in-nlp","next":"rasa-chatbots","image":null},"rasa-chatbots":{"slug":"rasa-chatbots","title":"Rasa in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/rasa-chatbots/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"nlp-engines","next":"stanford-nlp","image":null},"stanford-nlp":{"slug":"stanford-nlp","title":"Introduction to Stanford NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/stanford-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"rasa-chatbots","next":"spark-nlp","image":null},"spark-nlp":{"slug":"spark-nlp","title":"Spark NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/spark-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"stanford-nlp","next":"google-nlp","image":null},"google-nlp":{"slug":"google-nlp","title":"Google NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/google-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"spark-nlp","next":"elmo-nlp","image":null},"elmo-nlp":{"slug":"elmo-nlp","title":"ELMo NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/elmo-nlp/","children":[],"parent":"module_miscellaneous-d1324195-4502-44c3-8a60-726a0c67257a","prev":"google-nlp","next":"build-news-search-engine-using-nlp","image":null},"module_projects-3cfc2b32-03b9-4491-b6ed-1c7a511960eb":{"slug":"module_projects-3cfc2b32-03b9-4491-b6ed-1c7a511960eb","title":"Projects","read":false,"current":false,"isExpanded":false,"link":"","children":["build-news-search-engine-using-nlp","identify-topics-from-news-items-with-nlp","create-a-spell-check-with-nlp","create-your-own-nlp-module","building-a-text-summarizer-in-nlp"],"parent":"-1","prev":"","next":"","image":null},"build-news-search-engine-using-nlp":{"slug":"build-news-search-engine-using-nlp","title":"How to build a News Search Engine with NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/build-news-search-engine-using-nlp/","children":[],"parent":"module_projects-3cfc2b32-03b9-4491-b6ed-1c7a511960eb","prev":"elmo-nlp","next":"identify-topics-from-news-items-with-nlp","image":null},"identify-topics-from-news-items-with-nlp":{"slug":"identify-topics-from-news-items-with-nlp","title":"Identify Topics from News Items with NLP ","read":false,"current":false,"isExpanded":false,"link":"/nlp/identify-topics-from-news-items-with-nlp/","children":[],"parent":"module_projects-3cfc2b32-03b9-4491-b6ed-1c7a511960eb","prev":"build-news-search-engine-using-nlp","next":"create-a-spell-check-with-nlp","image":null},"create-a-spell-check-with-nlp":{"slug":"create-a-spell-check-with-nlp","title":"How to create a Spell Checker with NLP?","read":false,"current":false,"isExpanded":false,"link":"/nlp/create-a-spell-check-with-nlp/","children":[],"parent":"module_projects-3cfc2b32-03b9-4491-b6ed-1c7a511960eb","prev":"identify-topics-from-news-items-with-nlp","next":"create-your-own-nlp-module","image":null},"create-your-own-nlp-module":{"slug":"create-your-own-nlp-module","title":"How to create your Own NLP Module?","read":false,"current":false,"isExpanded":false,"link":"/nlp/create-your-own-nlp-module/","children":[],"parent":"module_projects-3cfc2b32-03b9-4491-b6ed-1c7a511960eb","prev":"create-a-spell-check-with-nlp","next":"building-a-text-summarizer-in-nlp","image":null},"building-a-text-summarizer-in-nlp":{"slug":"building-a-text-summarizer-in-nlp","title":"Building a Text Summarizer in NLP","read":false,"current":false,"isExpanded":false,"link":"/nlp/building-a-text-summarizer-in-nlp/","children":[],"parent":"module_projects-3cfc2b32-03b9-4491-b6ed-1c7a511960eb","prev":"create-your-own-nlp-module","next":"","image":null}},"nextSlug":"word-embedding-visualization","prevSlug":"cbow","breadcrumb":[{"slug":"/hubs","title":"Reading Tracks","link":"/hubs","type":"reading-track"},{"slug":"nlp","title":"NLP Tutorial","link":"/nlp"},{"slug":"skip-gram-model","title":"Skip-Gram Model in NLP","link":""}],"hubInfo":{"slug":"nlp","title":"NLP Tutorial","eligible_for_certificate":false},"mappedCourseSlug":""}},"objectType":"Article","metaDetails":{"title":"Skip-Gram Model in NLP - Scaler Topics","description":"With this article by Scaler Topics Learn about Skip-Gram Model in NLP with examples, explanations, and applications, read to know more","category":"NLP","author":"Navaneeth Malingan","publish_date":"undefined"},"contentData":"\n:::section{.abstract}\n## Overview\nThe skip-gram model is a method for **learning word embeddings**, which are continuous, dense, and low-dimensional representations of words in a vocabulary. It is trained using **large amounts of unstructured text** data and can **capture the context** and semantic similarity between words.\n\n:::\n\n\n\n:::section{.main}\n## Introduction\nThe skip-gram model was introduced by Mikolov et al. in their paper \"[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781 \"{rel=noopener nofollow}\")\" (`2013`). The skip-gram model is a way of teaching a computer to understand the **meaning of words based on the context** they are used in. An example would be training a computer to understand the word \"dog\" by looking at sentences where \"dog\" appears and seeing the words that come before and after it. By doing this, the computer will be able to understand how the word \"dog\" is commonly used and will be able to use that understanding in other ways.\n\nHere's an example to illustrate the concept:\n\nLet's say you have the sentence. \n\n**The dog fetched the ball.**\n\nIf you are trying to train a skip-gram model for the word \"dog\", the goal of the model is to predict the context words \"the\" and \"fetched\" given the input word \"dog\". So, the training data for the model would be pairs of the form (input word = \"dog\", context word = \"the\"), (input word = \"dog\", context word = \"fetched\").\n\n:::\n\n:::section{.main}\n## Architecture of Skip-Gram Model\n\nThe architecture of the skip-gram model consists of an **input layer**, an **output layer**, and a **hidden layer**. The input layer is the word to be predicted, and the output layer is the context words. The hidden layer represents the embedding of the input word learned during training. The skip-gram model uses a feedforward neural network with a single hidden layer, as shown in the diagram below:\n\n![skip gram architecture](https://www.scaler.com/topics/images/skip-gram-architecture.webp)\n\n\n\n**Input Layer --\u003e Hidden Layer --\u003e Output Layer**\n\nThe input and output layers are connected to the hidden layer through weights, adjusted during training to minimize the prediction error. The skip-gram model uses a **negative sampling objective function** to optimize the weights and learn the embeddings.\n\nThe skip-gram model is a method for learning word embeddings that captures the **context and semantic similarity** between words in a vocabulary. It is trained using a feedforward neural network with a single hidden layer and is widely used in NLP tasks.\n\n:::\n\n:::section{.main}\n## Implementing the Skip-gram Model\n\nTo implement a skip-gram model for word embeddings, you will need a **large corpus of text in a single language** and tools for preprocessing and tokenizing the text. You can download and access the text using the **Natural Language Toolkit (NLTK)** library.\n\nWe can use `TensorFlow` with the **Keras API** to build and train the model. A skip-gram generator can create training data for the model in pairs of words (the target word and the context word) and labels indicating whether the context word appears within a fixed window size of the target word in the input text.\n\nThe model architecture should include **embedding layers** for the target and context words and a dense layer with a **sigmoid activation** function to predict the probability of the context word appearing within a fixed window of the target word. The trained word embeddings can be extracted from the model once trained. The model can then be compiled with a loss function, an optimizer, and fit on the skip grams.\n\n### Build the Corpus Vocabulary\n\nLet's preprocess the text of the Bible to create a vocabulary of words that we will use to train the word embedding model. This includes **removing punctuation and numbers**, **lowercasing** all the words, and **filtering out empty strings** and lines with fewer than three words. \n\nCalculate the vocabulary size and the size of the embeddings, which is the length of the dense vector representation of each word. Create a **tokenizer** and fit it on the normalized text, and create mappings from words to ids and vice versa.\n\n```python\nimport nltk\nnltk.download('punkt')\nimport tensorflow as tf\nfrom nltk.corpus import gutenberg\nfrom string import punctuation\n# import tf.keras\nfrom keras.preprocessing import text\n\n# download and load the bible text from gutenberg\nnltk.download('gutenberg')\nbible_text = gutenberg.sents('bible-kjv.txt') \n\n# remove punctuation and numbers from the text\nremove_chars = punctuation + '0123456789'\nnormalized_bible = [[word.lower() for word in sent if word not in remove_chars] for sent in bible_text]\n\n# join the tokens back into a string\nnormalized_bible_text = [' '.join(tok_sent) for tok_sent in normalized_bible]\n\n# remove empty strings and lines with fewer than three words\nfiltered_bible_text = list(filter(None, normalized_bible_text))\nfiltered_bible_text = [tok_sent for tok_sent in filtered_bible_text if len(tok_sent.split()) \u003e 2]\n\nprint('Total number of lines in the original corpus:', len(bible_text))\nprint('\\nOriginal sample line:', bible_text[5])\nprint('\\nProcessed sample line:', filtered_bible_text[5])\n\n# create a tokenizer and fit it on the text\ntokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(filtered_bible_text)\n\n# create mapping dictionaries for words to ids and ids to words\nword_to_id = tokenizer.word_index\nid_to_word = {v:k for k, v in word_to_id.items()}\n\n# calculate the vocabulary size\nvocab_size = len(word_to_id) + 1 \nembedding_size = 100\n\n# convert the text to a list of word ids\nword_ids = [[word_to_id[w] for w in text.text_to_word_sequence(doc)] for doc in filtered_bible_text]\nprint('Vocabulary size:', vocab_size)\nprint('Vocabulary sample:', list(word_to_id.items())[:10])\n\n```\n\n**Output**\n```plaintext\n[nltk_data] Downloading package gutenberg to /root/nltk_data...\n[nltk_data]   Package gutenberg is already up-to-date!\nTotal number of lines in the original corpus: 30103\n\nOriginal sample line: ['And', 'the', 'Spirit', 'of', 'God', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters', '.']\n\nProcessed sample line: and the spirit of god moved upon the face of the waters.\nVocabulary size: 12726\nVocabulary sample: [('the', 1), ('and', 2), ('of', 3), ('to', 4), ('that', 5), ('in', 6), ('he', 7), ('shall', 8), ('unto', 9), ('for', 10)]\n```\n\n### Build a Skip-gram [(target, context), relevancy] Generator\n\nGenerate skip grams from the preprocessed text. A skip-gram is a pair of words (the target word and the context word) and a label indicating whether the context word appears within a fixed window size of the target word in the input text. Skip grams are used as training data for the word embedding model.\n\n```python\n# generate skip-grams\nskip_grams = [tf.keras.preprocessing.sequence.skipgrams(wid, vocabulary_size=vocab_size, window_size=10) for wid in word_ids]\n# view sample skip-grams\npairs, labels = skip_grams[0][0], skip_grams[0][1]\nfor i in range(10):\n    print(\"({:s} ({:d}), {:s} ({:d})) -\u003e {:d}\".format(\n          id_to_word[pairs[i][0]], pairs[i][0], \n          id_to_word[pairs[i][1]], pairs[i][1], \n          labels[i]))\n\n```\n\n**Output**\n```plaintext\n(bible (6037), grayheaded (7497)) -\u003e 0\n(bible (6037), lowliness (8668)) -\u003e 0\n(the (1), king (50)) -\u003e 1\n(the (1), particularly (8570)) -\u003e 0\n(king (50), james (1323)) -\u003e 1\n(bible (6037), king (50)) -\u003e 1\n(james (1323), king (50)) -\u003e 1\n(king (50), cause (304)) -\u003e 0\n(the (1), nursed (7168)) -\u003e 0\n(king (50), gently (7579)) -\u003e 0\n```\n\n### Build the Skip-Gram Model Architecture\n\nThe next step is to define the word embedding model's architecture using `Keras's functional API`. The model has two embedding layers for the target and context words, which are concatenated and passed through a dense layer with a sigmoid activation function to predict the probability of the context word appearing within a fixed window of the target word.\n\n```python\nfrom tensorflow.keras.layers import Concatenate, Dense, Embedding, Reshape\nfrom tensorflow.keras.models import Model\n\n# Define the input layers for the target and context words\ntarget_word_input = tf.keras.Input(shape=(1,))\ncontext_word_input = tf.keras.Input(shape=(1,))\n\n# Build skip-gram architecture\ntarget_word_model = Embedding(vocab_size, embedding_size,\n                              embeddings_initializer=\"glorot_uniform\")(target_word_input)\ntarget_word_model = Reshape((embedding_size,))(target_word_model)\n\ncontext_word_model = Embedding(vocab_size, embedding_size,\n                               embeddings_initializer=\"glorot_uniform\")(context_word_input)\ncontext_word_model = Reshape((embedding_size,))(context_word_model)\n\n# Concatenate the output of the target and context models\nmerged = Concatenate(axis=1)([target_word_model, context_word_model])\n\n# Add a dense layer and sigmoid activation\noutput = Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\")(merged)\n\n# Define the model\nmodel = Model(inputs=[target_word_input, context_word_input], outputs=output)\n\n# Compile the model\nmodel.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n\n# View model summary\nprint(model.summary())\n```\n\n**Output**\n```plaintext\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n embedding (Embedding)          (None, 1, 100)       1272600     ['input_3[0][0]']                \n                                                                                                  \n embedding_1 (Embedding)        (None, 1, 100)       1272600     ['input_4[0][0]']                \n                                                                                                  \n reshape (Reshape)              (None, 100)          0           ['embedding[0][0]']              \n                                                                                                  \n reshape_1 (Reshape)            (None, 100)          0           ['embedding_1[0][0]']            \n                                                                                                  \n concatenate (Concatenate)      (None, 200)          0           ['reshape[0][0]',                \n                                                                  'reshape_1[0][0]']              \n                                                                                                  \n dense (Dense)                  (None, 1)            201         ['concatenate[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 2,545,401\nTrainable params: 2,545,401\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n```\n\n### Train the Model\nIn order to train the word embedding model on the skip grams we'll use the fit method. The model is trained for a specified number of epochs, the number of times the model sees the entire dataset during training.\n\n```python\n# train the model on the skip-grams\nfor epoch in range(1, 6):\n    total_loss = 0\n    for i, elem in enumerate(skip_grams):\n        skip_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n        skip_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n        labels = np.array(elem[1], dtype='int32')\n        X = [skip_first_elem, skip_second_elem]\n        Y = labels\n        if i % 10000 == 0:\n            print('Processed {} skip-gram pairs'.format(i))\n        total_loss += model.train_on_batch(X,Y)  \n\n    print('Epoch: {} Loss: {}'.format(epoch, total_loss))\n```\n\n**Output**\n\n```plaintext\nProcessed 0 skip-gram pairs\nProcessed 10000 skip-gram pairs\nProcessed 20000 skip-gram pairs\nEpoch: 1 Loss: 2560.6447135005146 \nProcessed 0 skip-gram pairs\nProcessed 10000 skip-gram pairs \nProcessed 20000 skip-gram pairs \nEpoch: 2 Loss: 2367.486852501519 \nProcessed 0 skip-gram pairs\nProcessed 10000 skip-gram pairs\nProcessed 20000 skip-gram pairs \nEpoch: 3 Loss: 2343.08078927733 \nProcessed 0 skip-gram pairs\nProcessed 10000 skip-gram pairs\nProcessed 20000 skip-gram pairs\nEpoch: 4 Loss: 2325.2062594543386 \nProcessed 0 skip-gram pairs \nProcessed 10000 skip-gram pairs \nProcessed 20000 skip-gram pairs\nEpoch: 5 Loss: 2313.4975586438086\n```\n\n### Get Word Embeddings\nTo see results from the model, we first need to extract the trained word embeddings from the word embedding model. The word embeddings are the weights of the embedding layer, which are the **dense vector representations** of the words in the vocabulary. The shape of the weights tensor is (`vocab_size`, `embedding_size`), where `vocab_size` is the size of the vocabulary and `embedding_size` is the length of the dense vector representation of each word.\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics.pairwise import euclidean_distances\n\n# get the embeddings for the words in the vocabulary\nweights = model.layers[2].get_weights()[0]\n\ndistance_matrix = euclidean_distances(weights)\nprint(distance_matrix.shape)\n\nsimilar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:6]+1] \n                   for search_term in ['god', 'jesus', 'noah', 'egypt', 'john', 'gospel', 'moses','famine']}\n\nprint(similar_words)\n\n# reduce the dimensions of the embeddings using t-SNE\ntsne = TSNE(n_components=2, random_state=0)\nvectors_2d = tsne.fit_transform(weights)\n\n# create a list of the words in the vocabulary\nwords = [id2word[i] for i in range(1, vocab_size)]\n\n# plot the similar words\nfig, ax = plt.subplots(figsize=(20,10))\nfor word in similar_words:\n    ax.scatter(vectors_2d[word2id[word]-1, 0], vectors_2d[word2id[word]-1, 1], c='red', label=word)\n    for sim_word in similar_words[word]:\n        ax.scatter(vectors_2d[word2id[sim_word]-1, 0], vectors_2d[word2id[sim_word]-1, 1], c='blue')\n        ax.annotate(sim_word, (vectors_2d[word2id[sim_word]-1, 0], vectors_2d[word2id[sim_word]-1, 1]))\nax.legend()\nplt.show()\n\n```\n\n**Output**\n\n```plaintext\n(12726, 12726)\n{'god': ['true', 'effect', 'abound', 'waiteth', 'open'],\n 'jesus': ['grievous', 'windows', 'glory', 'lamb', 'did'],\n 'noah': ['teacheth', 'walls', 'residue', 'gathered', 'awake'],\n 'egypt': ['seir', 'beersheba', 'grievous', '108', 'synagogues'],\n 'john': ['gilead', 'fatherless', 'breadth', 'dwell', 'forasmuch'],\n 'gospel': ['seventy', 'cause', 'boards', 'clothed', 'nevertheless'],\n 'moses': ['meet', 'reach', 'youth', 'died', 'scatter'],\n 'famine': ['dogs', 'blasphemy', '33', 'restored', 'jezebel']}\n ```\n\n![dense vector representations example](https://www.scaler.com/topics/images/dense-vector-representations-example.webp)\n\n\n:::\n\n:::section{.summary}\n## Conclusion\n* In conclusion, the `skip-gram model` is a popular method for generating word embeddings, dense vector representations of words in a vocabulary. \n* The `skip-gram model` takes a large corpus of text as input and trains a neural network to predict the context words that appear within a target word's fixed window based on the text's co-occurrence. \n* The word embeddings can be extracted from the weights of the `embedding layer` in the trained model and can be used as input to other natural language processing tasks, such as `text classification`, `sentiment analysis`, and `machine translation`. \n* The skip-gram model has been shown to produce high-quality word embeddings that capture the semantic and syntactic relationships between words in the text, making it a useful tool for a wide range of NLP applications.\n\n:::","mediaList":["https://www.scaler.com/topics/images/skip-gram-architecture.webp","https://www.scaler.com/topics/images/dense-vector-representations-example.webp"],"pageClass":"articlePage","rootClass":"articleLayout","subProduct":"article","fallback":{"https://www.scaler.com/topics/api/v1/search/courses/1/6/":[{"slug":"java-beginners","title":"Java Course - Mastering the Fundamentals","category_type":"topics_course","cover_image_thumbnail":"https://www.scaler.com/topics/images/Java-master-image.webp","featured_image":"https://www.scaler.com/topics/images/java-master.webp","modules_count":12,"description":"Embark on your programming journey with our comprehensive Free Java Course for Beginners. Master the fundamentals of Java and gain the skills needed for advanced Java development. This easy-to-follow course is designed with beginners in mind, offering a structured learning path to specialize in Java programming. With no prerequisites, this course empowers you to learn Java at your own pace and take the first step toward a promising career in tech.","eligible_for_certificate":true,"instructor_name":"Tarun Luthra","instructor_image":"https://www.scaler.com/topics/images/instructor-tarun.webp","company_image":"https://www.scaler.com/topics/images/Scaler.webp","star_headline":"5 Star Instructor on Scaler","headline":"Software Engineer \u0026 Instructor","app_exclusive":false,"user_registration_count":77615,"is_popular":true,"first_entity":{"type":"Video","uuid":1},"category_meta_url":null,"total_time":"8h 9m","total_entities_count":95,"bookmarked":null,"programs":["academy","programming_languages"]},{"slug":"python-for-beginners","title":"Python Course for Beginners With Certification: Mastering the Essentials","category_type":"topics_course","cover_image_thumbnail":"https://www.scaler.com/topics/images/course_card_image_pybeg.webp","featured_image":"https://www.scaler.com/topics/images/course_featured_image_pybeg.webp","modules_count":16,"description":"Welcome to the free Python course online for beginners, designed to help you kickstart your programming journey. This comprehensive Python course offers a certificate upon completion, covering essential topics like basic Python fundamentals, data structures, object-oriented programming, and more. With 9 hours and 48 minutes of content, you'll gain the knowledge and confidence to start working on your Python projects.","eligible_for_certificate":true,"instructor_name":"Rahul Janghu","instructor_image":"https://www.scaler.com/topics/images/rahul_janghu.webp","company_image":"https://www.scaler.com/topics/images/Scaler.webp","star_headline":"4.90","headline":"Software Engineer and Instructor at Scaler","app_exclusive":false,"user_registration_count":67627,"is_popular":true,"first_entity":{"type":"Video","uuid":660},"category_meta_url":null,"total_time":"9h 44m","total_entities_count":131,"bookmarked":null,"programs":["academy","data_science","programming_languages"]},{"slug":"cpp-beginners","title":"C++ Course: Learn the Essentials","category_type":"topics_course","cover_image_thumbnail":"https://www.scaler.com/topics/images/cpp_card_master.webp","featured_image":"https://www.scaler.com/topics/images/cpp-master.webp","modules_count":14,"description":"Gain programming expertise with our Free C++ Course! Covering basics to advanced concepts, this online program provides a comprehensive curriculum encompassing environment setup, variables, conditional statements, loops, functions, pointers, arrays, sorting, character arrays, strings, and more. Perfect for beginners or seasoned programmers looking to enhance their skills and earn a certificate.","eligible_for_certificate":true,"instructor_name":"Prateek Narang","instructor_image":"https://www.scaler.com/topics/images/instructor-prateek.webp","company_image":"https://www.scaler.com/topics/images/Scaler.webp","star_headline":"5 Star Instructor on Udemy","headline":"Instructor \u0026 Engineering Lead","app_exclusive":false,"user_registration_count":40049,"is_popular":true,"first_entity":{"type":"Video","uuid":89},"category_meta_url":null,"total_time":"9h 24m","total_entities_count":105,"bookmarked":null,"programs":["academy","programming_languages"]},{"slug":"dbms","title":"DBMS Course - Master the Fundamentals and Advanced Concepts","category_type":"topics_course","cover_image_thumbnail":"https://www.scaler.com/topics/images/course_card_image_dbms.webp","featured_image":"https://www.scaler.com/topics/images/course_featured_image_dbms.webp","modules_count":16,"description":"Scaler Topics free DBMS course is designed to help beginners learn about the fundamental concepts of database management systems. The course is completely online, and it comes with a free certificate of completion that you can add to your resume or LinkedIn profile. You'll learn about the most popular DBMS like MySQL, Oracle, and SQL Server, as well as the theoretical foundations of databases.","eligible_for_certificate":true,"instructor_name":"Srikanth Varma","instructor_image":"https://www.scaler.com/topics/images/srikant-varma_instructor.webp","company_image":"https://www.scaler.com/topics/images/Scaler.webp","star_headline":"5","headline":"Lead DSML Instructor at Scaler","app_exclusive":false,"user_registration_count":34823,"is_popular":false,"first_entity":{"type":"Video","uuid":1620},"category_meta_url":null,"total_time":"1d 5h 17m","total_entities_count":90,"bookmarked":null,"programs":["academy"]},{"slug":"javascript-beginners","title":"JavaScript Course With Certification: Unlocking the Power of JavaScript","category_type":"topics_course","cover_image_thumbnail":"https://www.scaler.com/topics/images/Course_Listing_312x136_MrinalBhattacharya","featured_image":"https://www.scaler.com/topics/images/Course_FI_816x352_MrinalBhattacharya.webp","modules_count":9,"description":"Kickstart your journey into web development with this free JavaScript course online with a certificate. Designed for beginners, this comprehensive JavaScript online course covers the essential concepts and skills needed to master Javascript, one of the most popular and widely used programming languages in the world. With a course duration of 10 hours and 9 minutes, you'll learn everything from the basics to advanced techniques, all at your own pace.","eligible_for_certificate":true,"instructor_name":"Mrinal Bhattacharya","instructor_image":"https://www.scaler.com/topics/images/mrinal_bhattacharya.webp","company_image":"https://www.scaler.com/topics/images/Scaler.webp","star_headline":"4.8","headline":null,"app_exclusive":false,"user_registration_count":34177,"is_popular":false,"first_entity":{"type":"Video","uuid":1637},"category_meta_url":null,"total_time":"10h 14m","total_entities_count":78,"bookmarked":null,"programs":["academy","programming_languages","frontend_development"]},{"slug":"python-sql-data-science","title":"Python and SQL for Data Science","category_type":"topics_course","cover_image_thumbnail":"https://www.scaler.com/topics/images/course_card_image_pds.webp","featured_image":"https://www.scaler.com/topics/images/course_featured_image_pds.webp","modules_count":8,"description":"Introducing the Free Data Science with Python and SQL Certification Course Online, a comprehensive beginner's program designed to help aspiring data scientists learn the essential skills in the rapidly growing field of data science. This course offers a unique blend of practical and theoretical knowledge, combining the powerful programming language Python and the versatile database management system SQL to help you analyze, visualize, and interpret data efficiently.\n","eligible_for_certificate":true,"instructor_name":"Srikanth Varma","instructor_image":"https://www.scaler.com/topics/images/srikant-varma_instructor.webp","company_image":"https://www.scaler.com/topics/images/Scaler.webp","star_headline":"5","headline":"Lead DSML Instructor at Scaler","app_exclusive":false,"user_registration_count":28319,"is_popular":false,"first_entity":{"type":"Video","uuid":1624},"category_meta_url":null,"total_time":"14h 46m","total_entities_count":73,"bookmarked":null,"programs":["data_science"]}]}},"__N_SSG":true},"page":"/[...slug]","query":{"slug":["nlp","skip-gram-model"]},"buildId":"SOrsD7MfkmkYICw_q65D-","assetPrefix":"https://d1g0iq4cbcvjcd.cloudfront.net/topics","runtimeConfig":{"assetPrefix":"https://d1g0iq4cbcvjcd.cloudfront.net/topics","basePath":"/topics"},"isFallback":false,"dynamicIds":[32851,33161,81948,41631,96770,69605],"gsp":true,"scriptLoader":[]}</script><next-route-announcer><p aria-live="assertive" id="__next-route-announcer__" role="alert" style="border: 0px; clip: rect(0px, 0px, 0px, 0px); height: 1px; margin: -1px; overflow: hidden; padding: 0px; position: absolute; top: 0px; width: 1px; white-space: nowrap; overflow-wrap: normal;"></p></next-route-announcer><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/3994-895482d2e2657865.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/5049-ac51a78de419d9da.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/9905-1f7f62f3025bd875.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/8711-a8a944e595246ec4.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/9488-838167c018c56d9f.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/courses-6a7686cb76b86aed.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/5751-cd49377b10bfe86a.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/7002-248601e3219a55a2.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/2376-932492b0bf0c64ca.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/events-d4e3b462905d7987.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/2068-d8c544d17117635f.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/5332-8c504931a49893a4.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/index-77106070fc47187b.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/hubs-67d6286f11606b47.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/9968-45414fbb2e36aa31.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/3667-95fcc7986e605aea.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/1008-e6827334234282ce.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/2619-f1af377491843fe8.js.download"></script><script crossorigin="anonymous" src="./Skip-Gram Model in NLP - Scaler Topics_files/[slug]-eb2d9f7a11bd706d.js.download"></script><script id="gtag-base" data-nscript="lazyOnload">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
          new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
          j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
          'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
          })(window,document,'script','dataLayer', 'GTM-NXNWCP8');</script><script src="./Skip-Gram Model in NLP - Scaler Topics_files/client" data-nscript="lazyOnload"></script></body><grammarly-desktop-integration data-grammarly-shadow-root="true"><template shadowrootmode="open"><style>
      div.grammarly-desktop-integration {
        position: absolute;
        width: 1px;
        height: 1px;
        padding: 0;
        margin: -1px;
        overflow: hidden;
        clip: rect(0, 0, 0, 0);
        white-space: nowrap;
        border: 0;
        -moz-user-select: none;
        -webkit-user-select: none;
        -ms-user-select:none;
        user-select:none;
      }

      div.grammarly-desktop-integration:before {
        content: attr(data-content);
      }
    </style><div aria-label="grammarly-integration" role="group" tabindex="-1" class="grammarly-desktop-integration" data-content="{&quot;mode&quot;:&quot;full&quot;,&quot;isActive&quot;:true,&quot;isUserDisabled&quot;:false}"></div></template></grammarly-desktop-integration></html>