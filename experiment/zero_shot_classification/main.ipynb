{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Base Language: bengali ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 9/9 [00:01<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bengali:\n",
      "Accuracy: 0.5300751879699248\n",
      "Precision: 0.5300751879699248\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6928746928746928\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 34/34 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for english:\n",
      "Accuracy: 0.4911792014856082\n",
      "Precision: 0.4911792014856082\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6587795765877957\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 40/40 [00:12<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for indonesian:\n",
      "Accuracy: 0.49801113762927607\n",
      "Precision: 0.49801113762927607\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6648964418481148\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 66/66 [00:21<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for arabic:\n",
      "Accuracy: 0.497377205531712\n",
      "Precision: 0.497377205531712\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6643312101910828\n",
      "-------------------------\n",
      "-------- Base Language: english ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 9/9 [00:02<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bengali:\n",
      "Accuracy: 0.7443609022556391\n",
      "Precision: 0.762589928057554\n",
      "Recall: 0.75177304964539\n",
      "F1 Score: 0.757142857142857\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 34/34 [00:11<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for english:\n",
      "Accuracy: 0.8365831012070566\n",
      "Precision: 0.8058925476603119\n",
      "Recall: 0.8790170132325141\n",
      "F1 Score: 0.8408679927667269\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 40/40 [00:12<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for indonesian:\n",
      "Accuracy: 0.8591885441527446\n",
      "Precision: 0.8437978560490046\n",
      "Recall: 0.8801916932907349\n",
      "F1 Score: 0.8616106333072713\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 66/66 [00:24<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for arabic:\n",
      "Accuracy: 0.8721983786361469\n",
      "Precision: 0.8666035950804163\n",
      "Recall: 0.87823585810163\n",
      "F1 Score: 0.8723809523809524\n",
      "-------------------------\n",
      "-------- Base Language: indonesian ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 9/9 [00:02<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bengali:\n",
      "Accuracy: 0.48872180451127817\n",
      "Precision: 0.6086956521739131\n",
      "Recall: 0.09929078014184398\n",
      "F1 Score: 0.17073170731707316\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 34/34 [00:12<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for english:\n",
      "Accuracy: 0.5041782729805014\n",
      "Precision: 0.45614035087719296\n",
      "Recall: 0.04914933837429111\n",
      "F1 Score: 0.0887372013651877\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 40/40 [00:14<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for indonesian:\n",
      "Accuracy: 0.771678599840891\n",
      "Precision: 0.7548872180451128\n",
      "Recall: 0.8019169329073482\n",
      "F1 Score: 0.7776917118512781\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 66/66 [00:26<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for arabic:\n",
      "Accuracy: 0.5517405817835003\n",
      "Precision: 0.7288888888888889\n",
      "Recall: 0.15723873441994246\n",
      "F1 Score: 0.2586750788643533\n",
      "-------------------------\n",
      "-------- Base Language: arabic ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 9/9 [00:02<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bengali:\n",
      "Accuracy: 0.5300751879699248\n",
      "Precision: 0.5300751879699248\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6928746928746928\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 34/34 [00:13<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for english:\n",
      "Accuracy: 0.4911792014856082\n",
      "Precision: 0.4911792014856082\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6587795765877957\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 40/40 [00:14<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for indonesian:\n",
      "Accuracy: 0.49801113762927607\n",
      "Precision: 0.49801113762927607\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6648964418481148\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 66/66 [00:26<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for arabic:\n",
      "Accuracy: 0.497377205531712\n",
      "Precision: 0.497377205531712\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6643312101910828\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering, XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from functools import partial\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "from lab5_helper import collate_fn, get_train_features, get_validation_features, post_process_predictions, predict, val_collate_fn\n",
    "from lab5_train import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "lr = 2e-5\n",
    "n_epochs = 3\n",
    "weight_decay = 0.01\n",
    "warmup_steps = 200\n",
    "bert_map = {\n",
    "    'bengali': 'xlm-roberta-base', \n",
    "    'english': 'xlm-roberta-base', \n",
    "    'indonesian': 'xlm-roberta-base', \n",
    "    'arabic': 'xlm-roberta-base'\n",
    "}\n",
    "device = 'cuda'\n",
    "\n",
    "compute_squad = load_metric(\"squad_v2\")\n",
    "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].add_column('id', list(range(len(dataset[split]))))\n",
    "\n",
    "for language, bert in list(bert_map.items()):\n",
    "    print(f'-------- Base Language: {language} ------------')\n",
    "    # language_dataset = dataset.filter(lambda example: example['language'] == language)\n",
    "    # tk = AutoTokenizer.from_pretrained(bert, max_len=300)\n",
    "\n",
    "    # tokenized_train_dataset = language_dataset['train'].map(partial(get_train_features, tk), batched=True, remove_columns=language_dataset['train'].column_names)\n",
    "    # tokenized_validation_dataset = language_dataset['validation'].map(partial(get_train_features, tk), batched=True, remove_columns=language_dataset['validation'].column_names)\n",
    "\n",
    "    # train_dl = DataLoader(tokenized_train_dataset, collate_fn=collate_fn, shuffle=True, batch_size=4)\n",
    "\n",
    "    # # Load xlm-roberta-base model\n",
    "    # model = XLMRobertaForSequenceClassification.from_pretrained(bert, num_labels=2).to(device)\n",
    "    # no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    # optimizer_grouped_parameters = [\n",
    "    #     {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "    #     'weight_decay': weight_decay},\n",
    "    #     {'params': [p for n, p in model.named_parameters() if any(\n",
    "    #         nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    # ]\n",
    "\n",
    "    # optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    # scheduler = get_linear_schedule_with_warmup(\n",
    "    #     optimizer,\n",
    "    #     warmup_steps,\n",
    "    #     n_epochs * len(train_dl)\n",
    "    # )\n",
    "\n",
    "    # losses = train(\n",
    "    #     model,\n",
    "    #     train_dl,\n",
    "    #     optimizer,\n",
    "    #     scheduler,\n",
    "    #     n_epochs,\n",
    "    #     device\n",
    "    # )\n",
    "    # torch.save(model, f'{language}_xlm-roberta-base_classification.pt')\n",
    "    model = torch.load(f'{language}_xlm-roberta-base_classification.pt')\n",
    "    for language2, bert in list(bert_map.items()):\n",
    "        language_dataset = dataset.filter(lambda example: example['language'] == language2)\n",
    "        tk = AutoTokenizer.from_pretrained(bert, max_len=300)\n",
    "        \n",
    "        tokenized_validation_dataset = language_dataset['validation'].map(partial(get_train_features, tk), batched=True, remove_columns=language_dataset['validation'].column_names)  \n",
    "\n",
    "        val_dl = DataLoader(tokenized_validation_dataset, collate_fn=collate_fn, batch_size=32)\n",
    "        \n",
    "        logits = predict(model, val_dl, device)\n",
    "        # Assuming binary classification; use torch.argmax for multi-class.\n",
    "        predictions = logits.argmax(dim=1).cpu().numpy()\n",
    "        ground_truth = []\n",
    "        for batch in val_dl:\n",
    "            ground_truth.extend(batch['labels'].numpy())\n",
    "            \n",
    "        accuracy = accuracy_score(ground_truth, predictions)\n",
    "        precision = precision_score(ground_truth, predictions)\n",
    "        recall = recall_score(ground_truth, predictions)\n",
    "        f1 = f1_score(ground_truth, predictions)\n",
    "\n",
    "        print(f\"Results for {language2}:\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 Score: {f1}\")\n",
    "        print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: bengali\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304fc12c2da9469cab8c6dfffe2814b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32056469aac43109e280bf73f85b585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'start_logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/tokereines/tiger/experiments/lab5/main.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/lab5/main.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m train_dl \u001b[39m=\u001b[39m DataLoader(tokenized_train_dataset, collate_fn\u001b[39m=\u001b[39mcollate_fn, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/lab5/main.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m val_dl \u001b[39m=\u001b[39m DataLoader(tokenized_validation_dataset, collate_fn\u001b[39m=\u001b[39mval_collate_fn, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/lab5/main.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m logits \u001b[39m=\u001b[39m predict(model, val_dl, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/lab5/main.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m predictions \u001b[39m=\u001b[39m post_process_predictions(language_dataset[\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m], tokenized_validation_dataset, logits)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/lab5/main.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m formatted_predictions \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m: k, \u001b[39m'\u001b[39m\u001b[39mprediction_text\u001b[39m\u001b[39m'\u001b[39m: v, \u001b[39m'\u001b[39m\u001b[39mno_answer_probability\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.\u001b[39m} \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m predictions\u001b[39m.\u001b[39mitems()]\n",
      "File \u001b[0;32m~/tiger/experiments/lab5/lab5_helper.py:127\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, valid_dl, device)\u001b[0m\n\u001b[1;32m    121\u001b[0m     outputs \u001b[39m=\u001b[39m model(\n\u001b[1;32m    122\u001b[0m         input_ids\u001b[39m=\u001b[39mbatch[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    123\u001b[0m         attention_mask\u001b[39m=\u001b[39mbatch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m     \u001b[39m# Store the \"start\" class logits and \"end\" class logits for every token in the input\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     start_logits_all\u001b[39m.\u001b[39mextend(\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mlist\u001b[39m(outputs[\u001b[39m'\u001b[39;49m\u001b[39mstart_logits\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()))\n\u001b[1;32m    128\u001b[0m     end_logits_all\u001b[39m.\u001b[39mextend(\n\u001b[1;32m    129\u001b[0m         \u001b[39mlist\u001b[39m(outputs[\u001b[39m'\u001b[39m\u001b[39mend_logits\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()))\n\u001b[1;32m    131\u001b[0m \u001b[39mreturn\u001b[39;00m start_logits_all, end_logits_all\n",
      "File \u001b[0;32m~/miniconda3/envs/UNSPSC/lib/python3.9/site-packages/transformers/utils/generic.py:403\u001b[0m, in \u001b[0;36mModelOutput.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(k, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    402\u001b[0m     inner_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems())\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_dict[k]\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_tuple()[k]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_logits'"
     ]
    }
   ],
   "source": [
    "metrics = {l: {} for l in bert_map.keys()}\n",
    "for language, bert in list(bert_map.items()):\n",
    "    print(f'Language: {language}')\n",
    "    model = torch.load(f'{language}_xlm-roberta-base_span_detection.pt')\n",
    "    for language2, bert in list(bert_map.items()):\n",
    "        language_dataset = dataset.filter(lambda example: example['language'] == language2)\n",
    "        tk = AutoTokenizer.from_pretrained(bert, max_len=300)\n",
    "\n",
    "        tokenized_train_dataset = language_dataset['train'].map(partial(get_train_features, tk), batched=True, remove_columns=language_dataset['train'].column_names)\n",
    "        tokenized_validation_dataset = language_dataset['validation'].map(partial(get_validation_features, tk), batched=True, remove_columns=language_dataset['validation'].column_names)\n",
    "\n",
    "        train_dl = DataLoader(tokenized_train_dataset, collate_fn=collate_fn, shuffle=True, batch_size=4)\n",
    "        val_dl = DataLoader(tokenized_validation_dataset, collate_fn=val_collate_fn, batch_size=32)\n",
    "        \n",
    "        logits = predict(model, val_dl, device)\n",
    "        predictions = post_process_predictions(language_dataset['validation'], tokenized_validation_dataset, logits)\n",
    "        formatted_predictions = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.} for k, v in predictions.items()]\n",
    "        gold = [{\n",
    "            'id': example['id'],\n",
    "            'answers': {\n",
    "                'text': example['annotations']['answer_text'],\n",
    "                'answer_start': example['annotations']['answer_start']}\n",
    "            }\n",
    "            for example in language_dataset['validation']]\n",
    "\n",
    "\n",
    "        metrics[language][language2] = compute_squad.compute(references=gold, predictions=formatted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match scores, xlm-r span detection:\n",
      "tuned lan & bengali & english & indonesian & arabic\\\\\n",
      "bengali & 28.12 & 21.31 & 20.49 & 13.72\\\\\n",
      "english & 15.62 & 25.96 & 27.54 & 20.08\\\\\n",
      "indonesian & 17.86 & 26.16 & 34.17 & 25.13\\\\\n",
      "arabic & 18.30 & 26.16 & 29.89 & 30.34\\\\\n",
      "Average & 20.91 & 22.30 & 25.83 & 26.17\\\\\n"
     ]
    }
   ],
   "source": [
    "# Pretty print metrics\n",
    "print(\"Exact match scores, xlm-r span detection:\")\n",
    "print(' & '.join(['tuned lan'] + list(bert_map.keys())) + '\\\\\\\\')\n",
    "for language in bert_map.keys():\n",
    "    print(' & '.join([language] + [f'{metrics[language][language2][\"exact\"]:.2f}' for language2 in bert_map.keys()]) + '\\\\\\\\')\n",
    "print(' & '.join(['Average'] + [f'{sum([metrics[language][language2][\"exact\"] for language2 in bert_map.keys()]) / len(bert_map.keys()):.2f}' for language in bert_map.keys()]) + '\\\\\\\\')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNSPSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
