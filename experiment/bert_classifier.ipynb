{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5tfZxdfiNHF"
      },
      "source": [
        "# Bengali model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "vZOGzO4NiEfu",
        "outputId": "03715142-e29c-4c2f-a88c-311d29715447"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tokereines/miniconda3/envs/08_nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from dataset import FFN2Dataset\n",
        "from tokenizer import FFN2Tokenizer\n",
        "from torch.optim import Adam\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from models import MeanClassifier, CLSClassifier, LogRegCLSClassifier\n",
        "from train import train, evaluate\n",
        "from torch.optim.lr_scheduler import ExponentialLR, CyclicLR\n",
        "\n",
        "bert_map = {\n",
        "    'bengali': 'google/muril-base-cased', \n",
        "    'english': 'bert-base-uncased', \n",
        "    'indonesian': 'cahya/bert-base-indonesian-522M', \n",
        "    'arabic': 'asafaya/bert-base-arabic'\n",
        "}\n",
        "language = \"bengali\"\n",
        "languages = [\"bengali\", \"indonesian\", \"arabic\"]\n",
        "bert = bert_map[language]\n",
        "device = 'cuda'\n",
        "input_dim = 768\n",
        "hidden_dim = 50\n",
        "lr = 3e-2\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "\n",
        "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "language_dataset = dataset.filter(lambda row: row['language'] == language)\n",
        "\n",
        "train_set = language_dataset[\"train\"]\n",
        "validation_set = language_dataset[\"validation\"]\n",
        "\n",
        "tokenizer = FFN2Tokenizer(bert)\n",
        "train_set = FFN2Dataset(train_set, tokenizer)\n",
        "validation_set = FFN2Dataset(validation_set, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean FFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H8SzIKv5rRi3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 150/150 [03:13<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Loss: 0.6743885838985443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:11<00:00,  1.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 67.41%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3:  19%|█▉        | 29/150 [00:48<03:23,  1.69s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/tokereines/tiger/experiments/bert_classifier.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m optimizer \u001b[39m=\u001b[39m Adam(mean_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m scheduler \u001b[39m=\u001b[39m CyclicLR(optimizer, base_lr\u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m, max_lr\u001b[39m=\u001b[39mlr, step_size_up\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, step_size_down\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_set)\u001b[39m*\u001b[39mepochs, cycle_momentum\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m best_model \u001b[39m=\u001b[39m train(mean_model, optimizer, scheduler, train_set, validation_set, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, lr\u001b[39m=\u001b[39;49mlr, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m torch\u001b[39m.\u001b[39msave(best_model, \u001b[39m'\u001b[39m\u001b[39mmean_bert_classifier.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/tiger/experiments/train.py:46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, dataset, validation_set, epochs, batch_size, lr, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m     epoch_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     48\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "mean_model = MeanClassifier(bert)\n",
        "optimizer = Adam(mean_model.parameters(), lr=lr)\n",
        "scheduler = CyclicLR(optimizer, base_lr=0., max_lr=lr, step_size_up=1, step_size_down=len(train_set)*epochs, cycle_momentum=False)\n",
        "best_model = train(mean_model, optimizer, scheduler, train_set, validation_set, epochs=epochs, batch_size=batch_size, lr=lr, device=device)\n",
        "torch.save(best_model, 'mean_bert_classifier.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CLS FFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yygt9F99rR7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5: 100%|██████████| 150/150 [03:23<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.6944307072957356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 50.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5: 100%|██████████| 150/150 [03:24<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5, Loss: 0.6949388960997264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 50.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5: 100%|██████████| 150/150 [03:25<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/5, Loss: 0.6928549643357594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 50.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5: 100%|██████████| 150/150 [03:25<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/5, Loss: 0.6941517889499664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 50.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/5: 100%|██████████| 150/150 [03:24<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/5, Loss: 0.6939051934083302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 50.00%\n"
          ]
        }
      ],
      "source": [
        "cls_model = CLSClassifier(bert)\n",
        "optimizer = Adam(cls_model.parameters(), lr=lr)\n",
        "scheduler = CyclicLR(optimizer, base_lr=0., max_lr=lr, step_size_up=1, step_size_down=len(train_set)*epochs, cycle_momentum=False)\n",
        "best_model = train(cls_model, optimizer, scheduler, train_set, validation_set, epochs=epochs, batch_size=batch_size, lr=lr, device=device)\n",
        "torch.save(best_model, 'cls_bert_classifier.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CLS Log Reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5: 100%|██████████| 150/150 [03:24<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.6881467231114705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 65.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5: 100%|██████████| 150/150 [03:24<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5, Loss: 0.6739896603425344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 64.73%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5: 100%|██████████| 150/150 [03:25<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/5, Loss: 0.6637167219320933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 70.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5: 100%|██████████| 150/150 [03:24<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/5, Loss: 0.6536384157339732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 65.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/5: 100%|██████████| 150/150 [03:24<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/5, Loss: 0.6462677776813507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 57.59%\n"
          ]
        }
      ],
      "source": [
        "cls_model = LogRegCLSClassifier(bert)\n",
        "optimizer = Adam(cls_model.parameters(), lr=lr)\n",
        "scheduler = CyclicLR(optimizer, base_lr=0., max_lr=lr, step_size_up=1, step_size_down=len(train_set)*epochs, cycle_momentum=False)\n",
        "best_model = train(cls_model, optimizer, scheduler, train_set, validation_set, epochs=epochs, batch_size=batch_size, lr=lr, device=device)\n",
        "torch.save(best_model, 'cls_bert_logreg_classifier.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpcEDfI0iPgW"
      },
      "source": [
        "# Zero-shot Bengali classification model \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training bengali\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/1195 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "forward() got an unexpected keyword argument 'truncation'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/tokereines/tiger/experiments/bert_classifier.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     inputs \u001b[39m=\u001b[39m {key: val\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     labels \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/miniconda3/envs/UNSPSC/lib/python3.9/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/UNSPSC/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/miniconda3/envs/UNSPSC/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/miniconda3/envs/UNSPSC/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/miniconda3/envs/UNSPSC/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "\u001b[1;32m/home/tokereines/tiger/experiments/bert_classifier.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(row[\u001b[39m'\u001b[39;49m\u001b[39mquestion_text\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mdocument_plaintext\u001b[39;49m\u001b[39m'\u001b[39;49m], truncation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39monly_second\u001b[39;49m\u001b[39m'\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m, stride\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length, return_tensors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     inputs \u001b[39m=\u001b[39m {key: val\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlrig1/home/tokereines/tiger/experiments/bert_classifier.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     inputs[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[idx][\u001b[39m\"\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39manswer_start\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlong()\n",
            "File \u001b[0;32m~/miniconda3/envs/UNSPSC/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'truncation'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW, AutoModelForQuestionAnswering\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 1. Create a custom dataset\n",
        "class AnswerabilityDataset(Dataset):\n",
        "    def __init__(self, tokenizer, data, max_length=300):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data[idx]\n",
        "        inputs = self.tokenizer(row['question_text'], row['document_plaintext'], truncation='only_second', padding='max_length', stride=50, max_length=self.max_length, return_tensors='pt')\n",
        "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}\n",
        "        inputs['labels'] = torch.tensor(self.data[idx][\"annotations\"][\"answer_start\"][0] != -1).long()\n",
        "        return inputs\n",
        "    \n",
        "device = 'cpu'\n",
        "languages = [\"bengali\", \"indonesian\", \"arabic\"]\n",
        "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "for language in languages:\n",
        "    print(\"Training\", language)\n",
        "    language_dataset = dataset.filter(lambda row: row['language'] == language)\n",
        "\n",
        "    train_set = language_dataset[\"train\"]\n",
        "    validation_set = language_dataset[\"validation\"]\n",
        "\n",
        "    # 3. Initialize tokenizer and datasets\n",
        "    tokenizer = AutoModelForQuestionAnswering.from_pretrained('xlm-roberta-base')\n",
        "    train_dataset = AnswerabilityDataset(tokenizer, train_set)\n",
        "    val_dataset = AnswerabilityDataset(tokenizer, validation_set)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # 4. Load model and send to device\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained('xlm-roberta-base').to(device)\n",
        "\n",
        "    # 5. Training loop\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "    num_epochs = 3\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_loader):\n",
        "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(**inputs, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_eval_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader):\n",
        "                inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
        "                labels = batch['labels'].to(device)\n",
        "                outputs = model(**inputs, labels=labels)\n",
        "                total_eval_loss += outputs.loss.item()\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Val Loss: {total_eval_loss/len(val_loader)}\")\n",
        "\n",
        "    # 6. Save model\n",
        "    torch.save(model, f'{language}_xlm-roberta-base_cls_logreg_classifier.pt')\n",
        "\n",
        "\n",
        "    \n",
        "# dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "# for language in languages:\n",
        "#     print(\"Training\", language)\n",
        "#     language_dataset = dataset.filter(lambda row: row['language'] == language)\n",
        "\n",
        "#     train_set = language_dataset[\"train\"]\n",
        "#     validation_set = language_dataset[\"validation\"]\n",
        "        \n",
        "#     bert = 'xlm-roberta-base'\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(bert, max_len=300)\n",
        "#     train_set = AnswerabilityDataset(tokenizer, train_set)\n",
        "#     validation_set = AnswerabilityDataset(validation_set, tokenizer)\n",
        "    \n",
        "#     model = XLMRobertaForSequenceClassification.from_pretrained(bert).to(device)\n",
        "#     optimizer = Adam(model.parameters(), lr=lr)\n",
        "#     scheduler = CyclicLR(optimizer, base_lr=0., max_lr=lr, step_size_up=1, step_size_down=len(train_set)*epochs, cycle_momentum=False)\n",
        "#     train(model, optimizer, scheduler, train_set, validation_set, epochs=epochs, batch_size=batch_size, lr=lr, device=device)\n",
        "#     torch.save(model, f'{language}_xlm-roberta-base_cls_logreg_classifier.pt')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EsSGGjDtiFZi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating bengali bert for bengali\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [03:03<00:00, 26.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 63.39%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filter: 100%|██████████| 116067/116067 [00:01<00:00, 76433.28 examples/s]\n",
            "Filter: 100%|██████████| 13325/13325 [00:00<00:00, 83174.25 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating indonesian bert for indonesian\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 38/38 [16:07<00:00, 25.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 67.93%\n",
            "Evaluating arabic bert for arabic\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [25:59<00:00, 25.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0, Accuracy: 83.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "accuracies = {\n",
        "    \"indonesian\": {\"indonesian\": 0, \"bengali\": 0, \"arabic\": 0},\n",
        "    \"bengali\": {\"indonesian\": 0, \"bengali\": 0, \"arabic\": 0},\n",
        "    \"arabic\": {\"indonesian\": 0, \"bengali\": 0, \"arabic\": 0},\n",
        "}\n",
        "import torch_directml\n",
        "device = 'cpu' # torch_directml.device()\n",
        "for language in languages:\n",
        "    model = torch.load(f\"{language}_cls_bert_logreg_classifier.pt\", map_location=torch.device(device)).to(device)\n",
        "    tokenizer = FFN2Tokenizer(bert_map[language])\n",
        "    dataset_language = dataset.filter(lambda row: row[\"language\"] == language)[\n",
        "        \"validation\"\n",
        "    ]\n",
        "    validation_set = FFN2Dataset(dataset_language, tokenizer)\n",
        "\n",
        "    print(f\"Evaluating {language} bert for\", language)\n",
        "    accuracy = evaluate(model, validation_set, batch_size=batch_size, device=device)\n",
        "    accuracies[language][language] = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracies\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'languages' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/tokereines/repositories/08_NLP/experiment/bert_classifier.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tokereines/repositories/08_NLP/experiment/bert_classifier.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Pretty print accuracies\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tokereines/repositories/08_NLP/experiment/bert_classifier.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracies\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tokereines/repositories/08_NLP/experiment/bert_classifier.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(languages))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tokereines/repositories/08_NLP/experiment/bert_classifier.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m language, d1 \u001b[39min\u001b[39;00m accuracies\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tokereines/repositories/08_NLP/experiment/bert_classifier.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(language, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(accuracies[language][language])]))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'languages' is not defined"
          ]
        }
      ],
      "source": [
        "# Pretty print accuracies\n",
        "print(\"Accuracies\")\n",
        "print(\" \".join(languages))\n",
        "for language, d1 in accuracies.items():\n",
        "    print(language, \" \".join([str(accuracies[language][language])]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
