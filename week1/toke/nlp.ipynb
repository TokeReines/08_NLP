{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
       "    num_rows: 13325\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
    "train_set = dataset[\"train\"]\n",
    "validation_set = dataset[\"validation\"]\n",
    "\n",
    "# Define the languages of interest\n",
    "languages = [\"arabic\", \"bengali\", \"indonesian\"]\n",
    "validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_text': 'Milloin Charles Fort syntyi?',\n",
       " 'document_title': 'Charles Fort',\n",
       " 'language': 'finnish',\n",
       " 'annotations': {'answer_start': [-1], 'answer_text': ['']},\n",
       " 'document_plaintext': 'Fortin ystävät perustivat Fortean Societyn jo hänen elinaikanan, ja seuraa johti kirjailija Tiffany Thayer, puoliksi tosissaan ja puoliksi vitsin vuoksi, kuten Fortin itsensä työ. Fort kuitenkin torjui Societyn ja ankarana autoritaarisuuden vastustajana kieltäytyi sen johtajuudesta ja edelleen vastusti seuraa, sillä se saattaisi houkutella spiritualisteja, kiihkoilijoita ja niitä, jotka vastustivat tiedettä, koska se ei ollut hyväksynyt heitä. Se houkuttelisi niitä, jotka uskoivat omaan lempi-ilmiöönsä ylitse muiden: täysin vastakohtainen asenne fortilaisuudelle. On siis ironista, että sittemmin useita sellaisia \"fortilaisia\" seuroja on perustettu lisää. ',\n",
       " 'document_url': 'https://fi.wikipedia.org/wiki/Charles%20Fort'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# unanswerable = train_set[train_set[\"annotations\"][\"answer_start\"][0] == -1]\n",
    "unanswerable = train_set.filter(lambda example: example[\"annotations\"][\"answer_start\"][0] == -1)\n",
    "answerable = train_set.filter(lambda example: example[\"annotations\"][\"answer_start\"][0] != -1)\n",
    "unanswerable[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(answer: str, answer_start: int, document: str) -> bool:\n",
    "    \"\"\"Returns True if the answer is in the document at the given index.\"\"\"\n",
    "    return answer_start != -1 and document[answer_start:answer_start + len(answer)] == answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_1(question: str, document: str, language: str) -> bool:\n",
    "    return True # question in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_bow(question: str, document: str, language: str) -> bool:\n",
    "    \"\"\"Returns True if the question is in the document.\"\"\"\n",
    "    tracker = [word in document for word in question.split()]\n",
    "    contained_ratio = sum(tracker) / len(tracker)\n",
    "    return contained_ratio > 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "\n",
    "language_to_bpe = {'bengali': BPEmb(lang=\"bn\", dim=50), 'indonesian': BPEmb(lang=\"id\", dim=50), 'arabic': BPEmb(lang=\"ar\", dim=50)}\n",
    "\n",
    "def classifier_bpe(question: str, document: str, language: str) -> bool:\n",
    "    bpemb_model = language_to_bpe[language]\n",
    "    # Tokenize question and document\n",
    "    question_bpe = bpemb_model.encode(question)\n",
    "    document_bpe = bpemb_model.encode(document)\n",
    "    tracker = [token_bpe in document_bpe for token_bpe in question_bpe]\n",
    "    contained_ratio = sum(tracker) / len(tracker)\n",
    "    return contained_ratio > 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Try out the classifiers and evaluate them using the oracle function\n",
    "results = []\n",
    "for classifier in [classifier_1, classifier_bow, classifier_bpe]:\n",
    "    for sample in validation_set:\n",
    "        result = {}\n",
    "        if sample['language'] not in languages:\n",
    "            continue\n",
    "        \n",
    "        result['classifier'] = classifier.__name__\n",
    "        result['language'] = sample['language']\n",
    "        \n",
    "        classification = classifier(sample[\"question_text\"], sample[\"document_plaintext\"], sample['language'])\n",
    "        truth = oracle(sample[\"annotations\"][\"answer_text\"][0], sample[\"annotations\"][\"answer_start\"][0], sample[\"document_plaintext\"])\n",
    "        result['correct'] = classification == truth\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for arabic\n",
      "       classifier   correct\n",
      "0    classifier_1  0.500000\n",
      "1  classifier_bow  0.707676\n",
      "2  classifier_bpe  0.691903\n",
      "Count: 5706\n",
      "\n",
      "Results for bengali\n",
      "       classifier   correct\n",
      "0    classifier_1  0.500000\n",
      "1  classifier_bow  0.714286\n",
      "2  classifier_bpe  0.723214\n",
      "Count: 672\n",
      "\n",
      "Results for indonesian\n",
      "       classifier   correct\n",
      "0    classifier_1  0.501259\n",
      "1  classifier_bow  0.669186\n",
      "2  classifier_bpe  0.690176\n",
      "Count: 3573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "for language in languages:\n",
    "    lang_results = results[results['language'] == language]\n",
    "    print(f\"Results for {language}\")\n",
    "    \n",
    "    # Calculate the mean correctness for each classifier\n",
    "    classifier_mean = lang_results.groupby('classifier')['correct'].mean().reset_index()\n",
    "    print( classifier_mean)\n",
    "    \n",
    "    # Calculate the number of rows (samples) for each classifier\n",
    "    classifier_count = len(lang_results)\n",
    "    print(\"Count:\", classifier_count)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "08_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
